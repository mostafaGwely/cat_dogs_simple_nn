{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD,Adam\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "\n",
    "# ap.add_argument('-d','--dataset',required=True,help=\"path to input dataset of images\")\n",
    "# # ap.add_argument('-m','--model',required=True,help=\"path to the output trained model\")\n",
    "# # ap.add_argument('-l','--label-bin',required=True,help=\"path to output label binarize\")\n",
    "# # ap.add_argument('-p','--plot',required=True,help='path to the output accuracy/loss plot')\n",
    "\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "args = {\"dataset\":\"animals\",\"model\":\"output/simple_nn_model_mostafa\",\"label_bin\":\"output/label_bin_simple_nn_model_mostafa\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "labels = [] \n",
    "\n",
    "imagepaths = paths.list_images(args[\"dataset\"])\n",
    "\n",
    "for imagepath in imagepaths:\n",
    "    img = cv2.imread(imagepath)\n",
    "    img = cv2.resize(img,(32,32)).flatten()\n",
    "    data.append(img)\n",
    "    labels.append(imagepath.split(os.path.sep)[-2])\n",
    "data = np.array(data,dtype='float')/255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97254902, 0.92941176, 0.91764706, ..., 0.79607843, 0.79215686,\n",
       "        0.80784314]), 'dogs')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4], labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels,test_size=0.25,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750,), 'panda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape , testY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750, 3), array([0, 0, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape , testY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(32*32*3,),activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(len(lb.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 2000\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/2000\n",
      "2250/2250 [==============================] - 1s 580us/step - loss: 1.1236 - acc: 0.3258 - val_loss: 1.0822 - val_acc: 0.4533\n",
      "Epoch 2/2000\n",
      "2250/2250 [==============================] - 1s 364us/step - loss: 1.0829 - acc: 0.4609 - val_loss: 1.0773 - val_acc: 0.4547\n",
      "Epoch 3/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 1.0582 - acc: 0.4831 - val_loss: 1.0323 - val_acc: 0.5280\n",
      "Epoch 4/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 1.0299 - acc: 0.5044 - val_loss: 1.0125 - val_acc: 0.5093\n",
      "Epoch 5/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 1.0073 - acc: 0.5147 - val_loss: 1.0021 - val_acc: 0.4880\n",
      "Epoch 6/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.9910 - acc: 0.5222 - val_loss: 0.9844 - val_acc: 0.4813\n",
      "Epoch 7/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.9703 - acc: 0.5387 - val_loss: 0.9623 - val_acc: 0.5227\n",
      "Epoch 8/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.9578 - acc: 0.5378 - val_loss: 0.9462 - val_acc: 0.5507\n",
      "Epoch 9/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.9407 - acc: 0.5538 - val_loss: 0.9417 - val_acc: 0.5147\n",
      "Epoch 10/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.9316 - acc: 0.5404 - val_loss: 0.9302 - val_acc: 0.4960\n",
      "Epoch 11/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.9199 - acc: 0.5520 - val_loss: 0.9143 - val_acc: 0.5440\n",
      "Epoch 12/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.9092 - acc: 0.5702 - val_loss: 0.9049 - val_acc: 0.5693\n",
      "Epoch 13/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8977 - acc: 0.5707 - val_loss: 0.9002 - val_acc: 0.5360\n",
      "Epoch 14/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8892 - acc: 0.5578 - val_loss: 0.8905 - val_acc: 0.5507\n",
      "Epoch 15/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.8831 - acc: 0.5729 - val_loss: 0.8827 - val_acc: 0.5707\n",
      "Epoch 16/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8746 - acc: 0.5853 - val_loss: 0.8783 - val_acc: 0.5747\n",
      "Epoch 17/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8685 - acc: 0.5796 - val_loss: 0.8727 - val_acc: 0.5733\n",
      "Epoch 18/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8624 - acc: 0.5778 - val_loss: 0.8675 - val_acc: 0.5720\n",
      "Epoch 19/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8569 - acc: 0.5760 - val_loss: 0.8631 - val_acc: 0.5773\n",
      "Epoch 20/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8509 - acc: 0.5840 - val_loss: 0.8561 - val_acc: 0.5893\n",
      "Epoch 21/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.8476 - acc: 0.5876 - val_loss: 0.8541 - val_acc: 0.5800\n",
      "Epoch 22/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.8444 - acc: 0.5676 - val_loss: 0.8580 - val_acc: 0.5360\n",
      "Epoch 23/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8382 - acc: 0.5804 - val_loss: 0.8463 - val_acc: 0.6000\n",
      "Epoch 24/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8382 - acc: 0.5853 - val_loss: 0.8435 - val_acc: 0.5920\n",
      "Epoch 25/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8320 - acc: 0.5907 - val_loss: 0.8490 - val_acc: 0.5533\n",
      "Epoch 26/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.8282 - acc: 0.5738 - val_loss: 0.8428 - val_acc: 0.5840\n",
      "Epoch 27/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.8239 - acc: 0.5973 - val_loss: 0.8374 - val_acc: 0.5827\n",
      "Epoch 28/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8201 - acc: 0.5996 - val_loss: 0.8402 - val_acc: 0.5747\n",
      "Epoch 29/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8179 - acc: 0.5831 - val_loss: 0.8371 - val_acc: 0.5920\n",
      "Epoch 30/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.8163 - acc: 0.6009 - val_loss: 0.8320 - val_acc: 0.6067\n",
      "Epoch 31/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.8125 - acc: 0.6058 - val_loss: 0.8393 - val_acc: 0.5933\n",
      "Epoch 32/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.8155 - acc: 0.5831 - val_loss: 0.8395 - val_acc: 0.5733\n",
      "Epoch 33/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.8082 - acc: 0.5969 - val_loss: 0.8297 - val_acc: 0.6120\n",
      "Epoch 34/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.8086 - acc: 0.6080 - val_loss: 0.8301 - val_acc: 0.5853\n",
      "Epoch 35/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.8034 - acc: 0.5956 - val_loss: 0.8424 - val_acc: 0.5720\n",
      "Epoch 36/2000\n",
      "2250/2250 [==============================] - 1s 331us/step - loss: 0.8054 - acc: 0.5996 - val_loss: 0.8266 - val_acc: 0.5947\n",
      "Epoch 37/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.8016 - acc: 0.6164 - val_loss: 0.8265 - val_acc: 0.6000\n",
      "Epoch 38/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7985 - acc: 0.6164 - val_loss: 0.8281 - val_acc: 0.6040\n",
      "Epoch 39/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7955 - acc: 0.6187 - val_loss: 0.8262 - val_acc: 0.5947\n",
      "Epoch 40/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.7963 - acc: 0.6062 - val_loss: 0.8263 - val_acc: 0.5907\n",
      "Epoch 41/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7919 - acc: 0.6080 - val_loss: 0.8245 - val_acc: 0.6093\n",
      "Epoch 42/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7895 - acc: 0.6222 - val_loss: 0.8230 - val_acc: 0.5933\n",
      "Epoch 43/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7883 - acc: 0.6098 - val_loss: 0.8266 - val_acc: 0.5947\n",
      "Epoch 44/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.7879 - acc: 0.6133 - val_loss: 0.8204 - val_acc: 0.6107\n",
      "Epoch 45/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7839 - acc: 0.6244 - val_loss: 0.8242 - val_acc: 0.5973\n",
      "Epoch 46/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7857 - acc: 0.6258 - val_loss: 0.8244 - val_acc: 0.6053\n",
      "Epoch 47/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7872 - acc: 0.6164 - val_loss: 0.8243 - val_acc: 0.6067\n",
      "Epoch 48/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.7801 - acc: 0.6182 - val_loss: 0.8217 - val_acc: 0.6027\n",
      "Epoch 49/2000\n",
      "2250/2250 [==============================] - 1s 329us/step - loss: 0.7868 - acc: 0.6231 - val_loss: 0.8214 - val_acc: 0.5907\n",
      "Epoch 50/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7779 - acc: 0.6160 - val_loss: 0.8300 - val_acc: 0.6040\n",
      "Epoch 51/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.7822 - acc: 0.6244 - val_loss: 0.8155 - val_acc: 0.6053\n",
      "Epoch 52/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.7772 - acc: 0.6209 - val_loss: 0.8161 - val_acc: 0.5973\n",
      "Epoch 53/2000\n",
      "2250/2250 [==============================] - 1s 330us/step - loss: 0.7723 - acc: 0.6338 - val_loss: 0.8169 - val_acc: 0.6240\n",
      "Epoch 54/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7711 - acc: 0.6298 - val_loss: 0.8143 - val_acc: 0.5987\n",
      "Epoch 55/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.7693 - acc: 0.6324 - val_loss: 0.8130 - val_acc: 0.6067\n",
      "Epoch 56/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7660 - acc: 0.6360 - val_loss: 0.8147 - val_acc: 0.6040\n",
      "Epoch 57/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7640 - acc: 0.6316 - val_loss: 0.8128 - val_acc: 0.6080\n",
      "Epoch 58/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.7629 - acc: 0.6396 - val_loss: 0.8167 - val_acc: 0.5987\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.7625 - acc: 0.6262 - val_loss: 0.8125 - val_acc: 0.6067\n",
      "Epoch 60/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7610 - acc: 0.6356 - val_loss: 0.8104 - val_acc: 0.6067\n",
      "Epoch 61/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7583 - acc: 0.6484 - val_loss: 0.8165 - val_acc: 0.6013\n",
      "Epoch 62/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7581 - acc: 0.6364 - val_loss: 0.8107 - val_acc: 0.6107\n",
      "Epoch 63/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7555 - acc: 0.6440 - val_loss: 0.8120 - val_acc: 0.6013\n",
      "Epoch 64/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7542 - acc: 0.6449 - val_loss: 0.8167 - val_acc: 0.6120\n",
      "Epoch 65/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7551 - acc: 0.6418 - val_loss: 0.8095 - val_acc: 0.6067\n",
      "Epoch 66/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7503 - acc: 0.6489 - val_loss: 0.8114 - val_acc: 0.5987\n",
      "Epoch 67/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7503 - acc: 0.6542 - val_loss: 0.8116 - val_acc: 0.6120\n",
      "Epoch 68/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.7489 - acc: 0.6511 - val_loss: 0.8120 - val_acc: 0.6027\n",
      "Epoch 69/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7472 - acc: 0.6458 - val_loss: 0.8085 - val_acc: 0.6107\n",
      "Epoch 70/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7457 - acc: 0.6524 - val_loss: 0.8140 - val_acc: 0.6147\n",
      "Epoch 71/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7457 - acc: 0.6556 - val_loss: 0.8117 - val_acc: 0.6067\n",
      "Epoch 72/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7425 - acc: 0.6538 - val_loss: 0.8074 - val_acc: 0.6133\n",
      "Epoch 73/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.7388 - acc: 0.6538 - val_loss: 0.8111 - val_acc: 0.6000\n",
      "Epoch 74/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7413 - acc: 0.6498 - val_loss: 0.8087 - val_acc: 0.6053\n",
      "Epoch 75/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7389 - acc: 0.6587 - val_loss: 0.8094 - val_acc: 0.6013\n",
      "Epoch 76/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7358 - acc: 0.6640 - val_loss: 0.8135 - val_acc: 0.6160\n",
      "Epoch 77/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7393 - acc: 0.6613 - val_loss: 0.8181 - val_acc: 0.5933\n",
      "Epoch 78/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.7384 - acc: 0.6493 - val_loss: 0.8071 - val_acc: 0.6133\n",
      "Epoch 79/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7336 - acc: 0.6600 - val_loss: 0.8105 - val_acc: 0.6093\n",
      "Epoch 80/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7307 - acc: 0.6547 - val_loss: 0.8163 - val_acc: 0.5987\n",
      "Epoch 81/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.7291 - acc: 0.6658 - val_loss: 0.8100 - val_acc: 0.6107\n",
      "Epoch 82/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7298 - acc: 0.6613 - val_loss: 0.8169 - val_acc: 0.5987\n",
      "Epoch 83/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.7266 - acc: 0.6533 - val_loss: 0.8094 - val_acc: 0.6080\n",
      "Epoch 84/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7266 - acc: 0.6689 - val_loss: 0.8071 - val_acc: 0.6133\n",
      "Epoch 85/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.7223 - acc: 0.6662 - val_loss: 0.8194 - val_acc: 0.5987\n",
      "Epoch 86/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7216 - acc: 0.6653 - val_loss: 0.8084 - val_acc: 0.6093\n",
      "Epoch 87/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7267 - acc: 0.6693 - val_loss: 0.8100 - val_acc: 0.6067\n",
      "Epoch 88/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7181 - acc: 0.6671 - val_loss: 0.8187 - val_acc: 0.5973\n",
      "Epoch 89/2000\n",
      "2250/2250 [==============================] - 1s 334us/step - loss: 0.7178 - acc: 0.6747 - val_loss: 0.8102 - val_acc: 0.5960\n",
      "Epoch 90/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7217 - acc: 0.6778 - val_loss: 0.8117 - val_acc: 0.6013\n",
      "Epoch 91/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7171 - acc: 0.6636 - val_loss: 0.8158 - val_acc: 0.6040\n",
      "Epoch 92/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7148 - acc: 0.6711 - val_loss: 0.8111 - val_acc: 0.6013\n",
      "Epoch 93/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.7131 - acc: 0.6671 - val_loss: 0.8098 - val_acc: 0.6040\n",
      "Epoch 94/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.7105 - acc: 0.6862 - val_loss: 0.8065 - val_acc: 0.6067\n",
      "Epoch 95/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.7067 - acc: 0.6831 - val_loss: 0.8138 - val_acc: 0.5933\n",
      "Epoch 96/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7102 - acc: 0.6827 - val_loss: 0.8055 - val_acc: 0.6187\n",
      "Epoch 97/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7111 - acc: 0.6760 - val_loss: 0.8097 - val_acc: 0.6027\n",
      "Epoch 98/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.7116 - acc: 0.6604 - val_loss: 0.8097 - val_acc: 0.6013\n",
      "Epoch 99/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.7031 - acc: 0.6827 - val_loss: 0.8149 - val_acc: 0.6027\n",
      "Epoch 100/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.7045 - acc: 0.6844 - val_loss: 0.8240 - val_acc: 0.5920\n",
      "Epoch 101/2000\n",
      "2250/2250 [==============================] - 1s 344us/step - loss: 0.7053 - acc: 0.6733 - val_loss: 0.8071 - val_acc: 0.5947\n",
      "Epoch 102/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.6991 - acc: 0.6858 - val_loss: 0.8218 - val_acc: 0.5973\n",
      "Epoch 103/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.7016 - acc: 0.6760 - val_loss: 0.8097 - val_acc: 0.5960\n",
      "Epoch 104/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6966 - acc: 0.6924 - val_loss: 0.8049 - val_acc: 0.6080\n",
      "Epoch 105/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6959 - acc: 0.6884 - val_loss: 0.8095 - val_acc: 0.6000\n",
      "Epoch 106/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6902 - acc: 0.6951 - val_loss: 0.8111 - val_acc: 0.5947\n",
      "Epoch 107/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6910 - acc: 0.6911 - val_loss: 0.8129 - val_acc: 0.5973\n",
      "Epoch 108/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6897 - acc: 0.6893 - val_loss: 0.8103 - val_acc: 0.6053\n",
      "Epoch 109/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6881 - acc: 0.6920 - val_loss: 0.8086 - val_acc: 0.5973\n",
      "Epoch 110/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6880 - acc: 0.7022 - val_loss: 0.8074 - val_acc: 0.6040\n",
      "Epoch 111/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6824 - acc: 0.7022 - val_loss: 0.8156 - val_acc: 0.6000\n",
      "Epoch 112/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6832 - acc: 0.7000 - val_loss: 0.8069 - val_acc: 0.6027\n",
      "Epoch 113/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6808 - acc: 0.7071 - val_loss: 0.8096 - val_acc: 0.5973\n",
      "Epoch 114/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6783 - acc: 0.7053 - val_loss: 0.8146 - val_acc: 0.5987\n",
      "Epoch 115/2000\n",
      "2250/2250 [==============================] - 1s 338us/step - loss: 0.6781 - acc: 0.6960 - val_loss: 0.8109 - val_acc: 0.5960\n",
      "Epoch 116/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6756 - acc: 0.7049 - val_loss: 0.8113 - val_acc: 0.5933\n",
      "Epoch 117/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.6750 - acc: 0.7058 - val_loss: 0.8147 - val_acc: 0.5920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6736 - acc: 0.7058 - val_loss: 0.8097 - val_acc: 0.5933\n",
      "Epoch 119/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6707 - acc: 0.7031 - val_loss: 0.8092 - val_acc: 0.5933\n",
      "Epoch 120/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6690 - acc: 0.7124 - val_loss: 0.8077 - val_acc: 0.6040\n",
      "Epoch 121/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6725 - acc: 0.7044 - val_loss: 0.8177 - val_acc: 0.5973\n",
      "Epoch 122/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6706 - acc: 0.6987 - val_loss: 0.8097 - val_acc: 0.5987\n",
      "Epoch 123/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6676 - acc: 0.7080 - val_loss: 0.8120 - val_acc: 0.5880\n",
      "Epoch 124/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.6680 - acc: 0.7116 - val_loss: 0.8144 - val_acc: 0.6027\n",
      "Epoch 125/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6627 - acc: 0.7076 - val_loss: 0.8097 - val_acc: 0.5973\n",
      "Epoch 126/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6612 - acc: 0.7164 - val_loss: 0.8258 - val_acc: 0.5960\n",
      "Epoch 127/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6643 - acc: 0.7040 - val_loss: 0.8111 - val_acc: 0.6160\n",
      "Epoch 128/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6656 - acc: 0.7027 - val_loss: 0.8201 - val_acc: 0.5973\n",
      "Epoch 129/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6609 - acc: 0.7080 - val_loss: 0.8136 - val_acc: 0.6027\n",
      "Epoch 130/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6567 - acc: 0.7160 - val_loss: 0.8128 - val_acc: 0.5933\n",
      "Epoch 131/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6559 - acc: 0.7218 - val_loss: 0.8155 - val_acc: 0.5893\n",
      "Epoch 132/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.6533 - acc: 0.7133 - val_loss: 0.8116 - val_acc: 0.5920\n",
      "Epoch 133/2000\n",
      "2250/2250 [==============================] - 1s 331us/step - loss: 0.6499 - acc: 0.7276 - val_loss: 0.8268 - val_acc: 0.5920\n",
      "Epoch 134/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6517 - acc: 0.7213 - val_loss: 0.8130 - val_acc: 0.6027\n",
      "Epoch 135/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.6487 - acc: 0.7204 - val_loss: 0.8160 - val_acc: 0.5907\n",
      "Epoch 136/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.6468 - acc: 0.7302 - val_loss: 0.8140 - val_acc: 0.5853\n",
      "Epoch 137/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6427 - acc: 0.7262 - val_loss: 0.8162 - val_acc: 0.5973\n",
      "Epoch 138/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6415 - acc: 0.7298 - val_loss: 0.8139 - val_acc: 0.5920\n",
      "Epoch 139/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6407 - acc: 0.7329 - val_loss: 0.8198 - val_acc: 0.5907\n",
      "Epoch 140/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6415 - acc: 0.7289 - val_loss: 0.8142 - val_acc: 0.6000\n",
      "Epoch 141/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6394 - acc: 0.7240 - val_loss: 0.8258 - val_acc: 0.5987\n",
      "Epoch 142/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6386 - acc: 0.7200 - val_loss: 0.8231 - val_acc: 0.5800\n",
      "Epoch 143/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6353 - acc: 0.7307 - val_loss: 0.8169 - val_acc: 0.5973\n",
      "Epoch 144/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6334 - acc: 0.7316 - val_loss: 0.8231 - val_acc: 0.5947\n",
      "Epoch 145/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6325 - acc: 0.7338 - val_loss: 0.8151 - val_acc: 0.6040\n",
      "Epoch 146/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.6307 - acc: 0.7280 - val_loss: 0.8240 - val_acc: 0.5920\n",
      "Epoch 147/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6283 - acc: 0.7316 - val_loss: 0.8180 - val_acc: 0.6053\n",
      "Epoch 148/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6286 - acc: 0.7289 - val_loss: 0.8324 - val_acc: 0.6013\n",
      "Epoch 149/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6291 - acc: 0.7342 - val_loss: 0.8205 - val_acc: 0.5893\n",
      "Epoch 150/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6247 - acc: 0.7369 - val_loss: 0.8233 - val_acc: 0.5893\n",
      "Epoch 151/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6219 - acc: 0.7409 - val_loss: 0.8198 - val_acc: 0.5893\n",
      "Epoch 152/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.6186 - acc: 0.7462 - val_loss: 0.8217 - val_acc: 0.5960\n",
      "Epoch 153/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6166 - acc: 0.7462 - val_loss: 0.8222 - val_acc: 0.6013\n",
      "Epoch 154/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6149 - acc: 0.7484 - val_loss: 0.8206 - val_acc: 0.5947\n",
      "Epoch 155/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6130 - acc: 0.7462 - val_loss: 0.8233 - val_acc: 0.5987\n",
      "Epoch 156/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6121 - acc: 0.7440 - val_loss: 0.8288 - val_acc: 0.6000\n",
      "Epoch 157/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6112 - acc: 0.7427 - val_loss: 0.8230 - val_acc: 0.5960\n",
      "Epoch 158/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.6094 - acc: 0.7498 - val_loss: 0.8220 - val_acc: 0.5960\n",
      "Epoch 159/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6070 - acc: 0.7480 - val_loss: 0.8246 - val_acc: 0.6013\n",
      "Epoch 160/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.6045 - acc: 0.7520 - val_loss: 0.8256 - val_acc: 0.5907\n",
      "Epoch 161/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.6044 - acc: 0.7524 - val_loss: 0.8237 - val_acc: 0.5987\n",
      "Epoch 162/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.6038 - acc: 0.7498 - val_loss: 0.8260 - val_acc: 0.5973\n",
      "Epoch 163/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.6024 - acc: 0.7556 - val_loss: 0.8270 - val_acc: 0.5947\n",
      "Epoch 164/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5992 - acc: 0.7533 - val_loss: 0.8273 - val_acc: 0.5987\n",
      "Epoch 165/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5971 - acc: 0.7587 - val_loss: 0.8275 - val_acc: 0.5907\n",
      "Epoch 166/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5940 - acc: 0.7587 - val_loss: 0.8300 - val_acc: 0.5920\n",
      "Epoch 167/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5999 - acc: 0.7422 - val_loss: 0.8322 - val_acc: 0.5973\n",
      "Epoch 168/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6021 - acc: 0.7449 - val_loss: 0.8270 - val_acc: 0.6027\n",
      "Epoch 169/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.6034 - acc: 0.7440 - val_loss: 0.8280 - val_acc: 0.5987\n",
      "Epoch 170/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5928 - acc: 0.7564 - val_loss: 0.8338 - val_acc: 0.5880\n",
      "Epoch 171/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5928 - acc: 0.7644 - val_loss: 0.8282 - val_acc: 0.6013\n",
      "Epoch 172/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5947 - acc: 0.7640 - val_loss: 0.8413 - val_acc: 0.5960\n",
      "Epoch 173/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5864 - acc: 0.7662 - val_loss: 0.8323 - val_acc: 0.6040\n",
      "Epoch 174/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5837 - acc: 0.7640 - val_loss: 0.8418 - val_acc: 0.5920\n",
      "Epoch 175/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5840 - acc: 0.7618 - val_loss: 0.8419 - val_acc: 0.5960\n",
      "Epoch 176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5863 - acc: 0.7622 - val_loss: 0.8380 - val_acc: 0.5907\n",
      "Epoch 177/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5829 - acc: 0.7667 - val_loss: 0.8413 - val_acc: 0.6000\n",
      "Epoch 178/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5816 - acc: 0.7676 - val_loss: 0.8309 - val_acc: 0.6000\n",
      "Epoch 179/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5787 - acc: 0.7649 - val_loss: 0.8554 - val_acc: 0.5893\n",
      "Epoch 180/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5772 - acc: 0.7707 - val_loss: 0.8439 - val_acc: 0.5880\n",
      "Epoch 181/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.5830 - acc: 0.7560 - val_loss: 0.8594 - val_acc: 0.5880\n",
      "Epoch 182/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5825 - acc: 0.7609 - val_loss: 0.8408 - val_acc: 0.5947\n",
      "Epoch 183/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5771 - acc: 0.7578 - val_loss: 0.8423 - val_acc: 0.5973\n",
      "Epoch 184/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.5782 - acc: 0.7640 - val_loss: 0.8566 - val_acc: 0.5893\n",
      "Epoch 185/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5689 - acc: 0.7711 - val_loss: 0.8470 - val_acc: 0.5907\n",
      "Epoch 186/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5758 - acc: 0.7613 - val_loss: 0.8714 - val_acc: 0.5773\n",
      "Epoch 187/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5737 - acc: 0.7662 - val_loss: 0.8391 - val_acc: 0.6013\n",
      "Epoch 188/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5748 - acc: 0.7542 - val_loss: 0.8586 - val_acc: 0.5907\n",
      "Epoch 189/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5710 - acc: 0.7738 - val_loss: 0.8425 - val_acc: 0.5867\n",
      "Epoch 190/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5605 - acc: 0.7769 - val_loss: 0.8649 - val_acc: 0.5880\n",
      "Epoch 191/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5640 - acc: 0.7707 - val_loss: 0.8533 - val_acc: 0.5893\n",
      "Epoch 192/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5618 - acc: 0.7818 - val_loss: 0.8490 - val_acc: 0.5920\n",
      "Epoch 193/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5600 - acc: 0.7680 - val_loss: 0.8434 - val_acc: 0.5933\n",
      "Epoch 194/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5533 - acc: 0.7831 - val_loss: 0.8444 - val_acc: 0.5933\n",
      "Epoch 195/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5518 - acc: 0.7840 - val_loss: 0.8540 - val_acc: 0.5960\n",
      "Epoch 196/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5518 - acc: 0.7800 - val_loss: 0.8547 - val_acc: 0.5893\n",
      "Epoch 197/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.5674 - acc: 0.7471 - val_loss: 0.8838 - val_acc: 0.5893\n",
      "Epoch 198/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5586 - acc: 0.7738 - val_loss: 0.8531 - val_acc: 0.5907\n",
      "Epoch 199/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5582 - acc: 0.7667 - val_loss: 0.8902 - val_acc: 0.5867\n",
      "Epoch 200/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.5561 - acc: 0.7667 - val_loss: 0.8500 - val_acc: 0.5907\n",
      "Epoch 201/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5515 - acc: 0.7796 - val_loss: 0.8621 - val_acc: 0.5960\n",
      "Epoch 202/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5431 - acc: 0.7862 - val_loss: 0.8471 - val_acc: 0.5987\n",
      "Epoch 203/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5439 - acc: 0.7916 - val_loss: 0.8618 - val_acc: 0.5973\n",
      "Epoch 204/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5397 - acc: 0.7920 - val_loss: 0.8468 - val_acc: 0.5973\n",
      "Epoch 205/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5375 - acc: 0.7907 - val_loss: 0.8584 - val_acc: 0.5947\n",
      "Epoch 206/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5355 - acc: 0.7907 - val_loss: 0.8506 - val_acc: 0.5840\n",
      "Epoch 207/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5345 - acc: 0.7911 - val_loss: 0.8541 - val_acc: 0.5840\n",
      "Epoch 208/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5370 - acc: 0.7956 - val_loss: 0.8545 - val_acc: 0.5853\n",
      "Epoch 209/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5364 - acc: 0.7871 - val_loss: 0.8530 - val_acc: 0.5853\n",
      "Epoch 210/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.5317 - acc: 0.8013 - val_loss: 0.8629 - val_acc: 0.5907\n",
      "Epoch 211/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5319 - acc: 0.7960 - val_loss: 0.8502 - val_acc: 0.5893\n",
      "Epoch 212/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5293 - acc: 0.7982 - val_loss: 0.8719 - val_acc: 0.5867\n",
      "Epoch 213/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5296 - acc: 0.7920 - val_loss: 0.8516 - val_acc: 0.5920\n",
      "Epoch 214/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5244 - acc: 0.7938 - val_loss: 0.8870 - val_acc: 0.5760\n",
      "Epoch 215/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.5310 - acc: 0.7964 - val_loss: 0.8549 - val_acc: 0.5920\n",
      "Epoch 216/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.5268 - acc: 0.7938 - val_loss: 0.8714 - val_acc: 0.5880\n",
      "Epoch 217/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5212 - acc: 0.8031 - val_loss: 0.8578 - val_acc: 0.5813\n",
      "Epoch 218/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5253 - acc: 0.7973 - val_loss: 0.8554 - val_acc: 0.5853\n",
      "Epoch 219/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5254 - acc: 0.7893 - val_loss: 0.8790 - val_acc: 0.5853\n",
      "Epoch 220/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5302 - acc: 0.7916 - val_loss: 0.8736 - val_acc: 0.5827\n",
      "Epoch 221/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5310 - acc: 0.7862 - val_loss: 0.8832 - val_acc: 0.5880\n",
      "Epoch 222/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5258 - acc: 0.7858 - val_loss: 0.8639 - val_acc: 0.5933\n",
      "Epoch 223/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.5168 - acc: 0.7982 - val_loss: 0.8663 - val_acc: 0.5867\n",
      "Epoch 224/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5118 - acc: 0.8058 - val_loss: 0.8612 - val_acc: 0.5867\n",
      "Epoch 225/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5099 - acc: 0.8120 - val_loss: 0.8733 - val_acc: 0.5867\n",
      "Epoch 226/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.5115 - acc: 0.8080 - val_loss: 0.8700 - val_acc: 0.5867\n",
      "Epoch 227/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.5104 - acc: 0.8022 - val_loss: 0.8624 - val_acc: 0.6000\n",
      "Epoch 228/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5133 - acc: 0.8013 - val_loss: 0.8742 - val_acc: 0.5907\n",
      "Epoch 229/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5056 - acc: 0.8120 - val_loss: 0.8652 - val_acc: 0.5800\n",
      "Epoch 230/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.5030 - acc: 0.8164 - val_loss: 0.8739 - val_acc: 0.5867\n",
      "Epoch 231/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.5045 - acc: 0.8093 - val_loss: 0.8689 - val_acc: 0.5867\n",
      "Epoch 232/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5039 - acc: 0.8124 - val_loss: 0.8712 - val_acc: 0.5827\n",
      "Epoch 233/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4979 - acc: 0.8156 - val_loss: 0.8707 - val_acc: 0.5840\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.5014 - acc: 0.8147 - val_loss: 0.8698 - val_acc: 0.5840\n",
      "Epoch 235/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4988 - acc: 0.8133 - val_loss: 0.8683 - val_acc: 0.5760\n",
      "Epoch 236/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4949 - acc: 0.8178 - val_loss: 0.8917 - val_acc: 0.5853\n",
      "Epoch 237/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5051 - acc: 0.7951 - val_loss: 0.8738 - val_acc: 0.5920\n",
      "Epoch 238/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5053 - acc: 0.8009 - val_loss: 0.9004 - val_acc: 0.5813\n",
      "Epoch 239/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.5007 - acc: 0.7973 - val_loss: 0.8794 - val_acc: 0.5867\n",
      "Epoch 240/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4974 - acc: 0.8178 - val_loss: 0.8947 - val_acc: 0.5827\n",
      "Epoch 241/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4949 - acc: 0.8133 - val_loss: 0.8718 - val_acc: 0.5987\n",
      "Epoch 242/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4915 - acc: 0.8129 - val_loss: 0.8823 - val_acc: 0.5853\n",
      "Epoch 243/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4885 - acc: 0.8236 - val_loss: 0.8847 - val_acc: 0.5880\n",
      "Epoch 244/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4959 - acc: 0.8018 - val_loss: 0.8811 - val_acc: 0.5907\n",
      "Epoch 245/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.5044 - acc: 0.7933 - val_loss: 0.9481 - val_acc: 0.5800\n",
      "Epoch 246/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5123 - acc: 0.7773 - val_loss: 0.9068 - val_acc: 0.5827\n",
      "Epoch 247/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.5104 - acc: 0.7884 - val_loss: 0.9346 - val_acc: 0.5720\n",
      "Epoch 248/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.5016 - acc: 0.7973 - val_loss: 0.8833 - val_acc: 0.5893\n",
      "Epoch 249/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4872 - acc: 0.8160 - val_loss: 0.8960 - val_acc: 0.5827\n",
      "Epoch 250/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4839 - acc: 0.8178 - val_loss: 0.8773 - val_acc: 0.5840\n",
      "Epoch 251/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4813 - acc: 0.8178 - val_loss: 0.8778 - val_acc: 0.5827\n",
      "Epoch 252/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4788 - acc: 0.8191 - val_loss: 0.8763 - val_acc: 0.5787\n",
      "Epoch 253/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4805 - acc: 0.8258 - val_loss: 0.8787 - val_acc: 0.5800\n",
      "Epoch 254/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4790 - acc: 0.8249 - val_loss: 0.9021 - val_acc: 0.5813\n",
      "Epoch 255/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.4862 - acc: 0.8098 - val_loss: 0.8883 - val_acc: 0.5840\n",
      "Epoch 256/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4775 - acc: 0.8213 - val_loss: 0.9077 - val_acc: 0.5787\n",
      "Epoch 257/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4803 - acc: 0.8080 - val_loss: 0.8878 - val_acc: 0.5733\n",
      "Epoch 258/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4720 - acc: 0.8293 - val_loss: 0.8861 - val_acc: 0.5720\n",
      "Epoch 259/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4708 - acc: 0.8293 - val_loss: 0.9085 - val_acc: 0.5760\n",
      "Epoch 260/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4783 - acc: 0.8098 - val_loss: 0.8975 - val_acc: 0.5813\n",
      "Epoch 261/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.4884 - acc: 0.8027 - val_loss: 0.9151 - val_acc: 0.5787\n",
      "Epoch 262/2000\n",
      "2250/2250 [==============================] - 1s 328us/step - loss: 0.4724 - acc: 0.8182 - val_loss: 0.8941 - val_acc: 0.5827\n",
      "Epoch 263/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4698 - acc: 0.8311 - val_loss: 0.9108 - val_acc: 0.5760\n",
      "Epoch 264/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4711 - acc: 0.8204 - val_loss: 0.8896 - val_acc: 0.5867\n",
      "Epoch 265/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4659 - acc: 0.8342 - val_loss: 0.9356 - val_acc: 0.5787\n",
      "Epoch 266/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4801 - acc: 0.8102 - val_loss: 0.8945 - val_acc: 0.5893\n",
      "Epoch 267/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4751 - acc: 0.8147 - val_loss: 0.9508 - val_acc: 0.5693\n",
      "Epoch 268/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4763 - acc: 0.8129 - val_loss: 0.8917 - val_acc: 0.5920\n",
      "Epoch 269/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4685 - acc: 0.8191 - val_loss: 0.9125 - val_acc: 0.5747\n",
      "Epoch 270/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4595 - acc: 0.8347 - val_loss: 0.8906 - val_acc: 0.5893\n",
      "Epoch 271/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.4580 - acc: 0.8316 - val_loss: 0.8941 - val_acc: 0.5800\n",
      "Epoch 272/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4586 - acc: 0.8293 - val_loss: 0.9092 - val_acc: 0.5787\n",
      "Epoch 273/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4617 - acc: 0.8200 - val_loss: 0.8932 - val_acc: 0.5920\n",
      "Epoch 274/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.4647 - acc: 0.8204 - val_loss: 0.9330 - val_acc: 0.5760\n",
      "Epoch 275/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4625 - acc: 0.8160 - val_loss: 0.8937 - val_acc: 0.5880\n",
      "Epoch 276/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4587 - acc: 0.8338 - val_loss: 0.9121 - val_acc: 0.5747\n",
      "Epoch 277/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4526 - acc: 0.8360 - val_loss: 0.8938 - val_acc: 0.5840\n",
      "Epoch 278/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4487 - acc: 0.8404 - val_loss: 0.9010 - val_acc: 0.5760\n",
      "Epoch 279/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4476 - acc: 0.8413 - val_loss: 0.9126 - val_acc: 0.5773\n",
      "Epoch 280/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4478 - acc: 0.8329 - val_loss: 0.8968 - val_acc: 0.5907\n",
      "Epoch 281/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4633 - acc: 0.8102 - val_loss: 0.9543 - val_acc: 0.5680\n",
      "Epoch 282/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4694 - acc: 0.8076 - val_loss: 0.9018 - val_acc: 0.5907\n",
      "Epoch 283/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4730 - acc: 0.7982 - val_loss: 0.9338 - val_acc: 0.5787\n",
      "Epoch 284/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4547 - acc: 0.8227 - val_loss: 0.9159 - val_acc: 0.5720\n",
      "Epoch 285/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4494 - acc: 0.8324 - val_loss: 0.9248 - val_acc: 0.5787\n",
      "Epoch 286/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.4456 - acc: 0.8324 - val_loss: 0.9204 - val_acc: 0.5707\n",
      "Epoch 287/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4502 - acc: 0.8342 - val_loss: 0.9143 - val_acc: 0.5920\n",
      "Epoch 288/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4437 - acc: 0.8382 - val_loss: 0.9198 - val_acc: 0.5707\n",
      "Epoch 289/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4529 - acc: 0.8284 - val_loss: 0.9061 - val_acc: 0.5733\n",
      "Epoch 290/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4474 - acc: 0.8347 - val_loss: 0.9263 - val_acc: 0.5827\n",
      "Epoch 291/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4426 - acc: 0.8356 - val_loss: 0.9086 - val_acc: 0.5760\n",
      "Epoch 292/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4360 - acc: 0.8462 - val_loss: 0.9097 - val_acc: 0.5827\n",
      "Epoch 293/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4331 - acc: 0.8458 - val_loss: 0.9152 - val_acc: 0.5760\n",
      "Epoch 294/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4324 - acc: 0.8440 - val_loss: 0.9150 - val_acc: 0.5787\n",
      "Epoch 295/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4322 - acc: 0.8458 - val_loss: 0.9104 - val_acc: 0.5813\n",
      "Epoch 296/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4302 - acc: 0.8516 - val_loss: 0.9094 - val_acc: 0.5827\n",
      "Epoch 297/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4293 - acc: 0.8524 - val_loss: 0.9180 - val_acc: 0.5747\n",
      "Epoch 298/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4293 - acc: 0.8449 - val_loss: 0.9060 - val_acc: 0.5827\n",
      "Epoch 299/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4320 - acc: 0.8462 - val_loss: 0.9358 - val_acc: 0.5693\n",
      "Epoch 300/2000\n",
      "2250/2250 [==============================] - 1s 329us/step - loss: 0.4323 - acc: 0.8409 - val_loss: 0.9100 - val_acc: 0.5787\n",
      "Epoch 301/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4249 - acc: 0.8484 - val_loss: 0.9302 - val_acc: 0.5800\n",
      "Epoch 302/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.4264 - acc: 0.8436 - val_loss: 0.9221 - val_acc: 0.5720\n",
      "Epoch 303/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.4297 - acc: 0.8467 - val_loss: 0.9110 - val_acc: 0.5840\n",
      "Epoch 304/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4237 - acc: 0.8498 - val_loss: 0.9236 - val_acc: 0.5747\n",
      "Epoch 305/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4232 - acc: 0.8480 - val_loss: 0.9161 - val_acc: 0.5827\n",
      "Epoch 306/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4207 - acc: 0.8529 - val_loss: 0.9187 - val_acc: 0.5760\n",
      "Epoch 307/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4183 - acc: 0.8596 - val_loss: 0.9207 - val_acc: 0.5707\n",
      "Epoch 308/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4247 - acc: 0.8476 - val_loss: 0.9292 - val_acc: 0.5747\n",
      "Epoch 309/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.4181 - acc: 0.8524 - val_loss: 0.9257 - val_acc: 0.5720\n",
      "Epoch 310/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4148 - acc: 0.8600 - val_loss: 0.9243 - val_acc: 0.5760\n",
      "Epoch 311/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4132 - acc: 0.8604 - val_loss: 0.9245 - val_acc: 0.5760\n",
      "Epoch 312/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4126 - acc: 0.8596 - val_loss: 0.9241 - val_acc: 0.5787\n",
      "Epoch 313/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4115 - acc: 0.8640 - val_loss: 0.9362 - val_acc: 0.5747\n",
      "Epoch 314/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4123 - acc: 0.8542 - val_loss: 0.9200 - val_acc: 0.5827\n",
      "Epoch 315/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4144 - acc: 0.8569 - val_loss: 0.9285 - val_acc: 0.5707\n",
      "Epoch 316/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4102 - acc: 0.8609 - val_loss: 0.9183 - val_acc: 0.5813\n",
      "Epoch 317/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4118 - acc: 0.8596 - val_loss: 0.9231 - val_acc: 0.5760\n",
      "Epoch 318/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.4094 - acc: 0.8578 - val_loss: 0.9274 - val_acc: 0.5773\n",
      "Epoch 319/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.4053 - acc: 0.8622 - val_loss: 0.9201 - val_acc: 0.5827\n",
      "Epoch 320/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.4077 - acc: 0.8578 - val_loss: 0.9598 - val_acc: 0.5640\n",
      "Epoch 321/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4090 - acc: 0.8516 - val_loss: 0.9262 - val_acc: 0.5880\n",
      "Epoch 322/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.4130 - acc: 0.8484 - val_loss: 1.0057 - val_acc: 0.5653\n",
      "Epoch 323/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4272 - acc: 0.8276 - val_loss: 0.9400 - val_acc: 0.5787\n",
      "Epoch 324/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4149 - acc: 0.8418 - val_loss: 0.9965 - val_acc: 0.5680\n",
      "Epoch 325/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4184 - acc: 0.8409 - val_loss: 0.9440 - val_acc: 0.5720\n",
      "Epoch 326/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4145 - acc: 0.8449 - val_loss: 0.9440 - val_acc: 0.5680\n",
      "Epoch 327/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4050 - acc: 0.8564 - val_loss: 0.9427 - val_acc: 0.5747\n",
      "Epoch 328/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4112 - acc: 0.8436 - val_loss: 0.9308 - val_acc: 0.5760\n",
      "Epoch 329/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4141 - acc: 0.8449 - val_loss: 0.9792 - val_acc: 0.5667\n",
      "Epoch 330/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.4232 - acc: 0.8347 - val_loss: 0.9458 - val_acc: 0.5840\n",
      "Epoch 331/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.4147 - acc: 0.8400 - val_loss: 0.9852 - val_acc: 0.5720\n",
      "Epoch 332/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4103 - acc: 0.8431 - val_loss: 0.9450 - val_acc: 0.5760\n",
      "Epoch 333/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3987 - acc: 0.8600 - val_loss: 0.9556 - val_acc: 0.5720\n",
      "Epoch 334/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3947 - acc: 0.8564 - val_loss: 0.9421 - val_acc: 0.5773\n",
      "Epoch 335/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3935 - acc: 0.8667 - val_loss: 0.9558 - val_acc: 0.5680\n",
      "Epoch 336/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3920 - acc: 0.8627 - val_loss: 0.9431 - val_acc: 0.5773\n",
      "Epoch 337/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3917 - acc: 0.8609 - val_loss: 0.9493 - val_acc: 0.5747\n",
      "Epoch 338/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3907 - acc: 0.8698 - val_loss: 0.9421 - val_acc: 0.5853\n",
      "Epoch 339/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3932 - acc: 0.8640 - val_loss: 0.9503 - val_acc: 0.5693\n",
      "Epoch 340/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3996 - acc: 0.8636 - val_loss: 0.9855 - val_acc: 0.5667\n",
      "Epoch 341/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.4041 - acc: 0.8524 - val_loss: 0.9480 - val_acc: 0.5720\n",
      "Epoch 342/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3908 - acc: 0.8662 - val_loss: 1.0170 - val_acc: 0.5653\n",
      "Epoch 343/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.4032 - acc: 0.8364 - val_loss: 0.9522 - val_acc: 0.5840\n",
      "Epoch 344/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.4014 - acc: 0.8524 - val_loss: 0.9773 - val_acc: 0.5653\n",
      "Epoch 345/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3857 - acc: 0.8662 - val_loss: 0.9468 - val_acc: 0.5853\n",
      "Epoch 346/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3841 - acc: 0.8680 - val_loss: 0.9732 - val_acc: 0.5640\n",
      "Epoch 347/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3840 - acc: 0.8724 - val_loss: 0.9521 - val_acc: 0.5800\n",
      "Epoch 348/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3798 - acc: 0.8680 - val_loss: 0.9634 - val_acc: 0.5707\n",
      "Epoch 349/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.3812 - acc: 0.8738 - val_loss: 0.9744 - val_acc: 0.5667\n",
      "Epoch 350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.3843 - acc: 0.8636 - val_loss: 0.9533 - val_acc: 0.5800\n",
      "Epoch 351/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3799 - acc: 0.8698 - val_loss: 0.9680 - val_acc: 0.5747\n",
      "Epoch 352/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3774 - acc: 0.8729 - val_loss: 0.9581 - val_acc: 0.5680\n",
      "Epoch 353/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.3774 - acc: 0.8707 - val_loss: 0.9660 - val_acc: 0.5707\n",
      "Epoch 354/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3747 - acc: 0.8724 - val_loss: 0.9547 - val_acc: 0.5840\n",
      "Epoch 355/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3749 - acc: 0.8729 - val_loss: 0.9641 - val_acc: 0.5760\n",
      "Epoch 356/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3723 - acc: 0.8778 - val_loss: 0.9715 - val_acc: 0.5667\n",
      "Epoch 357/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3705 - acc: 0.8782 - val_loss: 0.9593 - val_acc: 0.5720\n",
      "Epoch 358/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3702 - acc: 0.8760 - val_loss: 0.9685 - val_acc: 0.5747\n",
      "Epoch 359/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3680 - acc: 0.8787 - val_loss: 0.9697 - val_acc: 0.5680\n",
      "Epoch 360/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3707 - acc: 0.8733 - val_loss: 0.9625 - val_acc: 0.5760\n",
      "Epoch 361/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3711 - acc: 0.8738 - val_loss: 0.9767 - val_acc: 0.5733\n",
      "Epoch 362/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3718 - acc: 0.8756 - val_loss: 0.9749 - val_acc: 0.5667\n",
      "Epoch 363/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3668 - acc: 0.8791 - val_loss: 0.9689 - val_acc: 0.5693\n",
      "Epoch 364/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3672 - acc: 0.8796 - val_loss: 0.9940 - val_acc: 0.5613\n",
      "Epoch 365/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3692 - acc: 0.8729 - val_loss: 0.9744 - val_acc: 0.5680\n",
      "Epoch 366/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3664 - acc: 0.8804 - val_loss: 0.9751 - val_acc: 0.5693\n",
      "Epoch 367/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3626 - acc: 0.8796 - val_loss: 0.9917 - val_acc: 0.5693\n",
      "Epoch 368/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3646 - acc: 0.8778 - val_loss: 0.9692 - val_acc: 0.5747\n",
      "Epoch 369/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3644 - acc: 0.8796 - val_loss: 0.9929 - val_acc: 0.5733\n",
      "Epoch 370/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3629 - acc: 0.8747 - val_loss: 0.9729 - val_acc: 0.5720\n",
      "Epoch 371/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3580 - acc: 0.8822 - val_loss: 0.9814 - val_acc: 0.5680\n",
      "Epoch 372/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3583 - acc: 0.8822 - val_loss: 0.9975 - val_acc: 0.5707\n",
      "Epoch 373/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3635 - acc: 0.8751 - val_loss: 0.9801 - val_acc: 0.5707\n",
      "Epoch 374/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3680 - acc: 0.8698 - val_loss: 1.0088 - val_acc: 0.5640\n",
      "Epoch 375/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3614 - acc: 0.8711 - val_loss: 0.9806 - val_acc: 0.5707\n",
      "Epoch 376/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3628 - acc: 0.8773 - val_loss: 0.9880 - val_acc: 0.5707\n",
      "Epoch 377/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3569 - acc: 0.8831 - val_loss: 0.9905 - val_acc: 0.5680\n",
      "Epoch 378/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3556 - acc: 0.8769 - val_loss: 0.9870 - val_acc: 0.5680\n",
      "Epoch 379/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3668 - acc: 0.8702 - val_loss: 1.0193 - val_acc: 0.5573\n",
      "Epoch 380/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3618 - acc: 0.8698 - val_loss: 0.9794 - val_acc: 0.5760\n",
      "Epoch 381/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3535 - acc: 0.8791 - val_loss: 0.9899 - val_acc: 0.5653\n",
      "Epoch 382/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3614 - acc: 0.8782 - val_loss: 1.0095 - val_acc: 0.5640\n",
      "Epoch 383/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3535 - acc: 0.8809 - val_loss: 0.9791 - val_acc: 0.5800\n",
      "Epoch 384/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3521 - acc: 0.8831 - val_loss: 1.0320 - val_acc: 0.5640\n",
      "Epoch 385/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3566 - acc: 0.8769 - val_loss: 0.9821 - val_acc: 0.5800\n",
      "Epoch 386/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3532 - acc: 0.8782 - val_loss: 1.0036 - val_acc: 0.5627\n",
      "Epoch 387/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3491 - acc: 0.8876 - val_loss: 0.9834 - val_acc: 0.5787\n",
      "Epoch 388/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3458 - acc: 0.8844 - val_loss: 0.9878 - val_acc: 0.5747\n",
      "Epoch 389/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3449 - acc: 0.8893 - val_loss: 0.9981 - val_acc: 0.5640\n",
      "Epoch 390/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3427 - acc: 0.8862 - val_loss: 0.9858 - val_acc: 0.5800\n",
      "Epoch 391/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.3532 - acc: 0.8813 - val_loss: 1.0200 - val_acc: 0.5600\n",
      "Epoch 392/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3465 - acc: 0.8867 - val_loss: 0.9909 - val_acc: 0.5667\n",
      "Epoch 393/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3455 - acc: 0.8849 - val_loss: 0.9888 - val_acc: 0.5693\n",
      "Epoch 394/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3494 - acc: 0.8867 - val_loss: 1.0180 - val_acc: 0.5573\n",
      "Epoch 395/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3436 - acc: 0.8809 - val_loss: 0.9865 - val_acc: 0.5773\n",
      "Epoch 396/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3405 - acc: 0.8920 - val_loss: 1.0140 - val_acc: 0.5627\n",
      "Epoch 397/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3369 - acc: 0.8920 - val_loss: 0.9933 - val_acc: 0.5760\n",
      "Epoch 398/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3385 - acc: 0.8924 - val_loss: 1.0044 - val_acc: 0.5667\n",
      "Epoch 399/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3350 - acc: 0.8858 - val_loss: 0.9975 - val_acc: 0.5720\n",
      "Epoch 400/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3403 - acc: 0.8867 - val_loss: 1.0142 - val_acc: 0.5653\n",
      "Epoch 401/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3335 - acc: 0.8933 - val_loss: 1.0004 - val_acc: 0.5720\n",
      "Epoch 402/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.3316 - acc: 0.8947 - val_loss: 1.0235 - val_acc: 0.5640\n",
      "Epoch 403/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3314 - acc: 0.8947 - val_loss: 0.9973 - val_acc: 0.5867\n",
      "Epoch 404/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3372 - acc: 0.8876 - val_loss: 1.0373 - val_acc: 0.5573\n",
      "Epoch 405/2000\n",
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3364 - acc: 0.8924 - val_loss: 1.0065 - val_acc: 0.5720\n",
      "Epoch 406/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.3306 - acc: 0.8862 - val_loss: 1.0080 - val_acc: 0.5667\n",
      "Epoch 407/2000\n",
      "2250/2250 [==============================] - 1s 320us/step - loss: 0.3277 - acc: 0.8978 - val_loss: 1.0153 - val_acc: 0.5667\n",
      "Epoch 408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 322us/step - loss: 0.3269 - acc: 0.8911 - val_loss: 1.0060 - val_acc: 0.5693\n",
      "Epoch 409/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3319 - acc: 0.8987 - val_loss: 1.0324 - val_acc: 0.5613\n",
      "Epoch 410/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.3285 - acc: 0.8938 - val_loss: 1.0107 - val_acc: 0.5653\n",
      "Epoch 411/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.3303 - acc: 0.8942 - val_loss: 1.0107 - val_acc: 0.5667\n",
      "Epoch 412/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3289 - acc: 0.8969 - val_loss: 1.0309 - val_acc: 0.5520\n",
      "Epoch 413/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3266 - acc: 0.8956 - val_loss: 1.0139 - val_acc: 0.5640\n",
      "Epoch 414/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3251 - acc: 0.8991 - val_loss: 1.0237 - val_acc: 0.5627\n",
      "Epoch 415/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.3221 - acc: 0.8991 - val_loss: 1.0170 - val_acc: 0.5720\n",
      "Epoch 416/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.3199 - acc: 0.8987 - val_loss: 1.0639 - val_acc: 0.5627\n",
      "Epoch 417/2000\n",
      "2250/2250 [==============================] - 1s 319us/step - loss: 0.3315 - acc: 0.8867 - val_loss: 1.0137 - val_acc: 0.5773\n",
      "Epoch 418/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.3224 - acc: 0.8942 - val_loss: 1.0253 - val_acc: 0.5667\n",
      "Epoch 419/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.3241 - acc: 0.9004 - val_loss: 1.0414 - val_acc: 0.5573\n",
      "Epoch 420/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3273 - acc: 0.8911 - val_loss: 1.0225 - val_acc: 0.5627\n",
      "Epoch 421/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.3231 - acc: 0.9004 - val_loss: 1.0588 - val_acc: 0.5680\n",
      "Epoch 422/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3266 - acc: 0.8907 - val_loss: 1.0344 - val_acc: 0.5680\n",
      "Epoch 423/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3294 - acc: 0.8956 - val_loss: 1.0504 - val_acc: 0.5560\n",
      "Epoch 424/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.3180 - acc: 0.8969 - val_loss: 1.0198 - val_acc: 0.5693\n",
      "Epoch 425/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.3142 - acc: 0.9000 - val_loss: 1.0529 - val_acc: 0.5560\n",
      "Epoch 426/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.3207 - acc: 0.8996 - val_loss: 1.0314 - val_acc: 0.5693\n",
      "Epoch 427/2000\n",
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.3145 - acc: 0.8960 - val_loss: 1.0352 - val_acc: 0.5627\n",
      "Epoch 428/2000\n",
      "2250/2250 [==============================] - 1s 350us/step - loss: 0.3176 - acc: 0.9044 - val_loss: 1.0492 - val_acc: 0.5627\n",
      "Epoch 429/2000\n",
      "2250/2250 [==============================] - 1s 434us/step - loss: 0.3205 - acc: 0.8902 - val_loss: 1.0435 - val_acc: 0.5613\n",
      "Epoch 430/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.3156 - acc: 0.9009 - val_loss: 1.0311 - val_acc: 0.5707\n",
      "Epoch 431/2000\n",
      "2250/2250 [==============================] - 1s 453us/step - loss: 0.3132 - acc: 0.8996 - val_loss: 1.0685 - val_acc: 0.5653\n",
      "Epoch 432/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.3232 - acc: 0.8898 - val_loss: 1.0402 - val_acc: 0.5707\n",
      "Epoch 433/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3236 - acc: 0.8911 - val_loss: 1.0581 - val_acc: 0.5560\n",
      "Epoch 434/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3081 - acc: 0.9076 - val_loss: 1.0422 - val_acc: 0.5613\n",
      "Epoch 435/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3128 - acc: 0.8938 - val_loss: 1.0315 - val_acc: 0.5840\n",
      "Epoch 436/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3154 - acc: 0.8978 - val_loss: 1.0766 - val_acc: 0.5573\n",
      "Epoch 437/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.3165 - acc: 0.9009 - val_loss: 1.0337 - val_acc: 0.5800\n",
      "Epoch 438/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3170 - acc: 0.8947 - val_loss: 1.0635 - val_acc: 0.5600\n",
      "Epoch 439/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3124 - acc: 0.9022 - val_loss: 1.0345 - val_acc: 0.5840\n",
      "Epoch 440/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.3113 - acc: 0.8907 - val_loss: 1.0559 - val_acc: 0.5560\n",
      "Epoch 441/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3092 - acc: 0.9013 - val_loss: 1.0401 - val_acc: 0.5627\n",
      "Epoch 442/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.3072 - acc: 0.9009 - val_loss: 1.0558 - val_acc: 0.5640\n",
      "Epoch 443/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3063 - acc: 0.9027 - val_loss: 1.0503 - val_acc: 0.5667\n",
      "Epoch 444/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3040 - acc: 0.9022 - val_loss: 1.0687 - val_acc: 0.5613\n",
      "Epoch 445/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3036 - acc: 0.9093 - val_loss: 1.0507 - val_acc: 0.5640\n",
      "Epoch 446/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3006 - acc: 0.9093 - val_loss: 1.0768 - val_acc: 0.5680\n",
      "Epoch 447/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3083 - acc: 0.9009 - val_loss: 1.0525 - val_acc: 0.5653\n",
      "Epoch 448/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2974 - acc: 0.9076 - val_loss: 1.0786 - val_acc: 0.5627\n",
      "Epoch 449/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.3021 - acc: 0.9053 - val_loss: 1.0608 - val_acc: 0.5627\n",
      "Epoch 450/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3013 - acc: 0.9067 - val_loss: 1.0573 - val_acc: 0.5640\n",
      "Epoch 451/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.3031 - acc: 0.9004 - val_loss: 1.0536 - val_acc: 0.5587\n",
      "Epoch 452/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2944 - acc: 0.9076 - val_loss: 1.0594 - val_acc: 0.5547\n",
      "Epoch 453/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2920 - acc: 0.9102 - val_loss: 1.0589 - val_acc: 0.5640\n",
      "Epoch 454/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2930 - acc: 0.9062 - val_loss: 1.0631 - val_acc: 0.5547\n",
      "Epoch 455/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2904 - acc: 0.9102 - val_loss: 1.0602 - val_acc: 0.5667\n",
      "Epoch 456/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2906 - acc: 0.9093 - val_loss: 1.0630 - val_acc: 0.5533\n",
      "Epoch 457/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2905 - acc: 0.9084 - val_loss: 1.0641 - val_acc: 0.5587\n",
      "Epoch 458/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2889 - acc: 0.9133 - val_loss: 1.0601 - val_acc: 0.5600\n",
      "Epoch 459/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2886 - acc: 0.9129 - val_loss: 1.0604 - val_acc: 0.5680\n",
      "Epoch 460/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2893 - acc: 0.9133 - val_loss: 1.0799 - val_acc: 0.5587\n",
      "Epoch 461/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2880 - acc: 0.9093 - val_loss: 1.0641 - val_acc: 0.5573\n",
      "Epoch 462/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2858 - acc: 0.9138 - val_loss: 1.0702 - val_acc: 0.5587\n",
      "Epoch 463/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2861 - acc: 0.9093 - val_loss: 1.0732 - val_acc: 0.5600\n",
      "Epoch 464/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2867 - acc: 0.9071 - val_loss: 1.0671 - val_acc: 0.5693\n",
      "Epoch 465/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2926 - acc: 0.9098 - val_loss: 1.0852 - val_acc: 0.5560\n",
      "Epoch 466/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2857 - acc: 0.9147 - val_loss: 1.0632 - val_acc: 0.5653\n",
      "Epoch 467/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2835 - acc: 0.9142 - val_loss: 1.0753 - val_acc: 0.5587\n",
      "Epoch 468/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.2825 - acc: 0.9178 - val_loss: 1.0825 - val_acc: 0.5627\n",
      "Epoch 469/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.2900 - acc: 0.9053 - val_loss: 1.0695 - val_acc: 0.5693\n",
      "Epoch 470/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.2908 - acc: 0.9147 - val_loss: 1.1035 - val_acc: 0.5573\n",
      "Epoch 471/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2845 - acc: 0.9129 - val_loss: 1.0696 - val_acc: 0.5640\n",
      "Epoch 472/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2862 - acc: 0.9080 - val_loss: 1.0688 - val_acc: 0.5667\n",
      "Epoch 473/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2872 - acc: 0.9107 - val_loss: 1.0944 - val_acc: 0.5533\n",
      "Epoch 474/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2819 - acc: 0.9151 - val_loss: 1.0809 - val_acc: 0.5640\n",
      "Epoch 475/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2841 - acc: 0.9098 - val_loss: 1.0736 - val_acc: 0.5600\n",
      "Epoch 476/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2786 - acc: 0.9156 - val_loss: 1.0888 - val_acc: 0.5560\n",
      "Epoch 477/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2757 - acc: 0.9169 - val_loss: 1.0840 - val_acc: 0.5560\n",
      "Epoch 478/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2745 - acc: 0.9178 - val_loss: 1.0989 - val_acc: 0.5627\n",
      "Epoch 479/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2790 - acc: 0.9124 - val_loss: 1.0901 - val_acc: 0.5693\n",
      "Epoch 480/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2813 - acc: 0.9116 - val_loss: 1.0768 - val_acc: 0.5720\n",
      "Epoch 481/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2845 - acc: 0.9089 - val_loss: 1.1436 - val_acc: 0.5547\n",
      "Epoch 482/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2860 - acc: 0.9040 - val_loss: 1.0885 - val_acc: 0.5720\n",
      "Epoch 483/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2796 - acc: 0.9129 - val_loss: 1.1096 - val_acc: 0.5653\n",
      "Epoch 484/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2710 - acc: 0.9227 - val_loss: 1.0955 - val_acc: 0.5680\n",
      "Epoch 485/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2777 - acc: 0.9142 - val_loss: 1.0930 - val_acc: 0.5627\n",
      "Epoch 486/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2733 - acc: 0.9182 - val_loss: 1.1084 - val_acc: 0.5520\n",
      "Epoch 487/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.2733 - acc: 0.9160 - val_loss: 1.0991 - val_acc: 0.5587\n",
      "Epoch 488/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2685 - acc: 0.9236 - val_loss: 1.0920 - val_acc: 0.5613\n",
      "Epoch 489/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2670 - acc: 0.9267 - val_loss: 1.1062 - val_acc: 0.5533\n",
      "Epoch 490/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2666 - acc: 0.9218 - val_loss: 1.0992 - val_acc: 0.5587\n",
      "Epoch 491/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.2657 - acc: 0.9258 - val_loss: 1.1090 - val_acc: 0.5587\n",
      "Epoch 492/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2698 - acc: 0.9164 - val_loss: 1.1146 - val_acc: 0.5560\n",
      "Epoch 493/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2693 - acc: 0.9244 - val_loss: 1.1396 - val_acc: 0.5640\n",
      "Epoch 494/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2778 - acc: 0.9080 - val_loss: 1.1040 - val_acc: 0.5547\n",
      "Epoch 495/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2664 - acc: 0.9178 - val_loss: 1.1012 - val_acc: 0.5720\n",
      "Epoch 496/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2689 - acc: 0.9129 - val_loss: 1.1481 - val_acc: 0.5600\n",
      "Epoch 497/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2732 - acc: 0.9089 - val_loss: 1.1167 - val_acc: 0.5707\n",
      "Epoch 498/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2715 - acc: 0.9151 - val_loss: 1.1007 - val_acc: 0.5627\n",
      "Epoch 499/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2688 - acc: 0.9169 - val_loss: 1.1475 - val_acc: 0.5587\n",
      "Epoch 500/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2730 - acc: 0.9142 - val_loss: 1.1033 - val_acc: 0.5747\n",
      "Epoch 501/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2711 - acc: 0.9133 - val_loss: 1.1418 - val_acc: 0.5627\n",
      "Epoch 502/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2628 - acc: 0.9231 - val_loss: 1.1196 - val_acc: 0.5573\n",
      "Epoch 503/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2622 - acc: 0.9204 - val_loss: 1.1049 - val_acc: 0.5693\n",
      "Epoch 504/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2632 - acc: 0.9196 - val_loss: 1.1401 - val_acc: 0.5560\n",
      "Epoch 505/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2634 - acc: 0.9209 - val_loss: 1.1073 - val_acc: 0.5653\n",
      "Epoch 506/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2571 - acc: 0.9258 - val_loss: 1.1291 - val_acc: 0.5507\n",
      "Epoch 507/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2610 - acc: 0.9218 - val_loss: 1.1406 - val_acc: 0.5427\n",
      "Epoch 508/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2570 - acc: 0.9249 - val_loss: 1.1091 - val_acc: 0.5787\n",
      "Epoch 509/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2593 - acc: 0.9187 - val_loss: 1.1543 - val_acc: 0.5493\n",
      "Epoch 510/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2605 - acc: 0.9227 - val_loss: 1.1131 - val_acc: 0.5667\n",
      "Epoch 511/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2592 - acc: 0.9200 - val_loss: 1.1312 - val_acc: 0.5520\n",
      "Epoch 512/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2551 - acc: 0.9276 - val_loss: 1.1312 - val_acc: 0.5533\n",
      "Epoch 513/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2529 - acc: 0.9236 - val_loss: 1.1172 - val_acc: 0.5627\n",
      "Epoch 514/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2561 - acc: 0.9262 - val_loss: 1.1382 - val_acc: 0.5533\n",
      "Epoch 515/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.2519 - acc: 0.9293 - val_loss: 1.1533 - val_acc: 0.5573\n",
      "Epoch 516/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2627 - acc: 0.9156 - val_loss: 1.1438 - val_acc: 0.5653\n",
      "Epoch 517/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2639 - acc: 0.9182 - val_loss: 1.2171 - val_acc: 0.5480\n",
      "Epoch 518/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2753 - acc: 0.9022 - val_loss: 1.1261 - val_acc: 0.5587\n",
      "Epoch 519/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2634 - acc: 0.9111 - val_loss: 1.1303 - val_acc: 0.5587\n",
      "Epoch 520/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2555 - acc: 0.9244 - val_loss: 1.1852 - val_acc: 0.5493\n",
      "Epoch 521/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2634 - acc: 0.9129 - val_loss: 1.1347 - val_acc: 0.5693\n",
      "Epoch 522/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2559 - acc: 0.9293 - val_loss: 1.1851 - val_acc: 0.5507\n",
      "Epoch 523/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2528 - acc: 0.9262 - val_loss: 1.1322 - val_acc: 0.5680\n",
      "Epoch 524/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2531 - acc: 0.9218 - val_loss: 1.1629 - val_acc: 0.5480\n",
      "Epoch 525/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2517 - acc: 0.9249 - val_loss: 1.1371 - val_acc: 0.5573\n",
      "Epoch 526/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2451 - acc: 0.9302 - val_loss: 1.1422 - val_acc: 0.5547\n",
      "Epoch 527/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2447 - acc: 0.9302 - val_loss: 1.1673 - val_acc: 0.5587\n",
      "Epoch 528/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2483 - acc: 0.9258 - val_loss: 1.1393 - val_acc: 0.5747\n",
      "Epoch 529/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2495 - acc: 0.9293 - val_loss: 1.2334 - val_acc: 0.5440\n",
      "Epoch 530/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2605 - acc: 0.9173 - val_loss: 1.1440 - val_acc: 0.5747\n",
      "Epoch 531/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2588 - acc: 0.9182 - val_loss: 1.1725 - val_acc: 0.5547\n",
      "Epoch 532/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2459 - acc: 0.9262 - val_loss: 1.1527 - val_acc: 0.5573\n",
      "Epoch 533/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2517 - acc: 0.9209 - val_loss: 1.1512 - val_acc: 0.5707\n",
      "Epoch 534/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2557 - acc: 0.9267 - val_loss: 1.1998 - val_acc: 0.5573\n",
      "Epoch 535/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2539 - acc: 0.9200 - val_loss: 1.1592 - val_acc: 0.5693\n",
      "Epoch 536/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2532 - acc: 0.9271 - val_loss: 1.2109 - val_acc: 0.5493\n",
      "Epoch 537/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2489 - acc: 0.9249 - val_loss: 1.1442 - val_acc: 0.5733\n",
      "Epoch 538/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2516 - acc: 0.9284 - val_loss: 1.1827 - val_acc: 0.5493\n",
      "Epoch 539/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2456 - acc: 0.9289 - val_loss: 1.1564 - val_acc: 0.5627\n",
      "Epoch 540/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2436 - acc: 0.9284 - val_loss: 1.1714 - val_acc: 0.5613\n",
      "Epoch 541/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2412 - acc: 0.9329 - val_loss: 1.1692 - val_acc: 0.5613\n",
      "Epoch 542/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2369 - acc: 0.9342 - val_loss: 1.1559 - val_acc: 0.5693\n",
      "Epoch 543/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2372 - acc: 0.9342 - val_loss: 1.1792 - val_acc: 0.5547\n",
      "Epoch 544/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2374 - acc: 0.9347 - val_loss: 1.1702 - val_acc: 0.5520\n",
      "Epoch 545/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2363 - acc: 0.9324 - val_loss: 1.1606 - val_acc: 0.5773\n",
      "Epoch 546/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2455 - acc: 0.9231 - val_loss: 1.1867 - val_acc: 0.5573\n",
      "Epoch 547/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2362 - acc: 0.9333 - val_loss: 1.1741 - val_acc: 0.5520\n",
      "Epoch 548/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2328 - acc: 0.9387 - val_loss: 1.1628 - val_acc: 0.5613\n",
      "Epoch 549/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2313 - acc: 0.9369 - val_loss: 1.1854 - val_acc: 0.5493\n",
      "Epoch 550/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2298 - acc: 0.9369 - val_loss: 1.1607 - val_acc: 0.5680\n",
      "Epoch 551/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2311 - acc: 0.9342 - val_loss: 1.1961 - val_acc: 0.5493\n",
      "Epoch 552/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2322 - acc: 0.9360 - val_loss: 1.1868 - val_acc: 0.5507\n",
      "Epoch 553/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2316 - acc: 0.9373 - val_loss: 1.1902 - val_acc: 0.5560\n",
      "Epoch 554/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2304 - acc: 0.9329 - val_loss: 1.1752 - val_acc: 0.5733\n",
      "Epoch 555/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2376 - acc: 0.9302 - val_loss: 1.1949 - val_acc: 0.5573\n",
      "Epoch 556/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2322 - acc: 0.9298 - val_loss: 1.1881 - val_acc: 0.5493\n",
      "Epoch 557/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2289 - acc: 0.9373 - val_loss: 1.1829 - val_acc: 0.5560\n",
      "Epoch 558/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2270 - acc: 0.9329 - val_loss: 1.1872 - val_acc: 0.5547\n",
      "Epoch 559/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2268 - acc: 0.9356 - val_loss: 1.1911 - val_acc: 0.5640\n",
      "Epoch 560/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2272 - acc: 0.9373 - val_loss: 1.1971 - val_acc: 0.5547\n",
      "Epoch 561/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2257 - acc: 0.9360 - val_loss: 1.1937 - val_acc: 0.5493\n",
      "Epoch 562/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2271 - acc: 0.9396 - val_loss: 1.1774 - val_acc: 0.5653\n",
      "Epoch 563/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2243 - acc: 0.9387 - val_loss: 1.1956 - val_acc: 0.5573\n",
      "Epoch 564/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2239 - acc: 0.9378 - val_loss: 1.1899 - val_acc: 0.5533\n",
      "Epoch 565/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2208 - acc: 0.9391 - val_loss: 1.1915 - val_acc: 0.5600\n",
      "Epoch 566/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.2208 - acc: 0.9396 - val_loss: 1.2066 - val_acc: 0.5507\n",
      "Epoch 567/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2227 - acc: 0.9409 - val_loss: 1.1861 - val_acc: 0.5680\n",
      "Epoch 568/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2221 - acc: 0.9360 - val_loss: 1.2103 - val_acc: 0.5507\n",
      "Epoch 569/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2212 - acc: 0.9413 - val_loss: 1.1990 - val_acc: 0.5547\n",
      "Epoch 570/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2223 - acc: 0.9382 - val_loss: 1.1830 - val_acc: 0.5667\n",
      "Epoch 571/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2264 - acc: 0.9329 - val_loss: 1.2334 - val_acc: 0.5493\n",
      "Epoch 572/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2266 - acc: 0.9391 - val_loss: 1.2244 - val_acc: 0.5533\n",
      "Epoch 573/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2316 - acc: 0.9298 - val_loss: 1.1893 - val_acc: 0.5680\n",
      "Epoch 574/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.2207 - acc: 0.9396 - val_loss: 1.2110 - val_acc: 0.5507\n",
      "Epoch 575/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2181 - acc: 0.9409 - val_loss: 1.2361 - val_acc: 0.5533\n",
      "Epoch 576/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2237 - acc: 0.9360 - val_loss: 1.2079 - val_acc: 0.5760\n",
      "Epoch 577/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2317 - acc: 0.9307 - val_loss: 1.2316 - val_acc: 0.5493\n",
      "Epoch 578/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2230 - acc: 0.9360 - val_loss: 1.2206 - val_acc: 0.5427\n",
      "Epoch 579/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2201 - acc: 0.9409 - val_loss: 1.2003 - val_acc: 0.5627\n",
      "Epoch 580/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2163 - acc: 0.9382 - val_loss: 1.2156 - val_acc: 0.5507\n",
      "Epoch 581/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.2132 - acc: 0.9422 - val_loss: 1.2111 - val_acc: 0.5520\n",
      "Epoch 582/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.2131 - acc: 0.9431 - val_loss: 1.2021 - val_acc: 0.5613\n",
      "Epoch 583/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2122 - acc: 0.9409 - val_loss: 1.2356 - val_acc: 0.5467\n",
      "Epoch 584/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2131 - acc: 0.9453 - val_loss: 1.2123 - val_acc: 0.5573\n",
      "Epoch 585/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2123 - acc: 0.9422 - val_loss: 1.2176 - val_acc: 0.5600\n",
      "Epoch 586/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2134 - acc: 0.9413 - val_loss: 1.2205 - val_acc: 0.5507\n",
      "Epoch 587/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2111 - acc: 0.9436 - val_loss: 1.2364 - val_acc: 0.5493\n",
      "Epoch 588/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2125 - acc: 0.9462 - val_loss: 1.2213 - val_acc: 0.5693\n",
      "Epoch 589/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2177 - acc: 0.9382 - val_loss: 1.2621 - val_acc: 0.5547\n",
      "Epoch 590/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2136 - acc: 0.9396 - val_loss: 1.2231 - val_acc: 0.5733\n",
      "Epoch 591/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2189 - acc: 0.9387 - val_loss: 1.2469 - val_acc: 0.5573\n",
      "Epoch 592/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2214 - acc: 0.9333 - val_loss: 1.2564 - val_acc: 0.5480\n",
      "Epoch 593/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2230 - acc: 0.9360 - val_loss: 1.2103 - val_acc: 0.5720\n",
      "Epoch 594/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2163 - acc: 0.9360 - val_loss: 1.2600 - val_acc: 0.5480\n",
      "Epoch 595/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2145 - acc: 0.9427 - val_loss: 1.2247 - val_acc: 0.5560\n",
      "Epoch 596/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2077 - acc: 0.9436 - val_loss: 1.2211 - val_acc: 0.5560\n",
      "Epoch 597/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.2074 - acc: 0.9409 - val_loss: 1.2634 - val_acc: 0.5480\n",
      "Epoch 598/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2070 - acc: 0.9462 - val_loss: 1.2180 - val_acc: 0.5800\n",
      "Epoch 599/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2140 - acc: 0.9387 - val_loss: 1.2749 - val_acc: 0.5520\n",
      "Epoch 600/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2088 - acc: 0.9422 - val_loss: 1.2204 - val_acc: 0.5640\n",
      "Epoch 601/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2059 - acc: 0.9440 - val_loss: 1.2337 - val_acc: 0.5600\n",
      "Epoch 602/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2060 - acc: 0.9396 - val_loss: 1.2534 - val_acc: 0.5533\n",
      "Epoch 603/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2047 - acc: 0.9453 - val_loss: 1.2319 - val_acc: 0.5613\n",
      "Epoch 604/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2016 - acc: 0.9458 - val_loss: 1.2320 - val_acc: 0.5667\n",
      "Epoch 605/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2022 - acc: 0.9431 - val_loss: 1.2454 - val_acc: 0.5587\n",
      "Epoch 606/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1998 - acc: 0.9462 - val_loss: 1.2462 - val_acc: 0.5560\n",
      "Epoch 607/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2009 - acc: 0.9458 - val_loss: 1.2510 - val_acc: 0.5507\n",
      "Epoch 608/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1992 - acc: 0.9480 - val_loss: 1.2835 - val_acc: 0.5507\n",
      "Epoch 609/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2047 - acc: 0.9413 - val_loss: 1.2314 - val_acc: 0.5720\n",
      "Epoch 610/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2007 - acc: 0.9409 - val_loss: 1.2754 - val_acc: 0.5560\n",
      "Epoch 611/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.2033 - acc: 0.9404 - val_loss: 1.2467 - val_acc: 0.5560\n",
      "Epoch 612/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1996 - acc: 0.9471 - val_loss: 1.2471 - val_acc: 0.5667\n",
      "Epoch 613/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2060 - acc: 0.9404 - val_loss: 1.2574 - val_acc: 0.5533\n",
      "Epoch 614/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1961 - acc: 0.9511 - val_loss: 1.2520 - val_acc: 0.5560\n",
      "Epoch 615/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1977 - acc: 0.9507 - val_loss: 1.2450 - val_acc: 0.5707\n",
      "Epoch 616/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.2049 - acc: 0.9378 - val_loss: 1.2524 - val_acc: 0.5613\n",
      "Epoch 617/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1969 - acc: 0.9449 - val_loss: 1.2634 - val_acc: 0.5600\n",
      "Epoch 618/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1951 - acc: 0.9493 - val_loss: 1.2521 - val_acc: 0.5667\n",
      "Epoch 619/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1995 - acc: 0.9449 - val_loss: 1.2872 - val_acc: 0.5467\n",
      "Epoch 620/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1962 - acc: 0.9484 - val_loss: 1.2489 - val_acc: 0.5627\n",
      "Epoch 621/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1952 - acc: 0.9489 - val_loss: 1.2635 - val_acc: 0.5587\n",
      "Epoch 622/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1934 - acc: 0.9520 - val_loss: 1.2599 - val_acc: 0.5533\n",
      "Epoch 623/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1913 - acc: 0.9511 - val_loss: 1.2843 - val_acc: 0.5493\n",
      "Epoch 624/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1955 - acc: 0.9489 - val_loss: 1.2722 - val_acc: 0.5520\n",
      "Epoch 625/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1923 - acc: 0.9502 - val_loss: 1.2570 - val_acc: 0.5707\n",
      "Epoch 626/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1967 - acc: 0.9431 - val_loss: 1.2900 - val_acc: 0.5533\n",
      "Epoch 627/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1949 - acc: 0.9462 - val_loss: 1.2761 - val_acc: 0.5600\n",
      "Epoch 628/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1939 - acc: 0.9476 - val_loss: 1.2551 - val_acc: 0.5773\n",
      "Epoch 629/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.2012 - acc: 0.9413 - val_loss: 1.3087 - val_acc: 0.5520\n",
      "Epoch 630/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1902 - acc: 0.9538 - val_loss: 1.2617 - val_acc: 0.5787\n",
      "Epoch 631/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2047 - acc: 0.9400 - val_loss: 1.2729 - val_acc: 0.5533\n",
      "Epoch 632/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1937 - acc: 0.9467 - val_loss: 1.2882 - val_acc: 0.5587\n",
      "Epoch 633/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1890 - acc: 0.9511 - val_loss: 1.2600 - val_acc: 0.5720\n",
      "Epoch 634/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1915 - acc: 0.9476 - val_loss: 1.3212 - val_acc: 0.5507\n",
      "Epoch 635/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1921 - acc: 0.9529 - val_loss: 1.2634 - val_acc: 0.5680\n",
      "Epoch 636/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1919 - acc: 0.9484 - val_loss: 1.2690 - val_acc: 0.5627\n",
      "Epoch 637/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1964 - acc: 0.9427 - val_loss: 1.3595 - val_acc: 0.5520\n",
      "Epoch 638/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2029 - acc: 0.9391 - val_loss: 1.2737 - val_acc: 0.5733\n",
      "Epoch 639/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1997 - acc: 0.9409 - val_loss: 1.3110 - val_acc: 0.5533\n",
      "Epoch 640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1958 - acc: 0.9458 - val_loss: 1.2779 - val_acc: 0.5627\n",
      "Epoch 641/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.1846 - acc: 0.9520 - val_loss: 1.2850 - val_acc: 0.5613\n",
      "Epoch 642/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.1857 - acc: 0.9507 - val_loss: 1.3339 - val_acc: 0.5560\n",
      "Epoch 643/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1923 - acc: 0.9498 - val_loss: 1.2858 - val_acc: 0.5733\n",
      "Epoch 644/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.2001 - acc: 0.9444 - val_loss: 1.3644 - val_acc: 0.5493\n",
      "Epoch 645/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.2002 - acc: 0.9436 - val_loss: 1.2871 - val_acc: 0.5573\n",
      "Epoch 646/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1943 - acc: 0.9458 - val_loss: 1.2858 - val_acc: 0.5693\n",
      "Epoch 647/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1894 - acc: 0.9502 - val_loss: 1.3417 - val_acc: 0.5533\n",
      "Epoch 648/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1900 - acc: 0.9498 - val_loss: 1.2844 - val_acc: 0.5773\n",
      "Epoch 649/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1822 - acc: 0.9516 - val_loss: 1.3564 - val_acc: 0.5480\n",
      "Epoch 650/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1853 - acc: 0.9587 - val_loss: 1.2820 - val_acc: 0.5747\n",
      "Epoch 651/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1875 - acc: 0.9533 - val_loss: 1.3215 - val_acc: 0.5547\n",
      "Epoch 652/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1879 - acc: 0.9516 - val_loss: 1.3225 - val_acc: 0.5533\n",
      "Epoch 653/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1979 - acc: 0.9436 - val_loss: 1.3002 - val_acc: 0.5773\n",
      "Epoch 654/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1894 - acc: 0.9524 - val_loss: 1.3215 - val_acc: 0.5547\n",
      "Epoch 655/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1814 - acc: 0.9516 - val_loss: 1.2919 - val_acc: 0.5680\n",
      "Epoch 656/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1814 - acc: 0.9529 - val_loss: 1.3239 - val_acc: 0.5720\n",
      "Epoch 657/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.1980 - acc: 0.9404 - val_loss: 1.3678 - val_acc: 0.5533\n",
      "Epoch 658/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1906 - acc: 0.9489 - val_loss: 1.3099 - val_acc: 0.5800\n",
      "Epoch 659/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1857 - acc: 0.9489 - val_loss: 1.3069 - val_acc: 0.5600\n",
      "Epoch 660/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.1783 - acc: 0.9547 - val_loss: 1.3313 - val_acc: 0.5507\n",
      "Epoch 661/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1804 - acc: 0.9520 - val_loss: 1.3090 - val_acc: 0.5587\n",
      "Epoch 662/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1750 - acc: 0.9569 - val_loss: 1.3221 - val_acc: 0.5560\n",
      "Epoch 663/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1757 - acc: 0.9564 - val_loss: 1.3175 - val_acc: 0.5587\n",
      "Epoch 664/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1723 - acc: 0.9587 - val_loss: 1.3367 - val_acc: 0.5547\n",
      "Epoch 665/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1754 - acc: 0.9551 - val_loss: 1.3142 - val_acc: 0.5733\n",
      "Epoch 666/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1796 - acc: 0.9533 - val_loss: 1.3465 - val_acc: 0.5547\n",
      "Epoch 667/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1774 - acc: 0.9542 - val_loss: 1.3145 - val_acc: 0.5573\n",
      "Epoch 668/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1780 - acc: 0.9524 - val_loss: 1.3145 - val_acc: 0.5720\n",
      "Epoch 669/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1811 - acc: 0.9493 - val_loss: 1.3669 - val_acc: 0.5587\n",
      "Epoch 670/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.1823 - acc: 0.9516 - val_loss: 1.3254 - val_acc: 0.5600\n",
      "Epoch 671/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1787 - acc: 0.9564 - val_loss: 1.3306 - val_acc: 0.5667\n",
      "Epoch 672/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1779 - acc: 0.9511 - val_loss: 1.4030 - val_acc: 0.5493\n",
      "Epoch 673/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1899 - acc: 0.9422 - val_loss: 1.3204 - val_acc: 0.5720\n",
      "Epoch 674/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1914 - acc: 0.9347 - val_loss: 1.3233 - val_acc: 0.5640\n",
      "Epoch 675/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1891 - acc: 0.9422 - val_loss: 1.3790 - val_acc: 0.5573\n",
      "Epoch 676/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1925 - acc: 0.9431 - val_loss: 1.3237 - val_acc: 0.5747\n",
      "Epoch 677/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1810 - acc: 0.9489 - val_loss: 1.3554 - val_acc: 0.5573\n",
      "Epoch 678/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1793 - acc: 0.9511 - val_loss: 1.3611 - val_acc: 0.5587\n",
      "Epoch 679/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1829 - acc: 0.9484 - val_loss: 1.3240 - val_acc: 0.5747\n",
      "Epoch 680/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1854 - acc: 0.9427 - val_loss: 1.3994 - val_acc: 0.5560\n",
      "Epoch 681/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1811 - acc: 0.9516 - val_loss: 1.3297 - val_acc: 0.5707\n",
      "Epoch 682/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.1764 - acc: 0.9467 - val_loss: 1.3388 - val_acc: 0.5560\n",
      "Epoch 683/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1714 - acc: 0.9551 - val_loss: 1.3523 - val_acc: 0.5653\n",
      "Epoch 684/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1700 - acc: 0.9564 - val_loss: 1.3306 - val_acc: 0.5693\n",
      "Epoch 685/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1792 - acc: 0.9458 - val_loss: 1.3900 - val_acc: 0.5560\n",
      "Epoch 686/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1704 - acc: 0.9556 - val_loss: 1.3253 - val_acc: 0.5720\n",
      "Epoch 687/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1755 - acc: 0.9524 - val_loss: 1.3542 - val_acc: 0.5547\n",
      "Epoch 688/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1682 - acc: 0.9533 - val_loss: 1.3392 - val_acc: 0.5587\n",
      "Epoch 689/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1650 - acc: 0.9627 - val_loss: 1.3463 - val_acc: 0.5573\n",
      "Epoch 690/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1637 - acc: 0.9622 - val_loss: 1.3517 - val_acc: 0.5573\n",
      "Epoch 691/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1617 - acc: 0.9640 - val_loss: 1.3442 - val_acc: 0.5547\n",
      "Epoch 692/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1629 - acc: 0.9644 - val_loss: 1.3446 - val_acc: 0.5653\n",
      "Epoch 693/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1662 - acc: 0.9573 - val_loss: 1.3654 - val_acc: 0.5627\n",
      "Epoch 694/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1633 - acc: 0.9627 - val_loss: 1.3566 - val_acc: 0.5600\n",
      "Epoch 695/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1642 - acc: 0.9591 - val_loss: 1.3622 - val_acc: 0.5613\n",
      "Epoch 696/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1630 - acc: 0.9618 - val_loss: 1.3702 - val_acc: 0.5573\n",
      "Epoch 697/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1624 - acc: 0.9627 - val_loss: 1.3465 - val_acc: 0.5680\n",
      "Epoch 698/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1630 - acc: 0.9622 - val_loss: 1.3556 - val_acc: 0.5613\n",
      "Epoch 699/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1616 - acc: 0.9613 - val_loss: 1.3884 - val_acc: 0.5613\n",
      "Epoch 700/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1661 - acc: 0.9569 - val_loss: 1.3641 - val_acc: 0.5720\n",
      "Epoch 701/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1695 - acc: 0.9564 - val_loss: 1.3836 - val_acc: 0.5613\n",
      "Epoch 702/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1640 - acc: 0.9551 - val_loss: 1.3551 - val_acc: 0.5560\n",
      "Epoch 703/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1604 - acc: 0.9636 - val_loss: 1.3641 - val_acc: 0.5560\n",
      "Epoch 704/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1584 - acc: 0.9653 - val_loss: 1.3659 - val_acc: 0.5613\n",
      "Epoch 705/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1576 - acc: 0.9640 - val_loss: 1.3631 - val_acc: 0.5587\n",
      "Epoch 706/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1561 - acc: 0.9640 - val_loss: 1.3735 - val_acc: 0.5573\n",
      "Epoch 707/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1560 - acc: 0.9653 - val_loss: 1.3619 - val_acc: 0.5573\n",
      "Epoch 708/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1567 - acc: 0.9644 - val_loss: 1.3688 - val_acc: 0.5547\n",
      "Epoch 709/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1552 - acc: 0.9667 - val_loss: 1.3827 - val_acc: 0.5600\n",
      "Epoch 710/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1550 - acc: 0.9653 - val_loss: 1.3604 - val_acc: 0.5640\n",
      "Epoch 711/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1569 - acc: 0.9644 - val_loss: 1.3910 - val_acc: 0.5640\n",
      "Epoch 712/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1557 - acc: 0.9667 - val_loss: 1.3669 - val_acc: 0.5640\n",
      "Epoch 713/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1573 - acc: 0.9644 - val_loss: 1.3605 - val_acc: 0.5573\n",
      "Epoch 714/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1583 - acc: 0.9604 - val_loss: 1.4137 - val_acc: 0.5587\n",
      "Epoch 715/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1564 - acc: 0.9622 - val_loss: 1.3691 - val_acc: 0.5587\n",
      "Epoch 716/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1536 - acc: 0.9676 - val_loss: 1.3837 - val_acc: 0.5560\n",
      "Epoch 717/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1535 - acc: 0.9676 - val_loss: 1.3865 - val_acc: 0.5600\n",
      "Epoch 718/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1514 - acc: 0.9653 - val_loss: 1.3729 - val_acc: 0.5573\n",
      "Epoch 719/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1513 - acc: 0.9680 - val_loss: 1.3966 - val_acc: 0.5613\n",
      "Epoch 720/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1517 - acc: 0.9662 - val_loss: 1.3765 - val_acc: 0.5547\n",
      "Epoch 721/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1511 - acc: 0.9644 - val_loss: 1.3897 - val_acc: 0.5587\n",
      "Epoch 722/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1500 - acc: 0.9676 - val_loss: 1.3956 - val_acc: 0.5547\n",
      "Epoch 723/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1502 - acc: 0.9684 - val_loss: 1.3873 - val_acc: 0.5587\n",
      "Epoch 724/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1504 - acc: 0.9698 - val_loss: 1.3901 - val_acc: 0.5587\n",
      "Epoch 725/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1493 - acc: 0.9667 - val_loss: 1.3902 - val_acc: 0.5587\n",
      "Epoch 726/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1494 - acc: 0.9662 - val_loss: 1.3957 - val_acc: 0.5560\n",
      "Epoch 727/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1488 - acc: 0.9667 - val_loss: 1.4104 - val_acc: 0.5533\n",
      "Epoch 728/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1492 - acc: 0.9676 - val_loss: 1.3874 - val_acc: 0.5653\n",
      "Epoch 729/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1522 - acc: 0.9627 - val_loss: 1.4193 - val_acc: 0.5573\n",
      "Epoch 730/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1503 - acc: 0.9658 - val_loss: 1.3995 - val_acc: 0.5547\n",
      "Epoch 731/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1478 - acc: 0.9689 - val_loss: 1.3969 - val_acc: 0.5547\n",
      "Epoch 732/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1470 - acc: 0.9676 - val_loss: 1.4195 - val_acc: 0.5587\n",
      "Epoch 733/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1495 - acc: 0.9622 - val_loss: 1.4083 - val_acc: 0.5600\n",
      "Epoch 734/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1456 - acc: 0.9676 - val_loss: 1.4134 - val_acc: 0.5560\n",
      "Epoch 735/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1451 - acc: 0.9698 - val_loss: 1.3960 - val_acc: 0.5667\n",
      "Epoch 736/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1475 - acc: 0.9658 - val_loss: 1.4464 - val_acc: 0.5547\n",
      "Epoch 737/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1499 - acc: 0.9640 - val_loss: 1.4057 - val_acc: 0.5587\n",
      "Epoch 738/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1466 - acc: 0.9693 - val_loss: 1.4120 - val_acc: 0.5613\n",
      "Epoch 739/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1452 - acc: 0.9702 - val_loss: 1.4367 - val_acc: 0.5613\n",
      "Epoch 740/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1467 - acc: 0.9698 - val_loss: 1.4015 - val_acc: 0.5760\n",
      "Epoch 741/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1498 - acc: 0.9640 - val_loss: 1.4406 - val_acc: 0.5640\n",
      "Epoch 742/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1443 - acc: 0.9716 - val_loss: 1.4171 - val_acc: 0.5627\n",
      "Epoch 743/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1455 - acc: 0.9667 - val_loss: 1.4085 - val_acc: 0.5547\n",
      "Epoch 744/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1444 - acc: 0.9693 - val_loss: 1.4265 - val_acc: 0.5560\n",
      "Epoch 745/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1437 - acc: 0.9684 - val_loss: 1.4300 - val_acc: 0.5627\n",
      "Epoch 746/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.1430 - acc: 0.9693 - val_loss: 1.4218 - val_acc: 0.5547\n",
      "Epoch 747/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1426 - acc: 0.9707 - val_loss: 1.4410 - val_acc: 0.5600\n",
      "Epoch 748/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1410 - acc: 0.9707 - val_loss: 1.4077 - val_acc: 0.5640\n",
      "Epoch 749/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1427 - acc: 0.9684 - val_loss: 1.4356 - val_acc: 0.5613\n",
      "Epoch 750/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1392 - acc: 0.9716 - val_loss: 1.4168 - val_acc: 0.5747\n",
      "Epoch 751/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1477 - acc: 0.9644 - val_loss: 1.4266 - val_acc: 0.5627\n",
      "Epoch 752/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1522 - acc: 0.9578 - val_loss: 1.4911 - val_acc: 0.5587\n",
      "Epoch 753/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1516 - acc: 0.9604 - val_loss: 1.4222 - val_acc: 0.5693\n",
      "Epoch 754/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1485 - acc: 0.9618 - val_loss: 1.4233 - val_acc: 0.5667\n",
      "Epoch 755/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1469 - acc: 0.9649 - val_loss: 1.4405 - val_acc: 0.5613\n",
      "Epoch 756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1372 - acc: 0.9720 - val_loss: 1.4216 - val_acc: 0.5707\n",
      "Epoch 757/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1392 - acc: 0.9711 - val_loss: 1.4749 - val_acc: 0.5600\n",
      "Epoch 758/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1410 - acc: 0.9738 - val_loss: 1.4304 - val_acc: 0.5680\n",
      "Epoch 759/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1428 - acc: 0.9627 - val_loss: 1.4348 - val_acc: 0.5613\n",
      "Epoch 760/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1415 - acc: 0.9671 - val_loss: 1.4927 - val_acc: 0.5573\n",
      "Epoch 761/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1485 - acc: 0.9609 - val_loss: 1.4208 - val_acc: 0.5707\n",
      "Epoch 762/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1426 - acc: 0.9658 - val_loss: 1.4606 - val_acc: 0.5613\n",
      "Epoch 763/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1431 - acc: 0.9662 - val_loss: 1.4724 - val_acc: 0.5613\n",
      "Epoch 764/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1426 - acc: 0.9676 - val_loss: 1.4339 - val_acc: 0.5760\n",
      "Epoch 765/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1411 - acc: 0.9671 - val_loss: 1.4832 - val_acc: 0.5547\n",
      "Epoch 766/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1390 - acc: 0.9680 - val_loss: 1.4491 - val_acc: 0.5627\n",
      "Epoch 767/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1379 - acc: 0.9698 - val_loss: 1.4387 - val_acc: 0.5760\n",
      "Epoch 768/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1437 - acc: 0.9631 - val_loss: 1.4835 - val_acc: 0.5600\n",
      "Epoch 769/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1353 - acc: 0.9747 - val_loss: 1.4420 - val_acc: 0.5733\n",
      "Epoch 770/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1382 - acc: 0.9689 - val_loss: 1.4791 - val_acc: 0.5627\n",
      "Epoch 771/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1344 - acc: 0.9729 - val_loss: 1.4443 - val_acc: 0.5653\n",
      "Epoch 772/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1332 - acc: 0.9764 - val_loss: 1.4605 - val_acc: 0.5600\n",
      "Epoch 773/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1365 - acc: 0.9693 - val_loss: 1.4867 - val_acc: 0.5600\n",
      "Epoch 774/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1353 - acc: 0.9720 - val_loss: 1.4474 - val_acc: 0.5773\n",
      "Epoch 775/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1374 - acc: 0.9693 - val_loss: 1.4946 - val_acc: 0.5587\n",
      "Epoch 776/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1353 - acc: 0.9693 - val_loss: 1.4578 - val_acc: 0.5627\n",
      "Epoch 777/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1355 - acc: 0.9720 - val_loss: 1.4642 - val_acc: 0.5667\n",
      "Epoch 778/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1411 - acc: 0.9640 - val_loss: 1.5143 - val_acc: 0.5600\n",
      "Epoch 779/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1400 - acc: 0.9653 - val_loss: 1.4569 - val_acc: 0.5720\n",
      "Epoch 780/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1444 - acc: 0.9600 - val_loss: 1.4702 - val_acc: 0.5587\n",
      "Epoch 781/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1372 - acc: 0.9658 - val_loss: 1.4767 - val_acc: 0.5653\n",
      "Epoch 782/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1321 - acc: 0.9724 - val_loss: 1.4768 - val_acc: 0.5613\n",
      "Epoch 783/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1377 - acc: 0.9671 - val_loss: 1.4895 - val_acc: 0.5613\n",
      "Epoch 784/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1370 - acc: 0.9707 - val_loss: 1.5077 - val_acc: 0.5587\n",
      "Epoch 785/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1407 - acc: 0.9618 - val_loss: 1.4604 - val_acc: 0.5747\n",
      "Epoch 786/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1347 - acc: 0.9676 - val_loss: 1.4985 - val_acc: 0.5613\n",
      "Epoch 787/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1369 - acc: 0.9698 - val_loss: 1.4973 - val_acc: 0.5587\n",
      "Epoch 788/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1291 - acc: 0.9742 - val_loss: 1.4652 - val_acc: 0.5640\n",
      "Epoch 789/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1268 - acc: 0.9760 - val_loss: 1.4668 - val_acc: 0.5707\n",
      "Epoch 790/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1345 - acc: 0.9680 - val_loss: 1.4901 - val_acc: 0.5600\n",
      "Epoch 791/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1276 - acc: 0.9747 - val_loss: 1.4874 - val_acc: 0.5613\n",
      "Epoch 792/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1274 - acc: 0.9751 - val_loss: 1.4786 - val_acc: 0.5653\n",
      "Epoch 793/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1274 - acc: 0.9751 - val_loss: 1.4989 - val_acc: 0.5560\n",
      "Epoch 794/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1276 - acc: 0.9742 - val_loss: 1.4802 - val_acc: 0.5573\n",
      "Epoch 795/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1259 - acc: 0.9756 - val_loss: 1.4791 - val_acc: 0.5667\n",
      "Epoch 796/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1315 - acc: 0.9707 - val_loss: 1.5250 - val_acc: 0.5587\n",
      "Epoch 797/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1329 - acc: 0.9711 - val_loss: 1.4944 - val_acc: 0.5640\n",
      "Epoch 798/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1274 - acc: 0.9747 - val_loss: 1.4864 - val_acc: 0.5640\n",
      "Epoch 799/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1245 - acc: 0.9764 - val_loss: 1.5067 - val_acc: 0.5653\n",
      "Epoch 800/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1270 - acc: 0.9733 - val_loss: 1.5070 - val_acc: 0.5693\n",
      "Epoch 801/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1288 - acc: 0.9747 - val_loss: 1.5039 - val_acc: 0.5600\n",
      "Epoch 802/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1272 - acc: 0.9760 - val_loss: 1.4982 - val_acc: 0.5640\n",
      "Epoch 803/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1231 - acc: 0.9760 - val_loss: 1.4885 - val_acc: 0.5627\n",
      "Epoch 804/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1231 - acc: 0.9764 - val_loss: 1.4889 - val_acc: 0.5627\n",
      "Epoch 805/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1237 - acc: 0.9756 - val_loss: 1.5046 - val_acc: 0.5667\n",
      "Epoch 806/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1243 - acc: 0.9751 - val_loss: 1.4975 - val_acc: 0.5640\n",
      "Epoch 807/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1213 - acc: 0.9782 - val_loss: 1.4983 - val_acc: 0.5627\n",
      "Epoch 808/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1203 - acc: 0.9787 - val_loss: 1.5016 - val_acc: 0.5653\n",
      "Epoch 809/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1206 - acc: 0.9809 - val_loss: 1.5259 - val_acc: 0.5600\n",
      "Epoch 810/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1237 - acc: 0.9738 - val_loss: 1.5002 - val_acc: 0.5587\n",
      "Epoch 811/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1207 - acc: 0.9782 - val_loss: 1.5178 - val_acc: 0.5600\n",
      "Epoch 812/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1236 - acc: 0.9742 - val_loss: 1.5413 - val_acc: 0.5600\n",
      "Epoch 813/2000\n",
      "2250/2250 [==============================] - 1s 326us/step - loss: 0.1231 - acc: 0.9769 - val_loss: 1.4882 - val_acc: 0.5720\n",
      "Epoch 814/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1249 - acc: 0.9747 - val_loss: 1.5294 - val_acc: 0.5600\n",
      "Epoch 815/2000\n",
      "2250/2250 [==============================] - 1s 314us/step - loss: 0.1212 - acc: 0.9764 - val_loss: 1.5154 - val_acc: 0.5600\n",
      "Epoch 816/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.1183 - acc: 0.9782 - val_loss: 1.4984 - val_acc: 0.5667\n",
      "Epoch 817/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1205 - acc: 0.9764 - val_loss: 1.5418 - val_acc: 0.5613\n",
      "Epoch 818/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1193 - acc: 0.9791 - val_loss: 1.4998 - val_acc: 0.5720\n",
      "Epoch 819/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1227 - acc: 0.9769 - val_loss: 1.5115 - val_acc: 0.5613\n",
      "Epoch 820/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1250 - acc: 0.9693 - val_loss: 1.5547 - val_acc: 0.5627\n",
      "Epoch 821/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1232 - acc: 0.9751 - val_loss: 1.5151 - val_acc: 0.5653\n",
      "Epoch 822/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1221 - acc: 0.9756 - val_loss: 1.5277 - val_acc: 0.5600\n",
      "Epoch 823/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1165 - acc: 0.9764 - val_loss: 1.5138 - val_acc: 0.5600\n",
      "Epoch 824/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.1159 - acc: 0.9804 - val_loss: 1.5351 - val_acc: 0.5613\n",
      "Epoch 825/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1157 - acc: 0.9787 - val_loss: 1.5370 - val_acc: 0.5640\n",
      "Epoch 826/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1169 - acc: 0.9787 - val_loss: 1.5096 - val_acc: 0.5653\n",
      "Epoch 827/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1165 - acc: 0.9778 - val_loss: 1.5286 - val_acc: 0.5667\n",
      "Epoch 828/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1144 - acc: 0.9818 - val_loss: 1.5486 - val_acc: 0.5613\n",
      "Epoch 829/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1167 - acc: 0.9796 - val_loss: 1.5262 - val_acc: 0.5653\n",
      "Epoch 830/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1150 - acc: 0.9773 - val_loss: 1.5219 - val_acc: 0.5667\n",
      "Epoch 831/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1149 - acc: 0.9791 - val_loss: 1.5256 - val_acc: 0.5640\n",
      "Epoch 832/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1130 - acc: 0.9822 - val_loss: 1.5422 - val_acc: 0.5653\n",
      "Epoch 833/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.1135 - acc: 0.9813 - val_loss: 1.5321 - val_acc: 0.5613\n",
      "Epoch 834/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1124 - acc: 0.9827 - val_loss: 1.5353 - val_acc: 0.5667\n",
      "Epoch 835/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1121 - acc: 0.9804 - val_loss: 1.5387 - val_acc: 0.5680\n",
      "Epoch 836/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1114 - acc: 0.9822 - val_loss: 1.5388 - val_acc: 0.5640\n",
      "Epoch 837/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1117 - acc: 0.9822 - val_loss: 1.5399 - val_acc: 0.5653\n",
      "Epoch 838/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1111 - acc: 0.9822 - val_loss: 1.5348 - val_acc: 0.5667\n",
      "Epoch 839/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1119 - acc: 0.9796 - val_loss: 1.5475 - val_acc: 0.5627\n",
      "Epoch 840/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1115 - acc: 0.9822 - val_loss: 1.5430 - val_acc: 0.5667\n",
      "Epoch 841/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1103 - acc: 0.9827 - val_loss: 1.5449 - val_acc: 0.5667\n",
      "Epoch 842/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1102 - acc: 0.9827 - val_loss: 1.5514 - val_acc: 0.5600\n",
      "Epoch 843/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1104 - acc: 0.9827 - val_loss: 1.5757 - val_acc: 0.5573\n",
      "Epoch 844/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1107 - acc: 0.9804 - val_loss: 1.5323 - val_acc: 0.5707\n",
      "Epoch 845/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1130 - acc: 0.9782 - val_loss: 1.5663 - val_acc: 0.5587\n",
      "Epoch 846/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1091 - acc: 0.9822 - val_loss: 1.5600 - val_acc: 0.5627\n",
      "Epoch 847/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1085 - acc: 0.9840 - val_loss: 1.5623 - val_acc: 0.5613\n",
      "Epoch 848/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1084 - acc: 0.9818 - val_loss: 1.5598 - val_acc: 0.5600\n",
      "Epoch 849/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1086 - acc: 0.9822 - val_loss: 1.5513 - val_acc: 0.5627\n",
      "Epoch 850/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1094 - acc: 0.9822 - val_loss: 1.6079 - val_acc: 0.5600\n",
      "Epoch 851/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1150 - acc: 0.9782 - val_loss: 1.5601 - val_acc: 0.5640\n",
      "Epoch 852/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1166 - acc: 0.9756 - val_loss: 1.5555 - val_acc: 0.5667\n",
      "Epoch 853/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1138 - acc: 0.9787 - val_loss: 1.5897 - val_acc: 0.5573\n",
      "Epoch 854/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1094 - acc: 0.9800 - val_loss: 1.5565 - val_acc: 0.5560\n",
      "Epoch 855/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1093 - acc: 0.9800 - val_loss: 1.5665 - val_acc: 0.5653\n",
      "Epoch 856/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1097 - acc: 0.9800 - val_loss: 1.6048 - val_acc: 0.5560\n",
      "Epoch 857/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1118 - acc: 0.9782 - val_loss: 1.5632 - val_acc: 0.5640\n",
      "Epoch 858/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1063 - acc: 0.9822 - val_loss: 1.5621 - val_acc: 0.5640\n",
      "Epoch 859/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1104 - acc: 0.9809 - val_loss: 1.5749 - val_acc: 0.5640\n",
      "Epoch 860/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1080 - acc: 0.9813 - val_loss: 1.5931 - val_acc: 0.5600\n",
      "Epoch 861/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1068 - acc: 0.9840 - val_loss: 1.5860 - val_acc: 0.5640\n",
      "Epoch 862/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1051 - acc: 0.9840 - val_loss: 1.5590 - val_acc: 0.5613\n",
      "Epoch 863/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1056 - acc: 0.9858 - val_loss: 1.5902 - val_acc: 0.5653\n",
      "Epoch 864/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1033 - acc: 0.9840 - val_loss: 1.5656 - val_acc: 0.5653\n",
      "Epoch 865/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.1030 - acc: 0.9822 - val_loss: 1.5891 - val_acc: 0.5667\n",
      "Epoch 866/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1045 - acc: 0.9849 - val_loss: 1.5704 - val_acc: 0.5680\n",
      "Epoch 867/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1031 - acc: 0.9844 - val_loss: 1.5881 - val_acc: 0.5627\n",
      "Epoch 868/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1029 - acc: 0.9853 - val_loss: 1.5944 - val_acc: 0.5627\n",
      "Epoch 869/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.1047 - acc: 0.9836 - val_loss: 1.5842 - val_acc: 0.5680\n",
      "Epoch 870/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1018 - acc: 0.9849 - val_loss: 1.5764 - val_acc: 0.5640\n",
      "Epoch 871/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1030 - acc: 0.9858 - val_loss: 1.6395 - val_acc: 0.5600\n",
      "Epoch 872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1107 - acc: 0.9764 - val_loss: 1.5768 - val_acc: 0.5680\n",
      "Epoch 873/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1038 - acc: 0.9822 - val_loss: 1.5876 - val_acc: 0.5600\n",
      "Epoch 874/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1044 - acc: 0.9836 - val_loss: 1.6325 - val_acc: 0.5600\n",
      "Epoch 875/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1068 - acc: 0.9804 - val_loss: 1.5800 - val_acc: 0.5653\n",
      "Epoch 876/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1039 - acc: 0.9858 - val_loss: 1.5966 - val_acc: 0.5640\n",
      "Epoch 877/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1012 - acc: 0.9867 - val_loss: 1.5959 - val_acc: 0.5680\n",
      "Epoch 878/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0996 - acc: 0.9844 - val_loss: 1.5960 - val_acc: 0.5667\n",
      "Epoch 879/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0998 - acc: 0.9849 - val_loss: 1.5996 - val_acc: 0.5667\n",
      "Epoch 880/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0993 - acc: 0.9840 - val_loss: 1.5953 - val_acc: 0.5667\n",
      "Epoch 881/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0994 - acc: 0.9844 - val_loss: 1.5922 - val_acc: 0.5627\n",
      "Epoch 882/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1003 - acc: 0.9840 - val_loss: 1.5957 - val_acc: 0.5667\n",
      "Epoch 883/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0987 - acc: 0.9858 - val_loss: 1.6289 - val_acc: 0.5560\n",
      "Epoch 884/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0993 - acc: 0.9858 - val_loss: 1.6060 - val_acc: 0.5640\n",
      "Epoch 885/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0991 - acc: 0.9858 - val_loss: 1.5997 - val_acc: 0.5653\n",
      "Epoch 886/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0982 - acc: 0.9853 - val_loss: 1.6216 - val_acc: 0.5627\n",
      "Epoch 887/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0974 - acc: 0.9867 - val_loss: 1.6146 - val_acc: 0.5600\n",
      "Epoch 888/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0979 - acc: 0.9858 - val_loss: 1.6136 - val_acc: 0.5653\n",
      "Epoch 889/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0973 - acc: 0.9862 - val_loss: 1.6179 - val_acc: 0.5627\n",
      "Epoch 890/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0965 - acc: 0.9862 - val_loss: 1.6111 - val_acc: 0.5653\n",
      "Epoch 891/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0962 - acc: 0.9876 - val_loss: 1.6195 - val_acc: 0.5627\n",
      "Epoch 892/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0957 - acc: 0.9876 - val_loss: 1.6328 - val_acc: 0.5600\n",
      "Epoch 893/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0969 - acc: 0.9867 - val_loss: 1.6260 - val_acc: 0.5600\n",
      "Epoch 894/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0962 - acc: 0.9867 - val_loss: 1.6048 - val_acc: 0.5627\n",
      "Epoch 895/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0961 - acc: 0.9853 - val_loss: 1.6439 - val_acc: 0.5627\n",
      "Epoch 896/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0977 - acc: 0.9867 - val_loss: 1.6293 - val_acc: 0.5640\n",
      "Epoch 897/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0947 - acc: 0.9876 - val_loss: 1.6147 - val_acc: 0.5587\n",
      "Epoch 898/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0961 - acc: 0.9858 - val_loss: 1.6274 - val_acc: 0.5640\n",
      "Epoch 899/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0950 - acc: 0.9867 - val_loss: 1.6313 - val_acc: 0.5653\n",
      "Epoch 900/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0939 - acc: 0.9871 - val_loss: 1.6135 - val_acc: 0.5640\n",
      "Epoch 901/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0968 - acc: 0.9871 - val_loss: 1.6210 - val_acc: 0.5653\n",
      "Epoch 902/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0964 - acc: 0.9862 - val_loss: 1.6254 - val_acc: 0.5613\n",
      "Epoch 903/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0944 - acc: 0.9880 - val_loss: 1.6351 - val_acc: 0.5613\n",
      "Epoch 904/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0950 - acc: 0.9862 - val_loss: 1.7413 - val_acc: 0.5480\n",
      "Epoch 905/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1163 - acc: 0.9676 - val_loss: 1.6178 - val_acc: 0.5613\n",
      "Epoch 906/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1071 - acc: 0.9747 - val_loss: 1.6295 - val_acc: 0.5613\n",
      "Epoch 907/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1110 - acc: 0.9707 - val_loss: 1.7239 - val_acc: 0.5493\n",
      "Epoch 908/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1135 - acc: 0.9698 - val_loss: 1.6749 - val_acc: 0.5587\n",
      "Epoch 909/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.1153 - acc: 0.9707 - val_loss: 1.6492 - val_acc: 0.5613\n",
      "Epoch 910/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1150 - acc: 0.9693 - val_loss: 1.6705 - val_acc: 0.5640\n",
      "Epoch 911/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.1041 - acc: 0.9769 - val_loss: 1.6855 - val_acc: 0.5613\n",
      "Epoch 912/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1084 - acc: 0.9751 - val_loss: 1.6381 - val_acc: 0.5627\n",
      "Epoch 913/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1070 - acc: 0.9764 - val_loss: 1.6900 - val_acc: 0.5600\n",
      "Epoch 914/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.1053 - acc: 0.9764 - val_loss: 1.6652 - val_acc: 0.5600\n",
      "Epoch 915/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.1006 - acc: 0.9818 - val_loss: 1.6314 - val_acc: 0.5613\n",
      "Epoch 916/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.1015 - acc: 0.9787 - val_loss: 1.7119 - val_acc: 0.5533\n",
      "Epoch 917/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0982 - acc: 0.9840 - val_loss: 1.6339 - val_acc: 0.5680\n",
      "Epoch 918/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0969 - acc: 0.9831 - val_loss: 1.6386 - val_acc: 0.5600\n",
      "Epoch 919/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.0933 - acc: 0.9862 - val_loss: 1.6861 - val_acc: 0.5533\n",
      "Epoch 920/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0912 - acc: 0.9884 - val_loss: 1.6468 - val_acc: 0.5720\n",
      "Epoch 921/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0896 - acc: 0.9880 - val_loss: 1.6447 - val_acc: 0.5613\n",
      "Epoch 922/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0941 - acc: 0.9840 - val_loss: 1.7151 - val_acc: 0.5587\n",
      "Epoch 923/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0961 - acc: 0.9813 - val_loss: 1.6481 - val_acc: 0.5733\n",
      "Epoch 924/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0891 - acc: 0.9893 - val_loss: 1.6610 - val_acc: 0.5680\n",
      "Epoch 925/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0884 - acc: 0.9880 - val_loss: 1.6662 - val_acc: 0.5627\n",
      "Epoch 926/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0868 - acc: 0.9889 - val_loss: 1.6567 - val_acc: 0.5693\n",
      "Epoch 927/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0864 - acc: 0.9898 - val_loss: 1.6593 - val_acc: 0.5640\n",
      "Epoch 928/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0868 - acc: 0.9902 - val_loss: 1.6707 - val_acc: 0.5653\n",
      "Epoch 929/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0861 - acc: 0.9902 - val_loss: 1.6677 - val_acc: 0.5680\n",
      "Epoch 930/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0872 - acc: 0.9902 - val_loss: 1.6592 - val_acc: 0.5693\n",
      "Epoch 931/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0854 - acc: 0.9907 - val_loss: 1.6758 - val_acc: 0.5640\n",
      "Epoch 932/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0856 - acc: 0.9907 - val_loss: 1.6703 - val_acc: 0.5667\n",
      "Epoch 933/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0852 - acc: 0.9898 - val_loss: 1.6774 - val_acc: 0.5627\n",
      "Epoch 934/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0861 - acc: 0.9884 - val_loss: 1.6870 - val_acc: 0.5560\n",
      "Epoch 935/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0850 - acc: 0.9920 - val_loss: 1.6582 - val_acc: 0.5627\n",
      "Epoch 936/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0856 - acc: 0.9920 - val_loss: 1.6965 - val_acc: 0.5587\n",
      "Epoch 937/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0864 - acc: 0.9898 - val_loss: 1.6918 - val_acc: 0.5587\n",
      "Epoch 938/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0853 - acc: 0.9902 - val_loss: 1.6666 - val_acc: 0.5653\n",
      "Epoch 939/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0845 - acc: 0.9916 - val_loss: 1.6757 - val_acc: 0.5667\n",
      "Epoch 940/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0847 - acc: 0.9911 - val_loss: 1.6740 - val_acc: 0.5653\n",
      "Epoch 941/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0842 - acc: 0.9902 - val_loss: 1.6918 - val_acc: 0.5600\n",
      "Epoch 942/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0828 - acc: 0.9916 - val_loss: 1.6697 - val_acc: 0.5640\n",
      "Epoch 943/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0856 - acc: 0.9924 - val_loss: 1.6846 - val_acc: 0.5640\n",
      "Epoch 944/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0861 - acc: 0.9902 - val_loss: 1.7382 - val_acc: 0.5587\n",
      "Epoch 945/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0889 - acc: 0.9880 - val_loss: 1.6701 - val_acc: 0.5613\n",
      "Epoch 946/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0868 - acc: 0.9862 - val_loss: 1.6901 - val_acc: 0.5627\n",
      "Epoch 947/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0873 - acc: 0.9876 - val_loss: 1.6991 - val_acc: 0.5587\n",
      "Epoch 948/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0816 - acc: 0.9929 - val_loss: 1.6822 - val_acc: 0.5680\n",
      "Epoch 949/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0814 - acc: 0.9920 - val_loss: 1.6960 - val_acc: 0.5573\n",
      "Epoch 950/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0807 - acc: 0.9933 - val_loss: 1.6853 - val_acc: 0.5680\n",
      "Epoch 951/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0831 - acc: 0.9902 - val_loss: 1.6978 - val_acc: 0.5613\n",
      "Epoch 952/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0853 - acc: 0.9884 - val_loss: 1.7116 - val_acc: 0.5600\n",
      "Epoch 953/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0826 - acc: 0.9924 - val_loss: 1.7029 - val_acc: 0.5600\n",
      "Epoch 954/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0818 - acc: 0.9920 - val_loss: 1.6797 - val_acc: 0.5627\n",
      "Epoch 955/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0842 - acc: 0.9876 - val_loss: 1.7057 - val_acc: 0.5613\n",
      "Epoch 956/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0807 - acc: 0.9929 - val_loss: 1.7071 - val_acc: 0.5640\n",
      "Epoch 957/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0802 - acc: 0.9924 - val_loss: 1.6949 - val_acc: 0.5667\n",
      "Epoch 958/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0791 - acc: 0.9916 - val_loss: 1.7265 - val_acc: 0.5600\n",
      "Epoch 959/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0817 - acc: 0.9907 - val_loss: 1.7128 - val_acc: 0.5560\n",
      "Epoch 960/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0788 - acc: 0.9933 - val_loss: 1.7084 - val_acc: 0.5600\n",
      "Epoch 961/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0782 - acc: 0.9929 - val_loss: 1.6939 - val_acc: 0.5653\n",
      "Epoch 962/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0796 - acc: 0.9920 - val_loss: 1.7135 - val_acc: 0.5587\n",
      "Epoch 963/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0785 - acc: 0.9929 - val_loss: 1.7278 - val_acc: 0.5547\n",
      "Epoch 964/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0789 - acc: 0.9929 - val_loss: 1.6933 - val_acc: 0.5627\n",
      "Epoch 965/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0798 - acc: 0.9916 - val_loss: 1.7141 - val_acc: 0.5640\n",
      "Epoch 966/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0788 - acc: 0.9916 - val_loss: 1.7309 - val_acc: 0.5573\n",
      "Epoch 967/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0777 - acc: 0.9942 - val_loss: 1.7034 - val_acc: 0.5627\n",
      "Epoch 968/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0799 - acc: 0.9907 - val_loss: 1.7063 - val_acc: 0.5613\n",
      "Epoch 969/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0829 - acc: 0.9880 - val_loss: 1.8023 - val_acc: 0.5533\n",
      "Epoch 970/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0893 - acc: 0.9867 - val_loss: 1.7102 - val_acc: 0.5587\n",
      "Epoch 971/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0925 - acc: 0.9831 - val_loss: 1.7017 - val_acc: 0.5627\n",
      "Epoch 972/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0885 - acc: 0.9858 - val_loss: 1.7855 - val_acc: 0.5600\n",
      "Epoch 973/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0829 - acc: 0.9889 - val_loss: 1.7088 - val_acc: 0.5640\n",
      "Epoch 974/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0785 - acc: 0.9933 - val_loss: 1.7495 - val_acc: 0.5600\n",
      "Epoch 975/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0801 - acc: 0.9907 - val_loss: 1.7380 - val_acc: 0.5573\n",
      "Epoch 976/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0767 - acc: 0.9929 - val_loss: 1.7194 - val_acc: 0.5627\n",
      "Epoch 977/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0775 - acc: 0.9920 - val_loss: 1.7461 - val_acc: 0.5600\n",
      "Epoch 978/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0772 - acc: 0.9924 - val_loss: 1.7344 - val_acc: 0.5653\n",
      "Epoch 979/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0755 - acc: 0.9933 - val_loss: 1.7248 - val_acc: 0.5653\n",
      "Epoch 980/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0753 - acc: 0.9933 - val_loss: 1.7290 - val_acc: 0.5667\n",
      "Epoch 981/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0748 - acc: 0.9938 - val_loss: 1.7586 - val_acc: 0.5613\n",
      "Epoch 982/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0757 - acc: 0.9920 - val_loss: 1.7326 - val_acc: 0.5640\n",
      "Epoch 983/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0747 - acc: 0.9924 - val_loss: 1.7276 - val_acc: 0.5667\n",
      "Epoch 984/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0754 - acc: 0.9920 - val_loss: 1.7603 - val_acc: 0.5613\n",
      "Epoch 985/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0747 - acc: 0.9929 - val_loss: 1.7501 - val_acc: 0.5667\n",
      "Epoch 986/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.0746 - acc: 0.9933 - val_loss: 1.7366 - val_acc: 0.5653\n",
      "Epoch 987/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0728 - acc: 0.9947 - val_loss: 1.7399 - val_acc: 0.5667\n",
      "Epoch 988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.0731 - acc: 0.9938 - val_loss: 1.7522 - val_acc: 0.5640\n",
      "Epoch 989/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0723 - acc: 0.9942 - val_loss: 1.7493 - val_acc: 0.5653\n",
      "Epoch 990/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0724 - acc: 0.9942 - val_loss: 1.7467 - val_acc: 0.5640\n",
      "Epoch 991/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0721 - acc: 0.9947 - val_loss: 1.7499 - val_acc: 0.5640\n",
      "Epoch 992/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0723 - acc: 0.9942 - val_loss: 1.7570 - val_acc: 0.5667\n",
      "Epoch 993/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0716 - acc: 0.9938 - val_loss: 1.7448 - val_acc: 0.5667\n",
      "Epoch 994/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0716 - acc: 0.9947 - val_loss: 1.7565 - val_acc: 0.5640\n",
      "Epoch 995/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0713 - acc: 0.9951 - val_loss: 1.7743 - val_acc: 0.5573\n",
      "Epoch 996/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0729 - acc: 0.9951 - val_loss: 1.7478 - val_acc: 0.5640\n",
      "Epoch 997/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0718 - acc: 0.9942 - val_loss: 1.7547 - val_acc: 0.5640\n",
      "Epoch 998/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0703 - acc: 0.9947 - val_loss: 1.7532 - val_acc: 0.5640\n",
      "Epoch 999/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0706 - acc: 0.9938 - val_loss: 1.7827 - val_acc: 0.5587\n",
      "Epoch 1000/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0721 - acc: 0.9933 - val_loss: 1.7757 - val_acc: 0.5613\n",
      "Epoch 1001/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0742 - acc: 0.9938 - val_loss: 1.7543 - val_acc: 0.5627\n",
      "Epoch 1002/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0755 - acc: 0.9911 - val_loss: 1.7784 - val_acc: 0.5600\n",
      "Epoch 1003/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0737 - acc: 0.9916 - val_loss: 1.7786 - val_acc: 0.5600\n",
      "Epoch 1004/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0715 - acc: 0.9956 - val_loss: 1.7594 - val_acc: 0.5640\n",
      "Epoch 1005/2000\n",
      "2250/2250 [==============================] - 1s 317us/step - loss: 0.0746 - acc: 0.9933 - val_loss: 1.7575 - val_acc: 0.5667\n",
      "Epoch 1006/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0706 - acc: 0.9942 - val_loss: 1.7958 - val_acc: 0.5627\n",
      "Epoch 1007/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0703 - acc: 0.9956 - val_loss: 1.7595 - val_acc: 0.5627\n",
      "Epoch 1008/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0759 - acc: 0.9924 - val_loss: 1.7630 - val_acc: 0.5653\n",
      "Epoch 1009/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0707 - acc: 0.9920 - val_loss: 1.7940 - val_acc: 0.5560\n",
      "Epoch 1010/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0697 - acc: 0.9964 - val_loss: 1.7850 - val_acc: 0.5600\n",
      "Epoch 1011/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0693 - acc: 0.9956 - val_loss: 1.7664 - val_acc: 0.5627\n",
      "Epoch 1012/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0689 - acc: 0.9938 - val_loss: 1.7869 - val_acc: 0.5600\n",
      "Epoch 1013/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0673 - acc: 0.9951 - val_loss: 1.7735 - val_acc: 0.5627\n",
      "Epoch 1014/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0686 - acc: 0.9960 - val_loss: 1.7712 - val_acc: 0.5573\n",
      "Epoch 1015/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0697 - acc: 0.9938 - val_loss: 1.7986 - val_acc: 0.5573\n",
      "Epoch 1016/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0671 - acc: 0.9951 - val_loss: 1.7726 - val_acc: 0.5573\n",
      "Epoch 1017/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0730 - acc: 0.9916 - val_loss: 1.7746 - val_acc: 0.5653\n",
      "Epoch 1018/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0700 - acc: 0.9929 - val_loss: 1.7928 - val_acc: 0.5627\n",
      "Epoch 1019/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0676 - acc: 0.9942 - val_loss: 1.8142 - val_acc: 0.5560\n",
      "Epoch 1020/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0673 - acc: 0.9947 - val_loss: 1.7816 - val_acc: 0.5587\n",
      "Epoch 1021/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0697 - acc: 0.9933 - val_loss: 1.7756 - val_acc: 0.5600\n",
      "Epoch 1022/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0773 - acc: 0.9880 - val_loss: 1.8415 - val_acc: 0.5613\n",
      "Epoch 1023/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0727 - acc: 0.9933 - val_loss: 1.8285 - val_acc: 0.5627\n",
      "Epoch 1024/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0741 - acc: 0.9924 - val_loss: 1.7746 - val_acc: 0.5613\n",
      "Epoch 1025/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0729 - acc: 0.9907 - val_loss: 1.7893 - val_acc: 0.5667\n",
      "Epoch 1026/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0683 - acc: 0.9942 - val_loss: 1.8174 - val_acc: 0.5573\n",
      "Epoch 1027/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0652 - acc: 0.9960 - val_loss: 1.7957 - val_acc: 0.5640\n",
      "Epoch 1028/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0645 - acc: 0.9956 - val_loss: 1.8231 - val_acc: 0.5560\n",
      "Epoch 1029/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0656 - acc: 0.9960 - val_loss: 1.8100 - val_acc: 0.5667\n",
      "Epoch 1030/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0643 - acc: 0.9960 - val_loss: 1.7997 - val_acc: 0.5653\n",
      "Epoch 1031/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0646 - acc: 0.9964 - val_loss: 1.7994 - val_acc: 0.5653\n",
      "Epoch 1032/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0643 - acc: 0.9956 - val_loss: 1.8076 - val_acc: 0.5640\n",
      "Epoch 1033/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0651 - acc: 0.9956 - val_loss: 1.7949 - val_acc: 0.5653\n",
      "Epoch 1034/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0647 - acc: 0.9964 - val_loss: 1.8654 - val_acc: 0.5587\n",
      "Epoch 1035/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0697 - acc: 0.9942 - val_loss: 1.8009 - val_acc: 0.5653\n",
      "Epoch 1036/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0689 - acc: 0.9916 - val_loss: 1.8190 - val_acc: 0.5600\n",
      "Epoch 1037/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0663 - acc: 0.9956 - val_loss: 1.8586 - val_acc: 0.5653\n",
      "Epoch 1038/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0751 - acc: 0.9924 - val_loss: 1.7995 - val_acc: 0.5613\n",
      "Epoch 1039/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0778 - acc: 0.9884 - val_loss: 1.8119 - val_acc: 0.5640\n",
      "Epoch 1040/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0687 - acc: 0.9911 - val_loss: 1.8661 - val_acc: 0.5573\n",
      "Epoch 1041/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0681 - acc: 0.9947 - val_loss: 1.8058 - val_acc: 0.5653\n",
      "Epoch 1042/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0627 - acc: 0.9978 - val_loss: 1.8233 - val_acc: 0.5627\n",
      "Epoch 1043/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0623 - acc: 0.9956 - val_loss: 1.8379 - val_acc: 0.5600\n",
      "Epoch 1044/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0618 - acc: 0.9960 - val_loss: 1.8120 - val_acc: 0.5653\n",
      "Epoch 1045/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0620 - acc: 0.9964 - val_loss: 1.8276 - val_acc: 0.5627\n",
      "Epoch 1046/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0612 - acc: 0.9964 - val_loss: 1.8318 - val_acc: 0.5600\n",
      "Epoch 1047/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0617 - acc: 0.9964 - val_loss: 1.8333 - val_acc: 0.5600\n",
      "Epoch 1048/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0606 - acc: 0.9964 - val_loss: 1.8197 - val_acc: 0.5680\n",
      "Epoch 1049/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0609 - acc: 0.9969 - val_loss: 1.8297 - val_acc: 0.5653\n",
      "Epoch 1050/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0609 - acc: 0.9973 - val_loss: 1.8492 - val_acc: 0.5560\n",
      "Epoch 1051/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0614 - acc: 0.9969 - val_loss: 1.8342 - val_acc: 0.5640\n",
      "Epoch 1052/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0600 - acc: 0.9973 - val_loss: 1.8560 - val_acc: 0.5613\n",
      "Epoch 1053/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0624 - acc: 0.9951 - val_loss: 1.8414 - val_acc: 0.5627\n",
      "Epoch 1054/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0603 - acc: 0.9964 - val_loss: 1.8178 - val_acc: 0.5627\n",
      "Epoch 1055/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0628 - acc: 0.9947 - val_loss: 1.8320 - val_acc: 0.5653\n",
      "Epoch 1056/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0627 - acc: 0.9947 - val_loss: 1.9172 - val_acc: 0.5547\n",
      "Epoch 1057/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0670 - acc: 0.9933 - val_loss: 1.8177 - val_acc: 0.5587\n",
      "Epoch 1058/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0696 - acc: 0.9933 - val_loss: 1.8278 - val_acc: 0.5573\n",
      "Epoch 1059/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0702 - acc: 0.9924 - val_loss: 1.9137 - val_acc: 0.5547\n",
      "Epoch 1060/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0670 - acc: 0.9942 - val_loss: 1.8277 - val_acc: 0.5600\n",
      "Epoch 1061/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0647 - acc: 0.9942 - val_loss: 1.8315 - val_acc: 0.5600\n",
      "Epoch 1062/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0680 - acc: 0.9924 - val_loss: 1.9191 - val_acc: 0.5573\n",
      "Epoch 1063/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0689 - acc: 0.9942 - val_loss: 1.8420 - val_acc: 0.5693\n",
      "Epoch 1064/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0622 - acc: 0.9951 - val_loss: 1.8457 - val_acc: 0.5613\n",
      "Epoch 1065/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0612 - acc: 0.9947 - val_loss: 1.8833 - val_acc: 0.5573\n",
      "Epoch 1066/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0598 - acc: 0.9956 - val_loss: 1.8344 - val_acc: 0.5600\n",
      "Epoch 1067/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0597 - acc: 0.9951 - val_loss: 1.8485 - val_acc: 0.5653\n",
      "Epoch 1068/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0601 - acc: 0.9956 - val_loss: 1.9029 - val_acc: 0.5613\n",
      "Epoch 1069/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0622 - acc: 0.9951 - val_loss: 1.8377 - val_acc: 0.5573\n",
      "Epoch 1070/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0587 - acc: 0.9964 - val_loss: 1.8548 - val_acc: 0.5627\n",
      "Epoch 1071/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0620 - acc: 0.9933 - val_loss: 1.8987 - val_acc: 0.5600\n",
      "Epoch 1072/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0612 - acc: 0.9960 - val_loss: 1.8503 - val_acc: 0.5600\n",
      "Epoch 1073/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0576 - acc: 0.9960 - val_loss: 1.8514 - val_acc: 0.5613\n",
      "Epoch 1074/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0592 - acc: 0.9947 - val_loss: 1.8676 - val_acc: 0.5587\n",
      "Epoch 1075/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0570 - acc: 0.9973 - val_loss: 1.8715 - val_acc: 0.5573\n",
      "Epoch 1076/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0566 - acc: 0.9973 - val_loss: 1.8607 - val_acc: 0.5653\n",
      "Epoch 1077/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0564 - acc: 0.9969 - val_loss: 1.8714 - val_acc: 0.5587\n",
      "Epoch 1078/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0577 - acc: 0.9973 - val_loss: 1.8651 - val_acc: 0.5680\n",
      "Epoch 1079/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0559 - acc: 0.9982 - val_loss: 1.8692 - val_acc: 0.5640\n",
      "Epoch 1080/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0554 - acc: 0.9973 - val_loss: 1.8736 - val_acc: 0.5627\n",
      "Epoch 1081/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0551 - acc: 0.9969 - val_loss: 1.8754 - val_acc: 0.5640\n",
      "Epoch 1082/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0551 - acc: 0.9973 - val_loss: 1.8592 - val_acc: 0.5600\n",
      "Epoch 1083/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0601 - acc: 0.9969 - val_loss: 1.8808 - val_acc: 0.5560\n",
      "Epoch 1084/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0575 - acc: 0.9960 - val_loss: 1.9339 - val_acc: 0.5600\n",
      "Epoch 1085/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0622 - acc: 0.9933 - val_loss: 1.8689 - val_acc: 0.5627\n",
      "Epoch 1086/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0575 - acc: 0.9960 - val_loss: 1.8801 - val_acc: 0.5600\n",
      "Epoch 1087/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0581 - acc: 0.9969 - val_loss: 1.9162 - val_acc: 0.5613\n",
      "Epoch 1088/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0588 - acc: 0.9973 - val_loss: 1.8689 - val_acc: 0.5533\n",
      "Epoch 1089/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0699 - acc: 0.9876 - val_loss: 1.8674 - val_acc: 0.5587\n",
      "Epoch 1090/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0695 - acc: 0.9867 - val_loss: 1.9859 - val_acc: 0.5453\n",
      "Epoch 1091/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0693 - acc: 0.9876 - val_loss: 1.8723 - val_acc: 0.5627\n",
      "Epoch 1092/2000\n",
      "2250/2250 [==============================] - 1s 314us/step - loss: 0.0609 - acc: 0.9938 - val_loss: 1.8666 - val_acc: 0.5533\n",
      "Epoch 1093/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0627 - acc: 0.9942 - val_loss: 1.9234 - val_acc: 0.5653\n",
      "Epoch 1094/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0575 - acc: 0.9964 - val_loss: 1.8816 - val_acc: 0.5653\n",
      "Epoch 1095/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0588 - acc: 0.9951 - val_loss: 1.8745 - val_acc: 0.5547\n",
      "Epoch 1096/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0644 - acc: 0.9916 - val_loss: 1.9354 - val_acc: 0.5587\n",
      "Epoch 1097/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0597 - acc: 0.9951 - val_loss: 1.8805 - val_acc: 0.5613\n",
      "Epoch 1098/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0556 - acc: 0.9973 - val_loss: 1.8783 - val_acc: 0.5600\n",
      "Epoch 1099/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0604 - acc: 0.9929 - val_loss: 1.9486 - val_acc: 0.5573\n",
      "Epoch 1100/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0599 - acc: 0.9964 - val_loss: 1.9024 - val_acc: 0.5613\n",
      "Epoch 1101/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0556 - acc: 0.9973 - val_loss: 1.8770 - val_acc: 0.5573\n",
      "Epoch 1102/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0543 - acc: 0.9978 - val_loss: 1.9524 - val_acc: 0.5600\n",
      "Epoch 1103/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0583 - acc: 0.9964 - val_loss: 1.8897 - val_acc: 0.5587\n",
      "Epoch 1104/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 323us/step - loss: 0.0600 - acc: 0.9942 - val_loss: 1.8949 - val_acc: 0.5667\n",
      "Epoch 1105/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0584 - acc: 0.9929 - val_loss: 1.9340 - val_acc: 0.5587\n",
      "Epoch 1106/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0534 - acc: 0.9982 - val_loss: 1.8914 - val_acc: 0.5600\n",
      "Epoch 1107/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0585 - acc: 0.9938 - val_loss: 1.9234 - val_acc: 0.5560\n",
      "Epoch 1108/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0567 - acc: 0.9951 - val_loss: 1.9247 - val_acc: 0.5573\n",
      "Epoch 1109/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0538 - acc: 0.9969 - val_loss: 1.8950 - val_acc: 0.5587\n",
      "Epoch 1110/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0545 - acc: 0.9956 - val_loss: 1.9474 - val_acc: 0.5560\n",
      "Epoch 1111/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0532 - acc: 0.9973 - val_loss: 1.9145 - val_acc: 0.5573\n",
      "Epoch 1112/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0530 - acc: 0.9969 - val_loss: 1.8994 - val_acc: 0.5613\n",
      "Epoch 1113/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0517 - acc: 0.9978 - val_loss: 1.9769 - val_acc: 0.5533\n",
      "Epoch 1114/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0568 - acc: 0.9973 - val_loss: 1.9099 - val_acc: 0.5613\n",
      "Epoch 1115/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0527 - acc: 0.9964 - val_loss: 1.9010 - val_acc: 0.5600\n",
      "Epoch 1116/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0564 - acc: 0.9942 - val_loss: 1.9543 - val_acc: 0.5560\n",
      "Epoch 1117/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0534 - acc: 0.9969 - val_loss: 1.9237 - val_acc: 0.5547\n",
      "Epoch 1118/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0515 - acc: 0.9973 - val_loss: 1.9102 - val_acc: 0.5653\n",
      "Epoch 1119/2000\n",
      "2250/2250 [==============================] - 1s 324us/step - loss: 0.0514 - acc: 0.9969 - val_loss: 1.9583 - val_acc: 0.5627\n",
      "Epoch 1120/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0524 - acc: 0.9973 - val_loss: 1.9108 - val_acc: 0.5653\n",
      "Epoch 1121/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0509 - acc: 0.9982 - val_loss: 1.9197 - val_acc: 0.5627\n",
      "Epoch 1122/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0497 - acc: 0.9982 - val_loss: 1.9384 - val_acc: 0.5547\n",
      "Epoch 1123/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0497 - acc: 0.9982 - val_loss: 1.9070 - val_acc: 0.5573\n",
      "Epoch 1124/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0539 - acc: 0.9969 - val_loss: 1.9329 - val_acc: 0.5627\n",
      "Epoch 1125/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0517 - acc: 0.9956 - val_loss: 1.9605 - val_acc: 0.5533\n",
      "Epoch 1126/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0504 - acc: 0.9982 - val_loss: 1.9144 - val_acc: 0.5587\n",
      "Epoch 1127/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0496 - acc: 0.9982 - val_loss: 1.9498 - val_acc: 0.5547\n",
      "Epoch 1128/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0488 - acc: 0.9982 - val_loss: 1.9309 - val_acc: 0.5653\n",
      "Epoch 1129/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0478 - acc: 0.9982 - val_loss: 1.9363 - val_acc: 0.5560\n",
      "Epoch 1130/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0483 - acc: 0.9973 - val_loss: 1.9596 - val_acc: 0.5560\n",
      "Epoch 1131/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0487 - acc: 0.9982 - val_loss: 1.9268 - val_acc: 0.5667\n",
      "Epoch 1132/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0482 - acc: 0.9978 - val_loss: 1.9381 - val_acc: 0.5560\n",
      "Epoch 1133/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0486 - acc: 0.9978 - val_loss: 1.9509 - val_acc: 0.5573\n",
      "Epoch 1134/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0472 - acc: 0.9982 - val_loss: 1.9436 - val_acc: 0.5560\n",
      "Epoch 1135/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0469 - acc: 0.9982 - val_loss: 1.9392 - val_acc: 0.5627\n",
      "Epoch 1136/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0472 - acc: 0.9987 - val_loss: 1.9589 - val_acc: 0.5573\n",
      "Epoch 1137/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0487 - acc: 0.9978 - val_loss: 1.9595 - val_acc: 0.5560\n",
      "Epoch 1138/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0486 - acc: 0.9978 - val_loss: 1.9641 - val_acc: 0.5587\n",
      "Epoch 1139/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0484 - acc: 0.9978 - val_loss: 1.9390 - val_acc: 0.5653\n",
      "Epoch 1140/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0471 - acc: 0.9978 - val_loss: 1.9392 - val_acc: 0.5640\n",
      "Epoch 1141/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0477 - acc: 0.9987 - val_loss: 1.9520 - val_acc: 0.5573\n",
      "Epoch 1142/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0465 - acc: 0.9987 - val_loss: 1.9492 - val_acc: 0.5707\n",
      "Epoch 1143/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0462 - acc: 0.9982 - val_loss: 1.9933 - val_acc: 0.5560\n",
      "Epoch 1144/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0506 - acc: 0.9973 - val_loss: 1.9469 - val_acc: 0.5627\n",
      "Epoch 1145/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0467 - acc: 0.9991 - val_loss: 1.9505 - val_acc: 0.5653\n",
      "Epoch 1146/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0459 - acc: 0.9982 - val_loss: 1.9671 - val_acc: 0.5587\n",
      "Epoch 1147/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0461 - acc: 0.9987 - val_loss: 1.9631 - val_acc: 0.5560\n",
      "Epoch 1148/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0459 - acc: 0.9991 - val_loss: 1.9545 - val_acc: 0.5680\n",
      "Epoch 1149/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0454 - acc: 0.9978 - val_loss: 1.9830 - val_acc: 0.5587\n",
      "Epoch 1150/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0459 - acc: 0.9978 - val_loss: 1.9589 - val_acc: 0.5627\n",
      "Epoch 1151/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0462 - acc: 0.9978 - val_loss: 1.9552 - val_acc: 0.5680\n",
      "Epoch 1152/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0453 - acc: 0.9982 - val_loss: 1.9812 - val_acc: 0.5560\n",
      "Epoch 1153/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0452 - acc: 0.9987 - val_loss: 1.9705 - val_acc: 0.5600\n",
      "Epoch 1154/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0445 - acc: 0.9987 - val_loss: 1.9561 - val_acc: 0.5653\n",
      "Epoch 1155/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0448 - acc: 0.9982 - val_loss: 1.9749 - val_acc: 0.5560\n",
      "Epoch 1156/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0442 - acc: 0.9987 - val_loss: 1.9596 - val_acc: 0.5653\n",
      "Epoch 1157/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0453 - acc: 0.9978 - val_loss: 1.9886 - val_acc: 0.5587\n",
      "Epoch 1158/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0445 - acc: 0.9987 - val_loss: 1.9765 - val_acc: 0.5547\n",
      "Epoch 1159/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.0452 - acc: 0.9987 - val_loss: 1.9542 - val_acc: 0.5560\n",
      "Epoch 1160/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0499 - acc: 0.9973 - val_loss: 2.0268 - val_acc: 0.5613\n",
      "Epoch 1161/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.0505 - acc: 0.9964 - val_loss: 1.9793 - val_acc: 0.5600\n",
      "Epoch 1162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0448 - acc: 0.9987 - val_loss: 1.9679 - val_acc: 0.5667\n",
      "Epoch 1163/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0448 - acc: 0.9982 - val_loss: 1.9795 - val_acc: 0.5587\n",
      "Epoch 1164/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0435 - acc: 0.9978 - val_loss: 1.9984 - val_acc: 0.5613\n",
      "Epoch 1165/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0437 - acc: 0.9987 - val_loss: 1.9635 - val_acc: 0.5587\n",
      "Epoch 1166/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0463 - acc: 0.9982 - val_loss: 2.0313 - val_acc: 0.5600\n",
      "Epoch 1167/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0479 - acc: 0.9973 - val_loss: 1.9881 - val_acc: 0.5587\n",
      "Epoch 1168/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0446 - acc: 0.9991 - val_loss: 1.9778 - val_acc: 0.5680\n",
      "Epoch 1169/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0436 - acc: 0.9987 - val_loss: 1.9998 - val_acc: 0.5573\n",
      "Epoch 1170/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0449 - acc: 0.9978 - val_loss: 1.9828 - val_acc: 0.5613\n",
      "Epoch 1171/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0422 - acc: 0.9987 - val_loss: 2.0024 - val_acc: 0.5573\n",
      "Epoch 1172/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0425 - acc: 0.9991 - val_loss: 1.9682 - val_acc: 0.5613\n",
      "Epoch 1173/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0437 - acc: 0.9987 - val_loss: 2.0031 - val_acc: 0.5560\n",
      "Epoch 1174/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0432 - acc: 0.9987 - val_loss: 1.9982 - val_acc: 0.5627\n",
      "Epoch 1175/2000\n",
      "2250/2250 [==============================] - 1s 304us/step - loss: 0.0431 - acc: 0.9987 - val_loss: 2.0003 - val_acc: 0.5560\n",
      "Epoch 1176/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0423 - acc: 0.9991 - val_loss: 1.9828 - val_acc: 0.5640\n",
      "Epoch 1177/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0423 - acc: 0.9982 - val_loss: 1.9982 - val_acc: 0.5627\n",
      "Epoch 1178/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.0418 - acc: 0.9987 - val_loss: 2.0225 - val_acc: 0.5573\n",
      "Epoch 1179/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0429 - acc: 0.9987 - val_loss: 1.9841 - val_acc: 0.5667\n",
      "Epoch 1180/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0422 - acc: 0.9991 - val_loss: 2.0098 - val_acc: 0.5600\n",
      "Epoch 1181/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0419 - acc: 0.9991 - val_loss: 2.0097 - val_acc: 0.5573\n",
      "Epoch 1182/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0426 - acc: 0.9987 - val_loss: 1.9828 - val_acc: 0.5600\n",
      "Epoch 1183/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0433 - acc: 0.9982 - val_loss: 2.0533 - val_acc: 0.5573\n",
      "Epoch 1184/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0445 - acc: 0.9991 - val_loss: 1.9907 - val_acc: 0.5640\n",
      "Epoch 1185/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0426 - acc: 0.9982 - val_loss: 1.9967 - val_acc: 0.5653\n",
      "Epoch 1186/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0421 - acc: 0.9982 - val_loss: 2.0083 - val_acc: 0.5667\n",
      "Epoch 1187/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0410 - acc: 0.9991 - val_loss: 1.9978 - val_acc: 0.5667\n",
      "Epoch 1188/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0425 - acc: 0.9987 - val_loss: 2.0287 - val_acc: 0.5600\n",
      "Epoch 1189/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0415 - acc: 0.9987 - val_loss: 2.0144 - val_acc: 0.5600\n",
      "Epoch 1190/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0415 - acc: 0.9987 - val_loss: 2.0052 - val_acc: 0.5600\n",
      "Epoch 1191/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0400 - acc: 0.9987 - val_loss: 2.0249 - val_acc: 0.5560\n",
      "Epoch 1192/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0399 - acc: 0.9991 - val_loss: 1.9992 - val_acc: 0.5627\n",
      "Epoch 1193/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0425 - acc: 0.9982 - val_loss: 2.0362 - val_acc: 0.5587\n",
      "Epoch 1194/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0412 - acc: 0.9987 - val_loss: 2.0352 - val_acc: 0.5573\n",
      "Epoch 1195/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0438 - acc: 0.9978 - val_loss: 1.9967 - val_acc: 0.5600\n",
      "Epoch 1196/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0432 - acc: 0.9982 - val_loss: 2.0187 - val_acc: 0.5640\n",
      "Epoch 1197/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0412 - acc: 0.9996 - val_loss: 2.0512 - val_acc: 0.5547\n",
      "Epoch 1198/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0410 - acc: 0.9987 - val_loss: 2.0041 - val_acc: 0.5627\n",
      "Epoch 1199/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0396 - acc: 0.9982 - val_loss: 2.0745 - val_acc: 0.5573\n",
      "Epoch 1200/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0434 - acc: 0.9987 - val_loss: 2.0187 - val_acc: 0.5693\n",
      "Epoch 1201/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0405 - acc: 0.9991 - val_loss: 2.0254 - val_acc: 0.5640\n",
      "Epoch 1202/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0401 - acc: 0.9978 - val_loss: 2.0549 - val_acc: 0.5573\n",
      "Epoch 1203/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0402 - acc: 0.9987 - val_loss: 2.0243 - val_acc: 0.5667\n",
      "Epoch 1204/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0396 - acc: 0.9996 - val_loss: 2.0205 - val_acc: 0.5693\n",
      "Epoch 1205/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0397 - acc: 0.9987 - val_loss: 2.0371 - val_acc: 0.5573\n",
      "Epoch 1206/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0389 - acc: 0.9982 - val_loss: 2.0500 - val_acc: 0.5547\n",
      "Epoch 1207/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0391 - acc: 0.9991 - val_loss: 2.0294 - val_acc: 0.5653\n",
      "Epoch 1208/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0379 - acc: 0.9991 - val_loss: 2.0447 - val_acc: 0.5613\n",
      "Epoch 1209/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0377 - acc: 0.9991 - val_loss: 2.0224 - val_acc: 0.5653\n",
      "Epoch 1210/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0403 - acc: 0.9987 - val_loss: 2.0639 - val_acc: 0.5547\n",
      "Epoch 1211/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0401 - acc: 0.9987 - val_loss: 2.0540 - val_acc: 0.5587\n",
      "Epoch 1212/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0403 - acc: 0.9991 - val_loss: 2.0219 - val_acc: 0.5587\n",
      "Epoch 1213/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0418 - acc: 0.9987 - val_loss: 2.0730 - val_acc: 0.5587\n",
      "Epoch 1214/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0398 - acc: 0.9991 - val_loss: 2.0269 - val_acc: 0.5613\n",
      "Epoch 1215/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0413 - acc: 0.9996 - val_loss: 2.0434 - val_acc: 0.5667\n",
      "Epoch 1216/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0397 - acc: 0.9978 - val_loss: 2.0632 - val_acc: 0.5573\n",
      "Epoch 1217/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0379 - acc: 0.9991 - val_loss: 2.0339 - val_acc: 0.5680\n",
      "Epoch 1218/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0370 - acc: 0.9991 - val_loss: 2.0931 - val_acc: 0.5573\n",
      "Epoch 1219/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0398 - acc: 0.9987 - val_loss: 2.0362 - val_acc: 0.5680\n",
      "Epoch 1220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0399 - acc: 0.9982 - val_loss: 2.0376 - val_acc: 0.5680\n",
      "Epoch 1221/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0379 - acc: 0.9987 - val_loss: 2.1038 - val_acc: 0.5573\n",
      "Epoch 1222/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0405 - acc: 0.9991 - val_loss: 2.0382 - val_acc: 0.5613\n",
      "Epoch 1223/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0391 - acc: 0.9987 - val_loss: 2.0574 - val_acc: 0.5560\n",
      "Epoch 1224/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0372 - acc: 0.9996 - val_loss: 2.0669 - val_acc: 0.5573\n",
      "Epoch 1225/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0373 - acc: 0.9987 - val_loss: 2.0446 - val_acc: 0.5640\n",
      "Epoch 1226/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0382 - acc: 0.9987 - val_loss: 2.0767 - val_acc: 0.5573\n",
      "Epoch 1227/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0377 - acc: 0.9982 - val_loss: 2.0741 - val_acc: 0.5573\n",
      "Epoch 1228/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0376 - acc: 0.9991 - val_loss: 2.0435 - val_acc: 0.5573\n",
      "Epoch 1229/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0419 - acc: 0.9982 - val_loss: 2.1065 - val_acc: 0.5573\n",
      "Epoch 1230/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0412 - acc: 0.9978 - val_loss: 2.0541 - val_acc: 0.5667\n",
      "Epoch 1231/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0380 - acc: 0.9987 - val_loss: 2.0492 - val_acc: 0.5653\n",
      "Epoch 1232/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0374 - acc: 0.9987 - val_loss: 2.0811 - val_acc: 0.5573\n",
      "Epoch 1233/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0357 - acc: 0.9991 - val_loss: 2.0525 - val_acc: 0.5653\n",
      "Epoch 1234/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0361 - acc: 0.9996 - val_loss: 2.0718 - val_acc: 0.5587\n",
      "Epoch 1235/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0349 - acc: 0.9991 - val_loss: 2.0705 - val_acc: 0.5653\n",
      "Epoch 1236/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0350 - acc: 0.9996 - val_loss: 2.0806 - val_acc: 0.5573\n",
      "Epoch 1237/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0347 - acc: 0.9996 - val_loss: 2.0475 - val_acc: 0.5613\n",
      "Epoch 1238/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0360 - acc: 0.9996 - val_loss: 2.0765 - val_acc: 0.5613\n",
      "Epoch 1239/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0348 - acc: 0.9991 - val_loss: 2.0756 - val_acc: 0.5653\n",
      "Epoch 1240/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0349 - acc: 0.9991 - val_loss: 2.0589 - val_acc: 0.5627\n",
      "Epoch 1241/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0351 - acc: 0.9996 - val_loss: 2.0862 - val_acc: 0.5547\n",
      "Epoch 1242/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0348 - acc: 0.9991 - val_loss: 2.1033 - val_acc: 0.5627\n",
      "Epoch 1243/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0350 - acc: 0.9996 - val_loss: 2.0630 - val_acc: 0.5653\n",
      "Epoch 1244/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0344 - acc: 0.9987 - val_loss: 2.0922 - val_acc: 0.5560\n",
      "Epoch 1245/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0355 - acc: 0.9991 - val_loss: 2.0810 - val_acc: 0.5693\n",
      "Epoch 1246/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0346 - acc: 0.9996 - val_loss: 2.0848 - val_acc: 0.5627\n",
      "Epoch 1247/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0345 - acc: 0.9991 - val_loss: 2.0835 - val_acc: 0.5573\n",
      "Epoch 1248/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0342 - acc: 0.9991 - val_loss: 2.0934 - val_acc: 0.5640\n",
      "Epoch 1249/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0336 - acc: 0.9991 - val_loss: 2.0828 - val_acc: 0.5613\n",
      "Epoch 1250/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0335 - acc: 0.9991 - val_loss: 2.0854 - val_acc: 0.5600\n",
      "Epoch 1251/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0334 - acc: 0.9996 - val_loss: 2.1099 - val_acc: 0.5560\n",
      "Epoch 1252/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0337 - acc: 0.9996 - val_loss: 2.0769 - val_acc: 0.5653\n",
      "Epoch 1253/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0344 - acc: 0.9987 - val_loss: 2.1039 - val_acc: 0.5547\n",
      "Epoch 1254/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0336 - acc: 0.9991 - val_loss: 2.0882 - val_acc: 0.5693\n",
      "Epoch 1255/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0338 - acc: 0.9991 - val_loss: 2.0851 - val_acc: 0.5667\n",
      "Epoch 1256/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0391 - acc: 0.9982 - val_loss: 2.1574 - val_acc: 0.5573\n",
      "Epoch 1257/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0387 - acc: 0.9978 - val_loss: 2.0787 - val_acc: 0.5640\n",
      "Epoch 1258/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0359 - acc: 0.9996 - val_loss: 2.0945 - val_acc: 0.5707\n",
      "Epoch 1259/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0366 - acc: 0.9982 - val_loss: 2.1362 - val_acc: 0.5573\n",
      "Epoch 1260/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0348 - acc: 0.9991 - val_loss: 2.0733 - val_acc: 0.5600\n",
      "Epoch 1261/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0368 - acc: 0.9987 - val_loss: 2.1103 - val_acc: 0.5640\n",
      "Epoch 1262/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0363 - acc: 0.9991 - val_loss: 2.1392 - val_acc: 0.5533\n",
      "Epoch 1263/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0353 - acc: 0.9987 - val_loss: 2.0968 - val_acc: 0.5613\n",
      "Epoch 1264/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0322 - acc: 0.9996 - val_loss: 2.1144 - val_acc: 0.5627\n",
      "Epoch 1265/2000\n",
      "2250/2250 [==============================] - 1s 313us/step - loss: 0.0326 - acc: 0.9996 - val_loss: 2.1010 - val_acc: 0.5680\n",
      "Epoch 1266/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0324 - acc: 0.9996 - val_loss: 2.1042 - val_acc: 0.5613\n",
      "Epoch 1267/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0319 - acc: 0.9996 - val_loss: 2.1121 - val_acc: 0.5613\n",
      "Epoch 1268/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0319 - acc: 0.9991 - val_loss: 2.1077 - val_acc: 0.5693\n",
      "Epoch 1269/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0321 - acc: 0.9996 - val_loss: 2.1220 - val_acc: 0.5613\n",
      "Epoch 1270/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0319 - acc: 0.9991 - val_loss: 2.1135 - val_acc: 0.5627\n",
      "Epoch 1271/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0316 - acc: 0.9996 - val_loss: 2.1067 - val_acc: 0.5693\n",
      "Epoch 1272/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0322 - acc: 0.9996 - val_loss: 2.1247 - val_acc: 0.5573\n",
      "Epoch 1273/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0317 - acc: 0.9991 - val_loss: 2.0986 - val_acc: 0.5653\n",
      "Epoch 1274/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0324 - acc: 0.9987 - val_loss: 2.1496 - val_acc: 0.5573\n",
      "Epoch 1275/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0327 - acc: 0.9996 - val_loss: 2.1034 - val_acc: 0.5653\n",
      "Epoch 1276/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0312 - acc: 0.9996 - val_loss: 2.1297 - val_acc: 0.5587\n",
      "Epoch 1277/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0315 - acc: 0.9991 - val_loss: 2.1186 - val_acc: 0.5693\n",
      "Epoch 1278/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0311 - acc: 0.9996 - val_loss: 2.1161 - val_acc: 0.5667\n",
      "Epoch 1279/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0313 - acc: 0.9996 - val_loss: 2.1413 - val_acc: 0.5573\n",
      "Epoch 1280/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0316 - acc: 0.9996 - val_loss: 2.1124 - val_acc: 0.5667\n",
      "Epoch 1281/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0327 - acc: 0.9987 - val_loss: 2.1382 - val_acc: 0.5627\n",
      "Epoch 1282/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0317 - acc: 0.9996 - val_loss: 2.1379 - val_acc: 0.5613\n",
      "Epoch 1283/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0312 - acc: 0.9991 - val_loss: 2.1151 - val_acc: 0.5680\n",
      "Epoch 1284/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 2.1423 - val_acc: 0.5613\n",
      "Epoch 1285/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0315 - acc: 0.9991 - val_loss: 2.1390 - val_acc: 0.5613\n",
      "Epoch 1286/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0305 - acc: 0.9991 - val_loss: 2.1258 - val_acc: 0.5613\n",
      "Epoch 1287/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0301 - acc: 0.9996 - val_loss: 2.1317 - val_acc: 0.5613\n",
      "Epoch 1288/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0299 - acc: 0.9996 - val_loss: 2.1579 - val_acc: 0.5560\n",
      "Epoch 1289/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0316 - acc: 0.9991 - val_loss: 2.1557 - val_acc: 0.5573\n",
      "Epoch 1290/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0317 - acc: 0.9996 - val_loss: 2.1138 - val_acc: 0.5600\n",
      "Epoch 1291/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0342 - acc: 0.9982 - val_loss: 2.1350 - val_acc: 0.5627\n",
      "Epoch 1292/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0311 - acc: 0.9991 - val_loss: 2.1502 - val_acc: 0.5587\n",
      "Epoch 1293/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0305 - acc: 0.9996 - val_loss: 2.1231 - val_acc: 0.5627\n",
      "Epoch 1294/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 2.1319 - val_acc: 0.5680\n",
      "Epoch 1295/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0311 - acc: 0.9991 - val_loss: 2.2026 - val_acc: 0.5480\n",
      "Epoch 1296/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0335 - acc: 0.9996 - val_loss: 2.1242 - val_acc: 0.5640\n",
      "Epoch 1297/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0304 - acc: 0.9991 - val_loss: 2.1468 - val_acc: 0.5600\n",
      "Epoch 1298/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0298 - acc: 0.9996 - val_loss: 2.1718 - val_acc: 0.5573\n",
      "Epoch 1299/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0299 - acc: 0.9996 - val_loss: 2.1437 - val_acc: 0.5600\n",
      "Epoch 1300/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0289 - acc: 0.9996 - val_loss: 2.1451 - val_acc: 0.5613\n",
      "Epoch 1301/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0290 - acc: 0.9996 - val_loss: 2.1421 - val_acc: 0.5693\n",
      "Epoch 1302/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 2.1676 - val_acc: 0.5600\n",
      "Epoch 1303/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 2.1385 - val_acc: 0.5667\n",
      "Epoch 1304/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0295 - acc: 0.9991 - val_loss: 2.1518 - val_acc: 0.5693\n",
      "Epoch 1305/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0289 - acc: 0.9996 - val_loss: 2.1750 - val_acc: 0.5587\n",
      "Epoch 1306/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 2.1324 - val_acc: 0.5627\n",
      "Epoch 1307/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0316 - acc: 0.9991 - val_loss: 2.1785 - val_acc: 0.5587\n",
      "Epoch 1308/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0304 - acc: 0.9991 - val_loss: 2.1761 - val_acc: 0.5600\n",
      "Epoch 1309/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0302 - acc: 0.9996 - val_loss: 2.1367 - val_acc: 0.5600\n",
      "Epoch 1310/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0344 - acc: 0.9982 - val_loss: 2.1710 - val_acc: 0.5600\n",
      "Epoch 1311/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0320 - acc: 0.9987 - val_loss: 2.2146 - val_acc: 0.5587\n",
      "Epoch 1312/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0345 - acc: 0.9991 - val_loss: 2.1459 - val_acc: 0.5587\n",
      "Epoch 1313/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0345 - acc: 0.9996 - val_loss: 2.2017 - val_acc: 0.5520\n",
      "Epoch 1314/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0346 - acc: 0.9996 - val_loss: 2.2130 - val_acc: 0.5533\n",
      "Epoch 1315/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0338 - acc: 0.9987 - val_loss: 2.1489 - val_acc: 0.5653\n",
      "Epoch 1316/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0307 - acc: 0.9991 - val_loss: 2.1707 - val_acc: 0.5587\n",
      "Epoch 1317/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 2.1848 - val_acc: 0.5600\n",
      "Epoch 1318/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0287 - acc: 0.9996 - val_loss: 2.1622 - val_acc: 0.5680\n",
      "Epoch 1319/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 2.1677 - val_acc: 0.5627\n",
      "Epoch 1320/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0276 - acc: 0.9996 - val_loss: 2.1744 - val_acc: 0.5613\n",
      "Epoch 1321/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 2.1945 - val_acc: 0.5587\n",
      "Epoch 1322/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0279 - acc: 0.9996 - val_loss: 2.1593 - val_acc: 0.5680\n",
      "Epoch 1323/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0284 - acc: 0.9991 - val_loss: 2.1862 - val_acc: 0.5613\n",
      "Epoch 1324/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0277 - acc: 0.9991 - val_loss: 2.1997 - val_acc: 0.5587\n",
      "Epoch 1325/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0292 - acc: 0.9996 - val_loss: 2.1613 - val_acc: 0.5693\n",
      "Epoch 1326/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0290 - acc: 0.9991 - val_loss: 2.2077 - val_acc: 0.5547\n",
      "Epoch 1327/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0291 - acc: 0.9996 - val_loss: 2.1836 - val_acc: 0.5627\n",
      "Epoch 1328/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0275 - acc: 0.9996 - val_loss: 2.1724 - val_acc: 0.5680\n",
      "Epoch 1329/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0269 - acc: 0.9996 - val_loss: 2.2112 - val_acc: 0.5533\n",
      "Epoch 1330/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0274 - acc: 0.9996 - val_loss: 2.1681 - val_acc: 0.5693\n",
      "Epoch 1331/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0283 - acc: 0.9996 - val_loss: 2.1804 - val_acc: 0.5613\n",
      "Epoch 1332/2000\n",
      "2250/2250 [==============================] - 1s 316us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 2.1890 - val_acc: 0.5653\n",
      "Epoch 1333/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0270 - acc: 0.9996 - val_loss: 2.1706 - val_acc: 0.5573\n",
      "Epoch 1334/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.0316 - acc: 0.9991 - val_loss: 2.2079 - val_acc: 0.5600\n",
      "Epoch 1335/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 2.2149 - val_acc: 0.5573\n",
      "Epoch 1336/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 2.1759 - val_acc: 0.5627\n",
      "Epoch 1337/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0286 - acc: 0.9996 - val_loss: 2.2501 - val_acc: 0.5547\n",
      "Epoch 1338/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0302 - acc: 0.9996 - val_loss: 2.1873 - val_acc: 0.5693\n",
      "Epoch 1339/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0298 - acc: 0.9991 - val_loss: 2.1849 - val_acc: 0.5627\n",
      "Epoch 1340/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0297 - acc: 0.9991 - val_loss: 2.2246 - val_acc: 0.5573\n",
      "Epoch 1341/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0276 - acc: 0.9996 - val_loss: 2.1984 - val_acc: 0.5640\n",
      "Epoch 1342/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0273 - acc: 0.9996 - val_loss: 2.1842 - val_acc: 0.5667\n",
      "Epoch 1343/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0278 - acc: 0.9991 - val_loss: 2.2003 - val_acc: 0.5627\n",
      "Epoch 1344/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0258 - acc: 0.9996 - val_loss: 2.2360 - val_acc: 0.5547\n",
      "Epoch 1345/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0272 - acc: 0.9996 - val_loss: 2.1817 - val_acc: 0.5627\n",
      "Epoch 1346/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0278 - acc: 0.9996 - val_loss: 2.2414 - val_acc: 0.5560\n",
      "Epoch 1347/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0273 - acc: 0.9996 - val_loss: 2.2015 - val_acc: 0.5653\n",
      "Epoch 1348/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0286 - acc: 0.9996 - val_loss: 2.1859 - val_acc: 0.5680\n",
      "Epoch 1349/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0280 - acc: 0.9987 - val_loss: 2.2495 - val_acc: 0.5547\n",
      "Epoch 1350/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 2.1955 - val_acc: 0.5693\n",
      "Epoch 1351/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 2.2360 - val_acc: 0.5560\n",
      "Epoch 1352/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0272 - acc: 0.9991 - val_loss: 2.2347 - val_acc: 0.5547\n",
      "Epoch 1353/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 2.1912 - val_acc: 0.5680\n",
      "Epoch 1354/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0263 - acc: 0.9991 - val_loss: 2.2896 - val_acc: 0.5520\n",
      "Epoch 1355/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0317 - acc: 0.9991 - val_loss: 2.2100 - val_acc: 0.5693\n",
      "Epoch 1356/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0301 - acc: 0.9991 - val_loss: 2.1959 - val_acc: 0.5627\n",
      "Epoch 1357/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0298 - acc: 0.9987 - val_loss: 2.2771 - val_acc: 0.5520\n",
      "Epoch 1358/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0290 - acc: 0.9991 - val_loss: 2.2098 - val_acc: 0.5693\n",
      "Epoch 1359/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0276 - acc: 0.9996 - val_loss: 2.2048 - val_acc: 0.5680\n",
      "Epoch 1360/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0283 - acc: 0.9991 - val_loss: 2.2658 - val_acc: 0.5560\n",
      "Epoch 1361/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0279 - acc: 0.9996 - val_loss: 2.2236 - val_acc: 0.5613\n",
      "Epoch 1362/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0260 - acc: 0.9996 - val_loss: 2.2276 - val_acc: 0.5627\n",
      "Epoch 1363/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 2.2339 - val_acc: 0.5613\n",
      "Epoch 1364/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 2.2208 - val_acc: 0.5640\n",
      "Epoch 1365/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 2.2243 - val_acc: 0.5640\n",
      "Epoch 1366/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 2.2543 - val_acc: 0.5587\n",
      "Epoch 1367/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 2.2212 - val_acc: 0.5667\n",
      "Epoch 1368/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 2.2487 - val_acc: 0.5640\n",
      "Epoch 1369/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0243 - acc: 0.9996 - val_loss: 2.2681 - val_acc: 0.5547\n",
      "Epoch 1370/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0259 - acc: 0.9996 - val_loss: 2.2141 - val_acc: 0.5640\n",
      "Epoch 1371/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0265 - acc: 0.9996 - val_loss: 2.2416 - val_acc: 0.5627\n",
      "Epoch 1372/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0243 - acc: 0.9996 - val_loss: 2.2454 - val_acc: 0.5627\n",
      "Epoch 1373/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 2.2350 - val_acc: 0.5653\n",
      "Epoch 1374/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 2.2389 - val_acc: 0.5653\n",
      "Epoch 1375/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 2.2468 - val_acc: 0.5667\n",
      "Epoch 1376/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 2.2284 - val_acc: 0.5667\n",
      "Epoch 1377/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 2.2422 - val_acc: 0.5640\n",
      "Epoch 1378/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 2.2392 - val_acc: 0.5680\n",
      "Epoch 1379/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 2.2430 - val_acc: 0.5667\n",
      "Epoch 1380/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 2.2456 - val_acc: 0.5680\n",
      "Epoch 1381/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 2.2668 - val_acc: 0.5587\n",
      "Epoch 1382/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0238 - acc: 0.9996 - val_loss: 2.2525 - val_acc: 0.5640\n",
      "Epoch 1383/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 2.2413 - val_acc: 0.5680\n",
      "Epoch 1384/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0230 - acc: 0.9996 - val_loss: 2.2497 - val_acc: 0.5640\n",
      "Epoch 1385/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 2.2607 - val_acc: 0.5640\n",
      "Epoch 1386/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 2.2515 - val_acc: 0.5627\n",
      "Epoch 1387/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 2.2558 - val_acc: 0.5653\n",
      "Epoch 1388/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 2.2539 - val_acc: 0.5613\n",
      "Epoch 1389/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 2.2538 - val_acc: 0.5653\n",
      "Epoch 1390/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 2.2899 - val_acc: 0.5547\n",
      "Epoch 1391/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 2.2407 - val_acc: 0.5693\n",
      "Epoch 1392/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 2.2636 - val_acc: 0.5627\n",
      "Epoch 1393/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0235 - acc: 0.9996 - val_loss: 2.2968 - val_acc: 0.5533\n",
      "Epoch 1394/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0241 - acc: 0.9996 - val_loss: 2.2471 - val_acc: 0.5573\n",
      "Epoch 1395/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0263 - acc: 0.9991 - val_loss: 2.2870 - val_acc: 0.5587\n",
      "Epoch 1396/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0234 - acc: 0.9996 - val_loss: 2.2483 - val_acc: 0.5640\n",
      "Epoch 1397/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0231 - acc: 0.9996 - val_loss: 2.2552 - val_acc: 0.5707\n",
      "Epoch 1398/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0230 - acc: 0.9996 - val_loss: 2.2845 - val_acc: 0.5600\n",
      "Epoch 1399/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 2.2626 - val_acc: 0.5653\n",
      "Epoch 1400/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 2.2633 - val_acc: 0.5627\n",
      "Epoch 1401/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 2.2869 - val_acc: 0.5613\n",
      "Epoch 1402/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 2.2798 - val_acc: 0.5627\n",
      "Epoch 1403/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 2.2647 - val_acc: 0.5680\n",
      "Epoch 1404/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 2.2640 - val_acc: 0.5640\n",
      "Epoch 1405/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2737 - val_acc: 0.5680\n",
      "Epoch 1406/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 2.2769 - val_acc: 0.5720\n",
      "Epoch 1407/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 2.2667 - val_acc: 0.5627\n",
      "Epoch 1408/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2665 - val_acc: 0.5627\n",
      "Epoch 1409/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2972 - val_acc: 0.5573\n",
      "Epoch 1410/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 2.2738 - val_acc: 0.5640\n",
      "Epoch 1411/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 2.2900 - val_acc: 0.5587\n",
      "Epoch 1412/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 2.2854 - val_acc: 0.5667\n",
      "Epoch 1413/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 2.3075 - val_acc: 0.5573\n",
      "Epoch 1414/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 2.2767 - val_acc: 0.5640\n",
      "Epoch 1415/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2758 - val_acc: 0.5653\n",
      "Epoch 1416/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 2.2948 - val_acc: 0.5653\n",
      "Epoch 1417/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 2.2790 - val_acc: 0.5707\n",
      "Epoch 1418/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 2.2996 - val_acc: 0.5613\n",
      "Epoch 1419/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 2.2769 - val_acc: 0.5640\n",
      "Epoch 1420/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 2.2918 - val_acc: 0.5640\n",
      "Epoch 1421/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 2.2898 - val_acc: 0.5640\n",
      "Epoch 1422/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.3067 - val_acc: 0.5627\n",
      "Epoch 1423/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 2.2981 - val_acc: 0.5653\n",
      "Epoch 1424/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.2840 - val_acc: 0.5653\n",
      "Epoch 1425/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 2.3080 - val_acc: 0.5613\n",
      "Epoch 1426/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 2.3054 - val_acc: 0.5627\n",
      "Epoch 1427/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 2.3043 - val_acc: 0.5640\n",
      "Epoch 1428/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.2949 - val_acc: 0.5613\n",
      "Epoch 1429/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 2.3160 - val_acc: 0.5640\n",
      "Epoch 1430/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 2.3372 - val_acc: 0.5547\n",
      "Epoch 1431/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2842 - val_acc: 0.5640\n",
      "Epoch 1432/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 2.3679 - val_acc: 0.5520\n",
      "Epoch 1433/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 2.2948 - val_acc: 0.5720\n",
      "Epoch 1434/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 2.2956 - val_acc: 0.5680\n",
      "Epoch 1435/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 2.3517 - val_acc: 0.5547\n",
      "Epoch 1436/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 2.3006 - val_acc: 0.5680\n",
      "Epoch 1437/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 2.3069 - val_acc: 0.5653\n",
      "Epoch 1438/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 2.3229 - val_acc: 0.5640\n",
      "Epoch 1439/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 2.3030 - val_acc: 0.5627\n",
      "Epoch 1440/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 2.3451 - val_acc: 0.5573\n",
      "Epoch 1441/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.3075 - val_acc: 0.5680\n",
      "Epoch 1442/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 2.3104 - val_acc: 0.5653\n",
      "Epoch 1443/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.3447 - val_acc: 0.5547\n",
      "Epoch 1444/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 2.3114 - val_acc: 0.5667\n",
      "Epoch 1445/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.3328 - val_acc: 0.5613\n",
      "Epoch 1446/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 2.3332 - val_acc: 0.5627\n",
      "Epoch 1447/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.3160 - val_acc: 0.5720\n",
      "Epoch 1448/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 2.3223 - val_acc: 0.5613\n",
      "Epoch 1449/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.3232 - val_acc: 0.5613\n",
      "Epoch 1450/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 2.3374 - val_acc: 0.5653\n",
      "Epoch 1451/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 2.3213 - val_acc: 0.5693\n",
      "Epoch 1452/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 2.3411 - val_acc: 0.5627\n",
      "Epoch 1453/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.3514 - val_acc: 0.5600\n",
      "Epoch 1454/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 2.3127 - val_acc: 0.5640\n",
      "Epoch 1455/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 2.3618 - val_acc: 0.5560\n",
      "Epoch 1456/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 2.3249 - val_acc: 0.5707\n",
      "Epoch 1457/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.3264 - val_acc: 0.5707\n",
      "Epoch 1458/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0198 - acc: 0.9996 - val_loss: 2.3775 - val_acc: 0.5520\n",
      "Epoch 1459/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.3138 - val_acc: 0.5640\n",
      "Epoch 1460/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 2.3639 - val_acc: 0.5560\n",
      "Epoch 1461/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 2.3422 - val_acc: 0.5707\n",
      "Epoch 1462/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.3372 - val_acc: 0.5693\n",
      "Epoch 1463/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 2.3536 - val_acc: 0.5627\n",
      "Epoch 1464/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.3470 - val_acc: 0.5653\n",
      "Epoch 1465/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 2.3415 - val_acc: 0.5693\n",
      "Epoch 1466/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 2.3593 - val_acc: 0.5627\n",
      "Epoch 1467/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.3392 - val_acc: 0.5680\n",
      "Epoch 1468/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.3524 - val_acc: 0.5680\n",
      "Epoch 1469/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 2.3672 - val_acc: 0.5613\n",
      "Epoch 1470/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 2.3338 - val_acc: 0.5707\n",
      "Epoch 1471/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 2.3593 - val_acc: 0.5587\n",
      "Epoch 1472/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 2.3635 - val_acc: 0.5573\n",
      "Epoch 1473/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 2.3385 - val_acc: 0.5720\n",
      "Epoch 1474/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 2.3715 - val_acc: 0.5560\n",
      "Epoch 1475/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 2.3535 - val_acc: 0.5613\n",
      "Epoch 1476/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 2.3502 - val_acc: 0.5707\n",
      "Epoch 1477/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 2.3768 - val_acc: 0.5600\n",
      "Epoch 1478/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 2.3536 - val_acc: 0.5680\n",
      "Epoch 1479/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 2.3616 - val_acc: 0.5680\n",
      "Epoch 1480/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 2.3703 - val_acc: 0.5653\n",
      "Epoch 1481/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 2.3556 - val_acc: 0.5653\n",
      "Epoch 1482/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 2.3535 - val_acc: 0.5693\n",
      "Epoch 1483/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 2.3653 - val_acc: 0.5693\n",
      "Epoch 1484/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 2.3646 - val_acc: 0.5627\n",
      "Epoch 1485/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 2.3641 - val_acc: 0.5640\n",
      "Epoch 1486/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 2.3659 - val_acc: 0.5680\n",
      "Epoch 1487/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 2.3777 - val_acc: 0.5613\n",
      "Epoch 1488/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 2.3562 - val_acc: 0.5613\n",
      "Epoch 1489/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 2.3853 - val_acc: 0.5613\n",
      "Epoch 1490/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 2.3699 - val_acc: 0.5707\n",
      "Epoch 1491/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 2.3693 - val_acc: 0.5613\n",
      "Epoch 1492/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.3806 - val_acc: 0.5627\n",
      "Epoch 1493/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 2.3710 - val_acc: 0.5707\n",
      "Epoch 1494/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 2.3832 - val_acc: 0.5600\n",
      "Epoch 1495/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 2.3728 - val_acc: 0.5653\n",
      "Epoch 1496/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.3665 - val_acc: 0.5693\n",
      "Epoch 1497/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 2.4016 - val_acc: 0.5600\n",
      "Epoch 1498/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 2.3707 - val_acc: 0.5667\n",
      "Epoch 1499/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 2.3801 - val_acc: 0.5667\n",
      "Epoch 1500/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.4011 - val_acc: 0.5613\n",
      "Epoch 1501/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 2.3747 - val_acc: 0.5693\n",
      "Epoch 1502/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 2.4061 - val_acc: 0.5573\n",
      "Epoch 1503/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.3728 - val_acc: 0.5693\n",
      "Epoch 1504/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 2.3843 - val_acc: 0.5680\n",
      "Epoch 1505/2000\n",
      "2250/2250 [==============================] - 1s 318us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 2.4033 - val_acc: 0.5600\n",
      "Epoch 1506/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 2.3795 - val_acc: 0.5640\n",
      "Epoch 1507/2000\n",
      "2250/2250 [==============================] - 1s 314us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 2.4022 - val_acc: 0.5600\n",
      "Epoch 1508/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 2.3886 - val_acc: 0.5667\n",
      "Epoch 1509/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 2.3906 - val_acc: 0.5653\n",
      "Epoch 1510/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 2.4057 - val_acc: 0.5600\n",
      "Epoch 1511/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 2.3887 - val_acc: 0.5667\n",
      "Epoch 1512/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 2.3950 - val_acc: 0.5653\n",
      "Epoch 1513/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 2.3977 - val_acc: 0.5667\n",
      "Epoch 1514/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 2.4142 - val_acc: 0.5640\n",
      "Epoch 1515/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 2.4152 - val_acc: 0.5613\n",
      "Epoch 1516/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 2.3845 - val_acc: 0.5680\n",
      "Epoch 1517/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 2.4273 - val_acc: 0.5560\n",
      "Epoch 1518/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 2.3942 - val_acc: 0.5693\n",
      "Epoch 1519/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 2.4119 - val_acc: 0.5613\n",
      "Epoch 1520/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 2.4026 - val_acc: 0.5653\n",
      "Epoch 1521/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 2.4069 - val_acc: 0.5707\n",
      "Epoch 1522/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 2.4175 - val_acc: 0.5613\n",
      "Epoch 1523/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.3983 - val_acc: 0.5693\n",
      "Epoch 1524/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 2.4295 - val_acc: 0.5573\n",
      "Epoch 1525/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 2.4020 - val_acc: 0.5653\n",
      "Epoch 1526/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 2.4171 - val_acc: 0.5613\n",
      "Epoch 1527/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 2.4073 - val_acc: 0.5693\n",
      "Epoch 1528/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 2.4135 - val_acc: 0.5680\n",
      "Epoch 1529/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 2.4061 - val_acc: 0.5693\n",
      "Epoch 1530/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 2.4177 - val_acc: 0.5680\n",
      "Epoch 1531/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 2.4310 - val_acc: 0.5613\n",
      "Epoch 1532/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 2.4032 - val_acc: 0.5680\n",
      "Epoch 1533/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 2.4367 - val_acc: 0.5613\n",
      "Epoch 1534/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.4402 - val_acc: 0.5627\n",
      "Epoch 1535/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 2.4034 - val_acc: 0.5707\n",
      "Epoch 1536/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.4305 - val_acc: 0.5613\n",
      "Epoch 1537/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 2.4171 - val_acc: 0.5667\n",
      "Epoch 1538/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 2.4302 - val_acc: 0.5627\n",
      "Epoch 1539/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 2.4317 - val_acc: 0.5653\n",
      "Epoch 1540/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 2.4215 - val_acc: 0.5640\n",
      "Epoch 1541/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 2.4363 - val_acc: 0.5640\n",
      "Epoch 1542/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 2.4226 - val_acc: 0.5653\n",
      "Epoch 1543/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 2.4113 - val_acc: 0.5640\n",
      "Epoch 1544/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 2.4434 - val_acc: 0.5613\n",
      "Epoch 1545/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 2.4354 - val_acc: 0.5693\n",
      "Epoch 1546/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 2.4327 - val_acc: 0.5627\n",
      "Epoch 1547/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 2.4379 - val_acc: 0.5640\n",
      "Epoch 1548/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 2.4378 - val_acc: 0.5680\n",
      "Epoch 1549/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4386 - val_acc: 0.5667\n",
      "Epoch 1550/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4314 - val_acc: 0.5653\n",
      "Epoch 1551/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4475 - val_acc: 0.5653\n",
      "Epoch 1552/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.4369 - val_acc: 0.5680\n",
      "Epoch 1553/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 2.4551 - val_acc: 0.5613\n",
      "Epoch 1554/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4484 - val_acc: 0.5627\n",
      "Epoch 1555/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 2.4239 - val_acc: 0.5667\n",
      "Epoch 1556/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 2.4857 - val_acc: 0.5587\n",
      "Epoch 1557/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 2.4482 - val_acc: 0.5680\n",
      "Epoch 1558/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 2.4463 - val_acc: 0.5720\n",
      "Epoch 1559/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 2.4829 - val_acc: 0.5587\n",
      "Epoch 1560/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 2.4349 - val_acc: 0.5693\n",
      "Epoch 1561/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 2.4522 - val_acc: 0.5667\n",
      "Epoch 1562/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.4647 - val_acc: 0.5600\n",
      "Epoch 1563/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 2.4406 - val_acc: 0.5693\n",
      "Epoch 1564/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.4779 - val_acc: 0.5560\n",
      "Epoch 1565/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.4381 - val_acc: 0.5667\n",
      "Epoch 1566/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 2.4659 - val_acc: 0.5613\n",
      "Epoch 1567/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 2.4479 - val_acc: 0.5653\n",
      "Epoch 1568/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.4586 - val_acc: 0.5653\n",
      "Epoch 1569/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.4495 - val_acc: 0.5680\n",
      "Epoch 1570/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 2.4703 - val_acc: 0.5640\n",
      "Epoch 1571/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.4573 - val_acc: 0.5667\n",
      "Epoch 1572/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.4802 - val_acc: 0.5587\n",
      "Epoch 1573/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 2.4578 - val_acc: 0.5667\n",
      "Epoch 1574/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.4542 - val_acc: 0.5640\n",
      "Epoch 1575/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 2.4949 - val_acc: 0.5560\n",
      "Epoch 1576/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.4449 - val_acc: 0.5680\n",
      "Epoch 1577/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 2.4885 - val_acc: 0.5600\n",
      "Epoch 1578/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.4636 - val_acc: 0.5693\n",
      "Epoch 1579/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 2.4554 - val_acc: 0.5667\n",
      "Epoch 1580/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 2.5350 - val_acc: 0.5507\n",
      "Epoch 1581/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 2.4723 - val_acc: 0.5667\n",
      "Epoch 1582/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4594 - val_acc: 0.5707\n",
      "Epoch 1583/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.4954 - val_acc: 0.5560\n",
      "Epoch 1584/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 2.4680 - val_acc: 0.5627\n",
      "Epoch 1585/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 2.4787 - val_acc: 0.5667\n",
      "Epoch 1586/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 2.4967 - val_acc: 0.5573\n",
      "Epoch 1587/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 2.4596 - val_acc: 0.5693\n",
      "Epoch 1588/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 2.5018 - val_acc: 0.5587\n",
      "Epoch 1589/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 2.4787 - val_acc: 0.5667\n",
      "Epoch 1590/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.4766 - val_acc: 0.5707\n",
      "Epoch 1591/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 2.5232 - val_acc: 0.5587\n",
      "Epoch 1592/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 2.4574 - val_acc: 0.5640\n",
      "Epoch 1593/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.5123 - val_acc: 0.5560\n",
      "Epoch 1594/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 2.4888 - val_acc: 0.5627\n",
      "Epoch 1595/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 2.4708 - val_acc: 0.5680\n",
      "Epoch 1596/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.5093 - val_acc: 0.5587\n",
      "Epoch 1597/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 2.4787 - val_acc: 0.5667\n",
      "Epoch 1598/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.5077 - val_acc: 0.5613\n",
      "Epoch 1599/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 2.4801 - val_acc: 0.5667\n",
      "Epoch 1600/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 2.5004 - val_acc: 0.5613\n",
      "Epoch 1601/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 2.4862 - val_acc: 0.5653\n",
      "Epoch 1602/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 2.4963 - val_acc: 0.5640\n",
      "Epoch 1603/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.4957 - val_acc: 0.5640\n",
      "Epoch 1604/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.4963 - val_acc: 0.5653\n",
      "Epoch 1605/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.5121 - val_acc: 0.5613\n",
      "Epoch 1606/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 2.4942 - val_acc: 0.5707\n",
      "Epoch 1607/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.5175 - val_acc: 0.5587\n",
      "Epoch 1608/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 2.5047 - val_acc: 0.5627\n",
      "Epoch 1609/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.5047 - val_acc: 0.5667\n",
      "Epoch 1610/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.5041 - val_acc: 0.5667\n",
      "Epoch 1611/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.5103 - val_acc: 0.5600\n",
      "Epoch 1612/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.4901 - val_acc: 0.5667\n",
      "Epoch 1613/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 2.5233 - val_acc: 0.5587\n",
      "Epoch 1614/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.4983 - val_acc: 0.5667\n",
      "Epoch 1615/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.5260 - val_acc: 0.5573\n",
      "Epoch 1616/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.5206 - val_acc: 0.5613\n",
      "Epoch 1617/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.5043 - val_acc: 0.5653\n",
      "Epoch 1618/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5158 - val_acc: 0.5667\n",
      "Epoch 1619/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.5080 - val_acc: 0.5640\n",
      "Epoch 1620/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5154 - val_acc: 0.5627\n",
      "Epoch 1621/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.5259 - val_acc: 0.5587\n",
      "Epoch 1622/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.5034 - val_acc: 0.5680\n",
      "Epoch 1623/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 2.5610 - val_acc: 0.5587\n",
      "Epoch 1624/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 2.5170 - val_acc: 0.5627\n",
      "Epoch 1625/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.5045 - val_acc: 0.5680\n",
      "Epoch 1626/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 2.5424 - val_acc: 0.5573\n",
      "Epoch 1627/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.5150 - val_acc: 0.5653\n",
      "Epoch 1628/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5090 - val_acc: 0.5680\n",
      "Epoch 1629/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 2.5459 - val_acc: 0.5600\n",
      "Epoch 1630/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5114 - val_acc: 0.5667\n",
      "Epoch 1631/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.5403 - val_acc: 0.5627\n",
      "Epoch 1632/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5244 - val_acc: 0.5640\n",
      "Epoch 1633/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 2.5236 - val_acc: 0.5640\n",
      "Epoch 1634/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.5469 - val_acc: 0.5600\n",
      "Epoch 1635/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 2.5147 - val_acc: 0.5720\n",
      "Epoch 1636/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5647 - val_acc: 0.5587\n",
      "Epoch 1637/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.5398 - val_acc: 0.5640\n",
      "Epoch 1638/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.5329 - val_acc: 0.5667\n",
      "Epoch 1639/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 2.5532 - val_acc: 0.5587\n",
      "Epoch 1640/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.5366 - val_acc: 0.5680\n",
      "Epoch 1641/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.5297 - val_acc: 0.5653\n",
      "Epoch 1642/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 2.5614 - val_acc: 0.5587\n",
      "Epoch 1643/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.5191 - val_acc: 0.5680\n",
      "Epoch 1644/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.5710 - val_acc: 0.5587\n",
      "Epoch 1645/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 2.5399 - val_acc: 0.5653\n",
      "Epoch 1646/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 2.5271 - val_acc: 0.5707\n",
      "Epoch 1647/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.5707 - val_acc: 0.5587\n",
      "Epoch 1648/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.5405 - val_acc: 0.5680\n",
      "Epoch 1649/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.5616 - val_acc: 0.5573\n",
      "Epoch 1650/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.5525 - val_acc: 0.5613\n",
      "Epoch 1651/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.5297 - val_acc: 0.5680\n",
      "Epoch 1652/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 2.5901 - val_acc: 0.5547\n",
      "Epoch 1653/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 2.5501 - val_acc: 0.5653\n",
      "Epoch 1654/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 2.5539 - val_acc: 0.5667\n",
      "Epoch 1655/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 2.5870 - val_acc: 0.5587\n",
      "Epoch 1656/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.5328 - val_acc: 0.5680\n",
      "Epoch 1657/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.5836 - val_acc: 0.5600\n",
      "Epoch 1658/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.5709 - val_acc: 0.5573\n",
      "Epoch 1659/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 2.5317 - val_acc: 0.5680\n",
      "Epoch 1660/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 2.6045 - val_acc: 0.5587\n",
      "Epoch 1661/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.5490 - val_acc: 0.5667\n",
      "Epoch 1662/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.5569 - val_acc: 0.5667\n",
      "Epoch 1663/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 2.5818 - val_acc: 0.5587\n",
      "Epoch 1664/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.5360 - val_acc: 0.5667\n",
      "Epoch 1665/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 2.5842 - val_acc: 0.5587\n",
      "Epoch 1666/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.5663 - val_acc: 0.5667\n",
      "Epoch 1667/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 2.5637 - val_acc: 0.5667\n",
      "Epoch 1668/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.5756 - val_acc: 0.5613\n",
      "Epoch 1669/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.5637 - val_acc: 0.5653\n",
      "Epoch 1670/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.5721 - val_acc: 0.5640\n",
      "Epoch 1671/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.5553 - val_acc: 0.5667\n",
      "Epoch 1672/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.5970 - val_acc: 0.5573\n",
      "Epoch 1673/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.5503 - val_acc: 0.5667\n",
      "Epoch 1674/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 2.6166 - val_acc: 0.5587\n",
      "Epoch 1675/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.5712 - val_acc: 0.5653\n",
      "Epoch 1676/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.5662 - val_acc: 0.5627\n",
      "Epoch 1677/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.6050 - val_acc: 0.5587\n",
      "Epoch 1678/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.5579 - val_acc: 0.5693\n",
      "Epoch 1679/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 2.5898 - val_acc: 0.5613\n",
      "Epoch 1680/2000\n",
      "2250/2250 [==============================] - 1s 333us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.5979 - val_acc: 0.5587\n",
      "Epoch 1681/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.5664 - val_acc: 0.5640\n",
      "Epoch 1682/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.5920 - val_acc: 0.5600\n",
      "Epoch 1683/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.5873 - val_acc: 0.5613\n",
      "Epoch 1684/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.5750 - val_acc: 0.5613\n",
      "Epoch 1685/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.5877 - val_acc: 0.5613\n",
      "Epoch 1686/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.5794 - val_acc: 0.5640\n",
      "Epoch 1687/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.6139 - val_acc: 0.5573\n",
      "Epoch 1688/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.5711 - val_acc: 0.5680\n",
      "Epoch 1689/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.6048 - val_acc: 0.5587\n",
      "Epoch 1690/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.5815 - val_acc: 0.5640\n",
      "Epoch 1691/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.5935 - val_acc: 0.5640\n",
      "Epoch 1692/2000\n",
      "2250/2250 [==============================] - 1s 335us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.5915 - val_acc: 0.5653\n",
      "Epoch 1693/2000\n",
      "2250/2250 [==============================] - 1s 327us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.5924 - val_acc: 0.5640\n",
      "Epoch 1694/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.5926 - val_acc: 0.5627\n",
      "Epoch 1695/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.5902 - val_acc: 0.5653\n",
      "Epoch 1696/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.5876 - val_acc: 0.5653\n",
      "Epoch 1697/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.6134 - val_acc: 0.5560\n",
      "Epoch 1698/2000\n",
      "2250/2250 [==============================] - 1s 314us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.5814 - val_acc: 0.5680\n",
      "Epoch 1699/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.6070 - val_acc: 0.5613\n",
      "Epoch 1700/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.5987 - val_acc: 0.5640\n",
      "Epoch 1701/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.6020 - val_acc: 0.5667\n",
      "Epoch 1702/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.5847 - val_acc: 0.5640\n",
      "Epoch 1703/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.6077 - val_acc: 0.5653\n",
      "Epoch 1704/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.6099 - val_acc: 0.5653\n",
      "Epoch 1705/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.6071 - val_acc: 0.5653\n",
      "Epoch 1706/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.5987 - val_acc: 0.5653\n",
      "Epoch 1707/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.6163 - val_acc: 0.5573\n",
      "Epoch 1708/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.6046 - val_acc: 0.5667\n",
      "Epoch 1709/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.6105 - val_acc: 0.5667\n",
      "Epoch 1710/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.6032 - val_acc: 0.5667\n",
      "Epoch 1711/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.5916 - val_acc: 0.5680\n",
      "Epoch 1712/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.6223 - val_acc: 0.5573\n",
      "Epoch 1713/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.6068 - val_acc: 0.5667\n",
      "Epoch 1714/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.6253 - val_acc: 0.5600\n",
      "Epoch 1715/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.5947 - val_acc: 0.5667\n",
      "Epoch 1716/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.6444 - val_acc: 0.5587\n",
      "Epoch 1717/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.6029 - val_acc: 0.5640\n",
      "Epoch 1718/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.6290 - val_acc: 0.5613\n",
      "Epoch 1719/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.6106 - val_acc: 0.5667\n",
      "Epoch 1720/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.6269 - val_acc: 0.5600\n",
      "Epoch 1721/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.6182 - val_acc: 0.5653\n",
      "Epoch 1722/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.6212 - val_acc: 0.5640\n",
      "Epoch 1723/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6150 - val_acc: 0.5653\n",
      "Epoch 1724/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6329 - val_acc: 0.5613\n",
      "Epoch 1725/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.6275 - val_acc: 0.5653\n",
      "Epoch 1726/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6229 - val_acc: 0.5680\n",
      "Epoch 1727/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6212 - val_acc: 0.5707\n",
      "Epoch 1728/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6228 - val_acc: 0.5667\n",
      "Epoch 1729/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6545 - val_acc: 0.5573\n",
      "Epoch 1730/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.6179 - val_acc: 0.5667\n",
      "Epoch 1731/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6307 - val_acc: 0.5627\n",
      "Epoch 1732/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.6252 - val_acc: 0.5667\n",
      "Epoch 1733/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6355 - val_acc: 0.5653\n",
      "Epoch 1734/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.6537 - val_acc: 0.5600\n",
      "Epoch 1735/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.6129 - val_acc: 0.5627\n",
      "Epoch 1736/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.6612 - val_acc: 0.5587\n",
      "Epoch 1737/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.6346 - val_acc: 0.5653\n",
      "Epoch 1738/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.6424 - val_acc: 0.5627\n",
      "Epoch 1739/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.6469 - val_acc: 0.5640\n",
      "Epoch 1740/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.6391 - val_acc: 0.5653\n",
      "Epoch 1741/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6284 - val_acc: 0.5667\n",
      "Epoch 1742/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.6483 - val_acc: 0.5613\n",
      "Epoch 1743/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.6421 - val_acc: 0.5653\n",
      "Epoch 1744/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.6442 - val_acc: 0.5640\n",
      "Epoch 1745/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6284 - val_acc: 0.5653\n",
      "Epoch 1746/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.6739 - val_acc: 0.5573\n",
      "Epoch 1747/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.6335 - val_acc: 0.5667\n",
      "Epoch 1748/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6468 - val_acc: 0.5680\n",
      "Epoch 1749/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6502 - val_acc: 0.5667\n",
      "Epoch 1750/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6525 - val_acc: 0.5653\n",
      "Epoch 1751/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6568 - val_acc: 0.5613\n",
      "Epoch 1752/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6427 - val_acc: 0.5667\n",
      "Epoch 1753/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6727 - val_acc: 0.5600\n",
      "Epoch 1754/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.6310 - val_acc: 0.5653\n",
      "Epoch 1755/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.6703 - val_acc: 0.5587\n",
      "Epoch 1756/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.6393 - val_acc: 0.5653\n",
      "Epoch 1757/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6502 - val_acc: 0.5640\n",
      "Epoch 1758/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6699 - val_acc: 0.5560\n",
      "Epoch 1759/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6491 - val_acc: 0.5653\n",
      "Epoch 1760/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6752 - val_acc: 0.5600\n",
      "Epoch 1761/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6479 - val_acc: 0.5667\n",
      "Epoch 1762/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.6562 - val_acc: 0.5653\n",
      "Epoch 1763/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.6904 - val_acc: 0.5600\n",
      "Epoch 1764/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.6400 - val_acc: 0.5653\n",
      "Epoch 1765/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.7021 - val_acc: 0.5613\n",
      "Epoch 1766/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.6405 - val_acc: 0.5667\n",
      "Epoch 1767/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.6919 - val_acc: 0.5587\n",
      "Epoch 1768/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.6560 - val_acc: 0.5653\n",
      "Epoch 1769/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.6570 - val_acc: 0.5653\n",
      "Epoch 1770/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.6713 - val_acc: 0.5640\n",
      "Epoch 1771/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.6783 - val_acc: 0.5627\n",
      "Epoch 1772/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.6640 - val_acc: 0.5667\n",
      "Epoch 1773/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.6678 - val_acc: 0.5680\n",
      "Epoch 1774/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.6577 - val_acc: 0.5653\n",
      "Epoch 1775/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.6912 - val_acc: 0.5573\n",
      "Epoch 1776/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.6732 - val_acc: 0.5693\n",
      "Epoch 1777/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.6771 - val_acc: 0.5667\n",
      "Epoch 1778/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.6715 - val_acc: 0.5667\n",
      "Epoch 1779/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.6891 - val_acc: 0.5600\n",
      "Epoch 1780/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.6690 - val_acc: 0.5667\n",
      "Epoch 1781/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.6837 - val_acc: 0.5653\n",
      "Epoch 1782/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.6811 - val_acc: 0.5640\n",
      "Epoch 1783/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.6951 - val_acc: 0.5573\n",
      "Epoch 1784/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.6660 - val_acc: 0.5640\n",
      "Epoch 1785/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.7063 - val_acc: 0.5613\n",
      "Epoch 1786/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.6777 - val_acc: 0.5653\n",
      "Epoch 1787/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.7092 - val_acc: 0.5573\n",
      "Epoch 1788/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.6752 - val_acc: 0.5680\n",
      "Epoch 1789/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.6873 - val_acc: 0.5667\n",
      "Epoch 1790/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.7085 - val_acc: 0.5587\n",
      "Epoch 1791/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.6749 - val_acc: 0.5653\n",
      "Epoch 1792/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.6902 - val_acc: 0.5640\n",
      "Epoch 1793/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.6995 - val_acc: 0.5640\n",
      "Epoch 1794/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.6925 - val_acc: 0.5653\n",
      "Epoch 1795/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.6779 - val_acc: 0.5640\n",
      "Epoch 1796/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.6936 - val_acc: 0.5653\n",
      "Epoch 1797/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6928 - val_acc: 0.5680\n",
      "Epoch 1798/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.6960 - val_acc: 0.5667\n",
      "Epoch 1799/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6881 - val_acc: 0.5667\n",
      "Epoch 1800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6938 - val_acc: 0.5667\n",
      "Epoch 1801/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.6997 - val_acc: 0.5667\n",
      "Epoch 1802/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6929 - val_acc: 0.5667\n",
      "Epoch 1803/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.7008 - val_acc: 0.5613\n",
      "Epoch 1804/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.6890 - val_acc: 0.5640\n",
      "Epoch 1805/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.7281 - val_acc: 0.5587\n",
      "Epoch 1806/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.7006 - val_acc: 0.5667\n",
      "Epoch 1807/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6862 - val_acc: 0.5667\n",
      "Epoch 1808/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.7144 - val_acc: 0.5627\n",
      "Epoch 1809/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.7012 - val_acc: 0.5680\n",
      "Epoch 1810/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.7258 - val_acc: 0.5600\n",
      "Epoch 1811/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6964 - val_acc: 0.5667\n",
      "Epoch 1812/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.7073 - val_acc: 0.5653\n",
      "Epoch 1813/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.7189 - val_acc: 0.5627\n",
      "Epoch 1814/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7024 - val_acc: 0.5680\n",
      "Epoch 1815/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7221 - val_acc: 0.5613\n",
      "Epoch 1816/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.7115 - val_acc: 0.5680\n",
      "Epoch 1817/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7170 - val_acc: 0.5640\n",
      "Epoch 1818/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7060 - val_acc: 0.5680\n",
      "Epoch 1819/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7123 - val_acc: 0.5667\n",
      "Epoch 1820/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7177 - val_acc: 0.5653\n",
      "Epoch 1821/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7034 - val_acc: 0.5627\n",
      "Epoch 1822/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.7335 - val_acc: 0.5587\n",
      "Epoch 1823/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7190 - val_acc: 0.5640\n",
      "Epoch 1824/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7018 - val_acc: 0.5640\n",
      "Epoch 1825/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7323 - val_acc: 0.5573\n",
      "Epoch 1826/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7136 - val_acc: 0.5653\n",
      "Epoch 1827/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7168 - val_acc: 0.5640\n",
      "Epoch 1828/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7082 - val_acc: 0.5640\n",
      "Epoch 1829/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7334 - val_acc: 0.5600\n",
      "Epoch 1830/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7270 - val_acc: 0.5653\n",
      "Epoch 1831/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7089 - val_acc: 0.5640\n",
      "Epoch 1832/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7369 - val_acc: 0.5640\n",
      "Epoch 1833/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7117 - val_acc: 0.5653\n",
      "Epoch 1834/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.7683 - val_acc: 0.5600\n",
      "Epoch 1835/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.7149 - val_acc: 0.5640\n",
      "Epoch 1836/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.7236 - val_acc: 0.5680\n",
      "Epoch 1837/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7372 - val_acc: 0.5600\n",
      "Epoch 1838/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7229 - val_acc: 0.5667\n",
      "Epoch 1839/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.7223 - val_acc: 0.5640\n",
      "Epoch 1840/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.7455 - val_acc: 0.5573\n",
      "Epoch 1841/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7191 - val_acc: 0.5640\n",
      "Epoch 1842/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7523 - val_acc: 0.5600\n",
      "Epoch 1843/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.7327 - val_acc: 0.5680\n",
      "Epoch 1844/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7485 - val_acc: 0.5600\n",
      "Epoch 1845/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7448 - val_acc: 0.5627\n",
      "Epoch 1846/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7261 - val_acc: 0.5667\n",
      "Epoch 1847/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.7594 - val_acc: 0.5587\n",
      "Epoch 1848/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7352 - val_acc: 0.5680\n",
      "Epoch 1849/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7450 - val_acc: 0.5627\n",
      "Epoch 1850/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7554 - val_acc: 0.5613\n",
      "Epoch 1851/2000\n",
      "2250/2250 [==============================] - 1s 321us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7268 - val_acc: 0.5613\n",
      "Epoch 1852/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.7950 - val_acc: 0.5587\n",
      "Epoch 1853/2000\n",
      "2250/2250 [==============================] - 1s 315us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.7437 - val_acc: 0.5640\n",
      "Epoch 1854/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7392 - val_acc: 0.5680\n",
      "Epoch 1855/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7655 - val_acc: 0.5587\n",
      "Epoch 1856/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7236 - val_acc: 0.5613\n",
      "Epoch 1857/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.7644 - val_acc: 0.5627\n",
      "Epoch 1858/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7569 - val_acc: 0.5627\n",
      "Epoch 1859/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7432 - val_acc: 0.5667\n",
      "Epoch 1860/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7644 - val_acc: 0.5627\n",
      "Epoch 1861/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7375 - val_acc: 0.5640\n",
      "Epoch 1862/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7823 - val_acc: 0.5587\n",
      "Epoch 1863/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.7419 - val_acc: 0.5653\n",
      "Epoch 1864/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.7540 - val_acc: 0.5667\n",
      "Epoch 1865/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.7655 - val_acc: 0.5627\n",
      "Epoch 1866/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.7441 - val_acc: 0.5640\n",
      "Epoch 1867/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.8012 - val_acc: 0.5587\n",
      "Epoch 1868/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.7364 - val_acc: 0.5613\n",
      "Epoch 1869/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.7770 - val_acc: 0.5587\n",
      "Epoch 1870/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.7566 - val_acc: 0.5680\n",
      "Epoch 1871/2000\n",
      "2250/2250 [==============================] - 1s 314us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.7598 - val_acc: 0.5640\n",
      "Epoch 1872/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7492 - val_acc: 0.5653\n",
      "Epoch 1873/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7684 - val_acc: 0.5653\n",
      "Epoch 1874/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7656 - val_acc: 0.5653\n",
      "Epoch 1875/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7659 - val_acc: 0.5653\n",
      "Epoch 1876/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7644 - val_acc: 0.5653\n",
      "Epoch 1877/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7819 - val_acc: 0.5573\n",
      "Epoch 1878/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7674 - val_acc: 0.5693\n",
      "Epoch 1879/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7606 - val_acc: 0.5680\n",
      "Epoch 1880/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7845 - val_acc: 0.5587\n",
      "Epoch 1881/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7685 - val_acc: 0.5667\n",
      "Epoch 1882/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7854 - val_acc: 0.5613\n",
      "Epoch 1883/2000\n",
      "2250/2250 [==============================] - 1s 305us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7625 - val_acc: 0.5693\n",
      "Epoch 1884/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7770 - val_acc: 0.5680\n",
      "Epoch 1885/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.7912 - val_acc: 0.5587\n",
      "Epoch 1886/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7695 - val_acc: 0.5667\n",
      "Epoch 1887/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.7909 - val_acc: 0.5627\n",
      "Epoch 1888/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7626 - val_acc: 0.5653\n",
      "Epoch 1889/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.7969 - val_acc: 0.5560\n",
      "Epoch 1890/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7811 - val_acc: 0.5667\n",
      "Epoch 1891/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.7825 - val_acc: 0.5627\n",
      "Epoch 1892/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.7871 - val_acc: 0.5627\n",
      "Epoch 1893/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.7826 - val_acc: 0.5653\n",
      "Epoch 1894/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7832 - val_acc: 0.5680\n",
      "Epoch 1895/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7898 - val_acc: 0.5667\n",
      "Epoch 1896/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7764 - val_acc: 0.5667\n",
      "Epoch 1897/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.7845 - val_acc: 0.5653\n",
      "Epoch 1898/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7930 - val_acc: 0.5640\n",
      "Epoch 1899/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7924 - val_acc: 0.5653\n",
      "Epoch 1900/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7758 - val_acc: 0.5680\n",
      "Epoch 1901/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7940 - val_acc: 0.5640\n",
      "Epoch 1902/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7875 - val_acc: 0.5693\n",
      "Epoch 1903/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.7993 - val_acc: 0.5613\n",
      "Epoch 1904/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7824 - val_acc: 0.5680\n",
      "Epoch 1905/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7890 - val_acc: 0.5693\n",
      "Epoch 1906/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.8001 - val_acc: 0.5627\n",
      "Epoch 1907/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7829 - val_acc: 0.5667\n",
      "Epoch 1908/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7975 - val_acc: 0.5627\n",
      "Epoch 1909/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.7910 - val_acc: 0.5693\n",
      "Epoch 1910/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.8098 - val_acc: 0.5573\n",
      "Epoch 1911/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.7822 - val_acc: 0.5667\n",
      "Epoch 1912/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.8007 - val_acc: 0.5613\n",
      "Epoch 1913/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.8093 - val_acc: 0.5600\n",
      "Epoch 1914/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.7942 - val_acc: 0.5653\n",
      "Epoch 1915/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.8231 - val_acc: 0.5573\n",
      "Epoch 1916/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.7915 - val_acc: 0.5667\n",
      "Epoch 1917/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.8026 - val_acc: 0.5640\n",
      "Epoch 1918/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.7889 - val_acc: 0.5667\n",
      "Epoch 1919/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.8178 - val_acc: 0.5573\n",
      "Epoch 1920/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.8019 - val_acc: 0.5680\n",
      "Epoch 1921/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8101 - val_acc: 0.5600\n",
      "Epoch 1922/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8009 - val_acc: 0.5653\n",
      "Epoch 1923/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8142 - val_acc: 0.5640\n",
      "Epoch 1924/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.7962 - val_acc: 0.5667\n",
      "Epoch 1925/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8246 - val_acc: 0.5627\n",
      "Epoch 1926/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.8055 - val_acc: 0.5693\n",
      "Epoch 1927/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8193 - val_acc: 0.5600\n",
      "Epoch 1928/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8070 - val_acc: 0.5667\n",
      "Epoch 1929/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8047 - val_acc: 0.5680\n",
      "Epoch 1930/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8236 - val_acc: 0.5600\n",
      "Epoch 1931/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8132 - val_acc: 0.5707\n",
      "Epoch 1932/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8193 - val_acc: 0.5613\n",
      "Epoch 1933/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8028 - val_acc: 0.5653\n",
      "Epoch 1934/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8317 - val_acc: 0.5587\n",
      "Epoch 1935/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8024 - val_acc: 0.5667\n",
      "Epoch 1936/2000\n",
      "2250/2250 [==============================] - 1s 311us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8310 - val_acc: 0.5613\n",
      "Epoch 1937/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8059 - val_acc: 0.5640\n",
      "Epoch 1938/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.8263 - val_acc: 0.5587\n",
      "Epoch 1939/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8086 - val_acc: 0.5667\n",
      "Epoch 1940/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8236 - val_acc: 0.5627\n",
      "Epoch 1941/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8138 - val_acc: 0.5707\n",
      "Epoch 1942/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8479 - val_acc: 0.5587\n",
      "Epoch 1943/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.8201 - val_acc: 0.5680\n",
      "Epoch 1944/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8277 - val_acc: 0.5627\n",
      "Epoch 1945/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8294 - val_acc: 0.5640\n",
      "Epoch 1946/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8210 - val_acc: 0.5680\n",
      "Epoch 1947/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8389 - val_acc: 0.5613\n",
      "Epoch 1948/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8216 - val_acc: 0.5680\n",
      "Epoch 1949/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8321 - val_acc: 0.5680\n",
      "Epoch 1950/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8348 - val_acc: 0.5627\n",
      "Epoch 1951/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8226 - val_acc: 0.5693\n",
      "Epoch 1952/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8367 - val_acc: 0.5627\n",
      "Epoch 1953/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8289 - val_acc: 0.5680\n",
      "Epoch 1954/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8481 - val_acc: 0.5627\n",
      "Epoch 1955/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8222 - val_acc: 0.5667\n",
      "Epoch 1956/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8360 - val_acc: 0.5693\n",
      "Epoch 1957/2000\n",
      "2250/2250 [==============================] - 1s 312us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8576 - val_acc: 0.5587\n",
      "Epoch 1958/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.8370 - val_acc: 0.5707\n",
      "Epoch 1959/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8440 - val_acc: 0.5640\n",
      "Epoch 1960/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8307 - val_acc: 0.5707\n",
      "Epoch 1961/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8473 - val_acc: 0.5627\n",
      "Epoch 1962/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8320 - val_acc: 0.5667\n",
      "Epoch 1963/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8380 - val_acc: 0.5653\n",
      "Epoch 1964/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8336 - val_acc: 0.5653\n",
      "Epoch 1965/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8518 - val_acc: 0.5640\n",
      "Epoch 1966/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8348 - val_acc: 0.5667\n",
      "Epoch 1967/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8491 - val_acc: 0.5600\n",
      "Epoch 1968/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8394 - val_acc: 0.5680\n",
      "Epoch 1969/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8462 - val_acc: 0.5667\n",
      "Epoch 1970/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8491 - val_acc: 0.5640\n",
      "Epoch 1971/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8429 - val_acc: 0.5667\n",
      "Epoch 1972/2000\n",
      "2250/2250 [==============================] - 1s 310us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8409 - val_acc: 0.5680\n",
      "Epoch 1973/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8749 - val_acc: 0.5560\n",
      "Epoch 1974/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.8275 - val_acc: 0.5640\n",
      "Epoch 1975/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.8645 - val_acc: 0.5600\n",
      "Epoch 1976/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8486 - val_acc: 0.5667\n",
      "Epoch 1977/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8457 - val_acc: 0.5653\n",
      "Epoch 1978/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.8610 - val_acc: 0.5627\n",
      "Epoch 1979/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.8490 - val_acc: 0.5707\n",
      "Epoch 1980/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8601 - val_acc: 0.5627\n",
      "Epoch 1981/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8500 - val_acc: 0.5667\n",
      "Epoch 1982/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8612 - val_acc: 0.5627\n",
      "Epoch 1983/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8563 - val_acc: 0.5680\n",
      "Epoch 1984/2000\n",
      "2250/2250 [==============================] - 1s 325us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8526 - val_acc: 0.5693\n",
      "Epoch 1985/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8587 - val_acc: 0.5600\n",
      "Epoch 1986/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8581 - val_acc: 0.5640\n",
      "Epoch 1987/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8718 - val_acc: 0.5600\n",
      "Epoch 1988/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8689 - val_acc: 0.5627\n",
      "Epoch 1989/2000\n",
      "2250/2250 [==============================] - 1s 309us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8513 - val_acc: 0.5667\n",
      "Epoch 1990/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8623 - val_acc: 0.5667\n",
      "Epoch 1991/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8726 - val_acc: 0.5640\n",
      "Epoch 1992/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8639 - val_acc: 0.5653\n",
      "Epoch 1993/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8573 - val_acc: 0.5653\n",
      "Epoch 1994/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8678 - val_acc: 0.5640\n",
      "Epoch 1995/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8646 - val_acc: 0.5720\n",
      "Epoch 1996/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.8747 - val_acc: 0.5627\n",
      "Epoch 1997/2000\n",
      "2250/2250 [==============================] - 1s 306us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8549 - val_acc: 0.5653\n",
      "Epoch 1998/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8813 - val_acc: 0.5613\n",
      "Epoch 1999/2000\n",
      "2250/2250 [==============================] - 1s 307us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.8615 - val_acc: 0.5640\n",
      "Epoch 2000/2000\n",
      "2250/2250 [==============================] - 1s 308us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.8841 - val_acc: 0.5600\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3535952e-08, 9.9998426e-01, 1.5749665e-05],\n",
       "       [4.3779858e-03, 3.1283475e-02, 9.6433848e-01],\n",
       "       [7.5610620e-03, 1.8709663e-01, 8.0534232e-01],\n",
       "       ...,\n",
       "       [7.0347404e-01, 9.4181247e-02, 2.0234472e-01],\n",
       "       [2.0415086e-05, 9.9790961e-01, 2.0699035e-03],\n",
       "       [9.9999928e-01, 1.8515641e-08, 6.8538850e-07]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(testX,batch_size=batch_size)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.47      0.59      0.53       239\n",
      "        dogs       0.51      0.45      0.48       262\n",
      "       panda       0.73      0.65      0.69       249\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       750\n",
      "   macro avg       0.57      0.56      0.56       750\n",
      "weighted avg       0.57      0.56      0.56       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faedf8eb3c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = np.arange(0, epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving the model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] saving the model...\")\n",
    "model.save(args[\"model\"])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args[\"label_bin\"], \"wb\") as f :\n",
    "    f.write(pickle.dumps(lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open('./output/label_bin_simple_nn_model_mostafa','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = paths.list_images('./animals/')\n",
    "d=[] \n",
    "for im in imgs:\n",
    "    d.append(im)\n",
    "imgs = np.array(d)    \n",
    "np.random.shuffle(imgs)\n",
    "\n",
    "for img in imgs:\n",
    "    img = cv2.imread(img)\n",
    "    copy = cv2.resize(img, (32,32)).flatten() / 255.0 \n",
    "    copy = copy.reshape(1, copy.shape[0])\n",
    "    pred = model.predict(copy) \n",
    "    label = lb.classes_[pred.argmax(axis=1)][0]\n",
    "    text = \"{}: {:.2f}%\".format(label, pred[0][pred.argmax(axis=1)[0]] * 100)\n",
    "    cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0, 0, 255), 2)\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.shuffle()\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
